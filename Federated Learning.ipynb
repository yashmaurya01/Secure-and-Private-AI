{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "# mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import syft as sy\n",
    "\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:trusted_agg #objects:0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "trusted_agg = sy.VirtualWorker(hook, id = \"trusted_agg\")\n",
    "\n",
    "bob.clear_objects()\n",
    "alice.clear_objects()\n",
    "trusted_agg.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])).federate((bob, alice)), \n",
    "                                                batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = th.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bob_train_dataset = sy.BaseDataset(train_data[:train_idx], train_labels[:train_idx]).send(bob)\n",
    "# bob_test_dataset = sy.BaseDataset(test_data[:test_idx], test_labels[:test_idx]).send(bob)\n",
    "\n",
    "# alice_train_dataset = sy.BaseDataset(train_data[train_idx:], train_labels[train_idx:]).send(alice)\n",
    "# alice_test_dataset = sy.BaseDataset(test_data[test_idx:], test_labels[test_idx:]).send(alice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_dataset = sy.FederatedDataset([bob_train_dataset, alice_train_dataset])\n",
    "# federated_test_dataset = sy.FederatedDataset([bob_test_dataset, alice_test_dataset])\n",
    "\n",
    "# federated_train_dataloader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size = 64)\n",
    "# federated_test_dataloader = sy.FederatedDataLoader(federated_test_dataset, shuffle=True, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, federate_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(federate_train_loader):\n",
    "        model.send(data.location)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get()\n",
    "        if batch_idx % 30 == 0:\n",
    "            loss = loss.get()\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx*64}/{len(federate_train_loader)*64} ({100. * batch_idx / len(federated_train_loader)}%)] \\t Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with th.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction= 'sum').item() #sum up batch loss\n",
    "            pred = output.argmax(1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60032 (0.0%)] \t Loss: 2.3842861652374268\n",
      "Train Epoch: 1 [1920/60032 (3.1982942430703623%)] \t Loss: 2.2972631454467773\n",
      "Train Epoch: 1 [3840/60032 (6.3965884861407245%)] \t Loss: 2.2915751934051514\n",
      "Train Epoch: 1 [5760/60032 (9.594882729211088%)] \t Loss: 2.2619338035583496\n",
      "Train Epoch: 1 [7680/60032 (12.793176972281449%)] \t Loss: 2.220524311065674\n",
      "Train Epoch: 1 [9600/60032 (15.991471215351812%)] \t Loss: 2.105748176574707\n",
      "Train Epoch: 1 [11520/60032 (19.189765458422176%)] \t Loss: 2.0877764225006104\n",
      "Train Epoch: 1 [13440/60032 (22.388059701492537%)] \t Loss: 1.907545804977417\n",
      "Train Epoch: 1 [15360/60032 (25.586353944562898%)] \t Loss: 1.7111232280731201\n",
      "Train Epoch: 1 [17280/60032 (28.784648187633262%)] \t Loss: 1.509189248085022\n",
      "Train Epoch: 1 [19200/60032 (31.982942430703623%)] \t Loss: 1.5387048721313477\n",
      "Train Epoch: 1 [21120/60032 (35.18123667377399%)] \t Loss: 1.3840252161026\n",
      "Train Epoch: 1 [23040/60032 (38.37953091684435%)] \t Loss: 1.0371626615524292\n",
      "Train Epoch: 1 [24960/60032 (41.57782515991471%)] \t Loss: 1.078875184059143\n",
      "Train Epoch: 1 [26880/60032 (44.776119402985074%)] \t Loss: 1.0499022006988525\n",
      "Train Epoch: 1 [28800/60032 (47.97441364605544%)] \t Loss: 0.9322268962860107\n",
      "Train Epoch: 1 [30720/60032 (51.172707889125796%)] \t Loss: 0.9230748414993286\n",
      "Train Epoch: 1 [32640/60032 (54.37100213219616%)] \t Loss: 0.6522901058197021\n",
      "Train Epoch: 1 [34560/60032 (57.569296375266525%)] \t Loss: 0.8697865009307861\n",
      "Train Epoch: 1 [36480/60032 (60.76759061833689%)] \t Loss: 0.6340234279632568\n",
      "Train Epoch: 1 [38400/60032 (63.96588486140725%)] \t Loss: 0.8791638612747192\n",
      "Train Epoch: 1 [40320/60032 (67.16417910447761%)] \t Loss: 0.6881065368652344\n",
      "Train Epoch: 1 [42240/60032 (70.36247334754798%)] \t Loss: 0.6022143363952637\n",
      "Train Epoch: 1 [44160/60032 (73.56076759061834%)] \t Loss: 0.5819265246391296\n",
      "Train Epoch: 1 [46080/60032 (76.7590618336887%)] \t Loss: 0.7012923955917358\n",
      "Train Epoch: 1 [48000/60032 (79.95735607675905%)] \t Loss: 0.664373517036438\n",
      "Train Epoch: 1 [49920/60032 (83.15565031982942%)] \t Loss: 0.9320135712623596\n",
      "Train Epoch: 1 [51840/60032 (86.35394456289978%)] \t Loss: 0.6820898056030273\n",
      "Train Epoch: 1 [53760/60032 (89.55223880597015%)] \t Loss: 0.7834733724594116\n",
      "Train Epoch: 1 [55680/60032 (92.75053304904051%)] \t Loss: 0.6509917974472046\n",
      "Train Epoch: 1 [57600/60032 (95.94882729211088%)] \t Loss: 0.8551297783851624\n",
      "Train Epoch: 1 [59520/60032 (99.14712153518124%)] \t Loss: 0.5246497988700867\n",
      "\n",
      "Test set: Average loss: 0.2696, Accuracy: 9251/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60032 (0.0%)] \t Loss: 0.40070927143096924\n",
      "Train Epoch: 2 [1920/60032 (3.1982942430703623%)] \t Loss: 0.7778343558311462\n",
      "Train Epoch: 2 [3840/60032 (6.3965884861407245%)] \t Loss: 0.3347555994987488\n",
      "Train Epoch: 2 [5760/60032 (9.594882729211088%)] \t Loss: 0.537438154220581\n",
      "Train Epoch: 2 [7680/60032 (12.793176972281449%)] \t Loss: 0.6419604420661926\n",
      "Train Epoch: 2 [9600/60032 (15.991471215351812%)] \t Loss: 0.6093391180038452\n",
      "Train Epoch: 2 [11520/60032 (19.189765458422176%)] \t Loss: 0.562760591506958\n",
      "Train Epoch: 2 [13440/60032 (22.388059701492537%)] \t Loss: 0.5787466764450073\n",
      "Train Epoch: 2 [15360/60032 (25.586353944562898%)] \t Loss: 0.6238731145858765\n",
      "Train Epoch: 2 [17280/60032 (28.784648187633262%)] \t Loss: 0.6032298803329468\n",
      "Train Epoch: 2 [19200/60032 (31.982942430703623%)] \t Loss: 0.48718127608299255\n",
      "Train Epoch: 2 [21120/60032 (35.18123667377399%)] \t Loss: 0.6334317922592163\n",
      "Train Epoch: 2 [23040/60032 (38.37953091684435%)] \t Loss: 0.5328752398490906\n",
      "Train Epoch: 2 [24960/60032 (41.57782515991471%)] \t Loss: 0.4184061288833618\n",
      "Train Epoch: 2 [26880/60032 (44.776119402985074%)] \t Loss: 0.5381261110305786\n",
      "Train Epoch: 2 [28800/60032 (47.97441364605544%)] \t Loss: 0.5796235203742981\n",
      "Train Epoch: 2 [30720/60032 (51.172707889125796%)] \t Loss: 0.4908911883831024\n",
      "Train Epoch: 2 [32640/60032 (54.37100213219616%)] \t Loss: 0.627998948097229\n",
      "Train Epoch: 2 [34560/60032 (57.569296375266525%)] \t Loss: 0.4840008616447449\n",
      "Train Epoch: 2 [36480/60032 (60.76759061833689%)] \t Loss: 0.45351412892341614\n",
      "Train Epoch: 2 [38400/60032 (63.96588486140725%)] \t Loss: 0.2756708860397339\n",
      "Train Epoch: 2 [40320/60032 (67.16417910447761%)] \t Loss: 0.4057190716266632\n",
      "Train Epoch: 2 [42240/60032 (70.36247334754798%)] \t Loss: 0.35548165440559387\n",
      "Train Epoch: 2 [44160/60032 (73.56076759061834%)] \t Loss: 0.41412419080734253\n",
      "Train Epoch: 2 [46080/60032 (76.7590618336887%)] \t Loss: 0.4195617437362671\n",
      "Train Epoch: 2 [48000/60032 (79.95735607675905%)] \t Loss: 0.35541677474975586\n",
      "Train Epoch: 2 [49920/60032 (83.15565031982942%)] \t Loss: 0.46287769079208374\n",
      "Train Epoch: 2 [51840/60032 (86.35394456289978%)] \t Loss: 0.4742843806743622\n",
      "Train Epoch: 2 [53760/60032 (89.55223880597015%)] \t Loss: 0.4384869933128357\n",
      "Train Epoch: 2 [55680/60032 (92.75053304904051%)] \t Loss: 0.4323931932449341\n",
      "Train Epoch: 2 [57600/60032 (95.94882729211088%)] \t Loss: 0.5074498653411865\n",
      "Train Epoch: 2 [59520/60032 (99.14712153518124%)] \t Loss: 0.20664095878601074\n",
      "\n",
      "Test set: Average loss: 0.1644, Accuracy: 9506/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60032 (0.0%)] \t Loss: 0.2672320604324341\n",
      "Train Epoch: 3 [1920/60032 (3.1982942430703623%)] \t Loss: 0.36005306243896484\n",
      "Train Epoch: 3 [3840/60032 (6.3965884861407245%)] \t Loss: 0.3637439012527466\n",
      "Train Epoch: 3 [5760/60032 (9.594882729211088%)] \t Loss: 0.5408033132553101\n",
      "Train Epoch: 3 [7680/60032 (12.793176972281449%)] \t Loss: 0.362201452255249\n",
      "Train Epoch: 3 [9600/60032 (15.991471215351812%)] \t Loss: 0.3265834450721741\n",
      "Train Epoch: 3 [11520/60032 (19.189765458422176%)] \t Loss: 0.35360273718833923\n",
      "Train Epoch: 3 [13440/60032 (22.388059701492537%)] \t Loss: 0.48727989196777344\n",
      "Train Epoch: 3 [15360/60032 (25.586353944562898%)] \t Loss: 0.5203714370727539\n",
      "Train Epoch: 3 [17280/60032 (28.784648187633262%)] \t Loss: 0.20409098267555237\n",
      "Train Epoch: 3 [19200/60032 (31.982942430703623%)] \t Loss: 0.23131248354911804\n",
      "Train Epoch: 3 [21120/60032 (35.18123667377399%)] \t Loss: 0.37234678864479065\n",
      "Train Epoch: 3 [23040/60032 (38.37953091684435%)] \t Loss: 0.45048266649246216\n",
      "Train Epoch: 3 [24960/60032 (41.57782515991471%)] \t Loss: 0.4124932289123535\n",
      "Train Epoch: 3 [26880/60032 (44.776119402985074%)] \t Loss: 0.3946296274662018\n",
      "Train Epoch: 3 [28800/60032 (47.97441364605544%)] \t Loss: 0.46277210116386414\n",
      "Train Epoch: 3 [30720/60032 (51.172707889125796%)] \t Loss: 0.240193173289299\n",
      "Train Epoch: 3 [32640/60032 (54.37100213219616%)] \t Loss: 0.2670711278915405\n",
      "Train Epoch: 3 [34560/60032 (57.569296375266525%)] \t Loss: 0.38612252473831177\n",
      "Train Epoch: 3 [36480/60032 (60.76759061833689%)] \t Loss: 0.26082950830459595\n",
      "Train Epoch: 3 [38400/60032 (63.96588486140725%)] \t Loss: 0.345960408449173\n",
      "Train Epoch: 3 [40320/60032 (67.16417910447761%)] \t Loss: 0.5821199417114258\n",
      "Train Epoch: 3 [42240/60032 (70.36247334754798%)] \t Loss: 0.2678181529045105\n",
      "Train Epoch: 3 [44160/60032 (73.56076759061834%)] \t Loss: 0.3006799817085266\n",
      "Train Epoch: 3 [46080/60032 (76.7590618336887%)] \t Loss: 0.33577200770378113\n",
      "Train Epoch: 3 [48000/60032 (79.95735607675905%)] \t Loss: 0.3466672897338867\n",
      "Train Epoch: 3 [49920/60032 (83.15565031982942%)] \t Loss: 0.18959221243858337\n",
      "Train Epoch: 3 [51840/60032 (86.35394456289978%)] \t Loss: 0.3758615553379059\n",
      "Train Epoch: 3 [53760/60032 (89.55223880597015%)] \t Loss: 0.26815083622932434\n",
      "Train Epoch: 3 [55680/60032 (92.75053304904051%)] \t Loss: 0.3399580717086792\n",
      "Train Epoch: 3 [57600/60032 (95.94882729211088%)] \t Loss: 0.23484599590301514\n",
      "Train Epoch: 3 [59520/60032 (99.14712153518124%)] \t Loss: 0.4883710741996765\n",
      "\n",
      "Test set: Average loss: 0.1308, Accuracy: 9613/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60032 (0.0%)] \t Loss: 0.3758498430252075\n",
      "Train Epoch: 4 [1920/60032 (3.1982942430703623%)] \t Loss: 0.5284408926963806\n",
      "Train Epoch: 4 [3840/60032 (6.3965884861407245%)] \t Loss: 0.156260147690773\n",
      "Train Epoch: 4 [5760/60032 (9.594882729211088%)] \t Loss: 0.23250895738601685\n",
      "Train Epoch: 4 [7680/60032 (12.793176972281449%)] \t Loss: 0.2665669322013855\n",
      "Train Epoch: 4 [9600/60032 (15.991471215351812%)] \t Loss: 0.32832878828048706\n",
      "Train Epoch: 4 [11520/60032 (19.189765458422176%)] \t Loss: 0.3376224637031555\n",
      "Train Epoch: 4 [13440/60032 (22.388059701492537%)] \t Loss: 0.23151494562625885\n",
      "Train Epoch: 4 [15360/60032 (25.586353944562898%)] \t Loss: 0.28966814279556274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [17280/60032 (28.784648187633262%)] \t Loss: 0.3432607650756836\n",
      "Train Epoch: 4 [19200/60032 (31.982942430703623%)] \t Loss: 0.2782602608203888\n",
      "Train Epoch: 4 [21120/60032 (35.18123667377399%)] \t Loss: 0.3694225251674652\n",
      "Train Epoch: 4 [23040/60032 (38.37953091684435%)] \t Loss: 0.3750835955142975\n",
      "Train Epoch: 4 [24960/60032 (41.57782515991471%)] \t Loss: 0.37244901061058044\n",
      "Train Epoch: 4 [26880/60032 (44.776119402985074%)] \t Loss: 0.286194384098053\n",
      "Train Epoch: 4 [28800/60032 (47.97441364605544%)] \t Loss: 0.4524414539337158\n",
      "Train Epoch: 4 [30720/60032 (51.172707889125796%)] \t Loss: 0.24584181606769562\n",
      "Train Epoch: 4 [32640/60032 (54.37100213219616%)] \t Loss: 0.28444766998291016\n",
      "Train Epoch: 4 [34560/60032 (57.569296375266525%)] \t Loss: 0.22051136195659637\n",
      "Train Epoch: 4 [36480/60032 (60.76759061833689%)] \t Loss: 0.31226763129234314\n",
      "Train Epoch: 4 [38400/60032 (63.96588486140725%)] \t Loss: 0.2974189221858978\n",
      "Train Epoch: 4 [40320/60032 (67.16417910447761%)] \t Loss: 0.24012809991836548\n",
      "Train Epoch: 4 [42240/60032 (70.36247334754798%)] \t Loss: 0.2650095820426941\n",
      "Train Epoch: 4 [44160/60032 (73.56076759061834%)] \t Loss: 0.41899678111076355\n",
      "Train Epoch: 4 [46080/60032 (76.7590618336887%)] \t Loss: 0.34879761934280396\n",
      "Train Epoch: 4 [48000/60032 (79.95735607675905%)] \t Loss: 0.311164915561676\n",
      "Train Epoch: 4 [49920/60032 (83.15565031982942%)] \t Loss: 0.3179922103881836\n",
      "Train Epoch: 4 [51840/60032 (86.35394456289978%)] \t Loss: 0.35576575994491577\n",
      "Train Epoch: 4 [53760/60032 (89.55223880597015%)] \t Loss: 0.22804629802703857\n",
      "Train Epoch: 4 [55680/60032 (92.75053304904051%)] \t Loss: 0.1772371381521225\n",
      "Train Epoch: 4 [57600/60032 (95.94882729211088%)] \t Loss: 0.43359845876693726\n",
      "Train Epoch: 4 [59520/60032 (99.14712153518124%)] \t Loss: 0.13239413499832153\n",
      "\n",
      "Test set: Average loss: 0.1078, Accuracy: 9666/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60032 (0.0%)] \t Loss: 0.27267712354660034\n",
      "Train Epoch: 5 [1920/60032 (3.1982942430703623%)] \t Loss: 0.4138072431087494\n",
      "Train Epoch: 5 [3840/60032 (6.3965884861407245%)] \t Loss: 0.21938297152519226\n",
      "Train Epoch: 5 [5760/60032 (9.594882729211088%)] \t Loss: 0.4559004604816437\n",
      "Train Epoch: 5 [7680/60032 (12.793176972281449%)] \t Loss: 0.16330818831920624\n",
      "Train Epoch: 5 [9600/60032 (15.991471215351812%)] \t Loss: 0.29054224491119385\n",
      "Train Epoch: 5 [11520/60032 (19.189765458422176%)] \t Loss: 0.3222719728946686\n",
      "Train Epoch: 5 [13440/60032 (22.388059701492537%)] \t Loss: 0.22061647474765778\n",
      "Train Epoch: 5 [15360/60032 (25.586353944562898%)] \t Loss: 0.22706174850463867\n",
      "Train Epoch: 5 [17280/60032 (28.784648187633262%)] \t Loss: 0.14606651663780212\n",
      "Train Epoch: 5 [19200/60032 (31.982942430703623%)] \t Loss: 0.5676106810569763\n",
      "Train Epoch: 5 [21120/60032 (35.18123667377399%)] \t Loss: 0.375932902097702\n",
      "Train Epoch: 5 [23040/60032 (38.37953091684435%)] \t Loss: 0.3551614284515381\n",
      "Train Epoch: 5 [24960/60032 (41.57782515991471%)] \t Loss: 0.30392757058143616\n",
      "Train Epoch: 5 [26880/60032 (44.776119402985074%)] \t Loss: 0.25823917984962463\n",
      "Train Epoch: 5 [28800/60032 (47.97441364605544%)] \t Loss: 0.31601786613464355\n",
      "Train Epoch: 5 [30720/60032 (51.172707889125796%)] \t Loss: 0.38720470666885376\n",
      "Train Epoch: 5 [32640/60032 (54.37100213219616%)] \t Loss: 0.28216561675071716\n",
      "Train Epoch: 5 [34560/60032 (57.569296375266525%)] \t Loss: 0.20848515629768372\n",
      "Train Epoch: 5 [36480/60032 (60.76759061833689%)] \t Loss: 0.28839871287345886\n",
      "Train Epoch: 5 [38400/60032 (63.96588486140725%)] \t Loss: 0.2690363824367523\n",
      "Train Epoch: 5 [40320/60032 (67.16417910447761%)] \t Loss: 0.37921708822250366\n",
      "Train Epoch: 5 [42240/60032 (70.36247334754798%)] \t Loss: 0.29468268156051636\n",
      "Train Epoch: 5 [44160/60032 (73.56076759061834%)] \t Loss: 0.3086380958557129\n",
      "Train Epoch: 5 [46080/60032 (76.7590618336887%)] \t Loss: 0.11324639618396759\n",
      "Train Epoch: 5 [48000/60032 (79.95735607675905%)] \t Loss: 0.23299375176429749\n",
      "Train Epoch: 5 [49920/60032 (83.15565031982942%)] \t Loss: 0.3733636736869812\n",
      "Train Epoch: 5 [51840/60032 (86.35394456289978%)] \t Loss: 0.31181275844573975\n",
      "Train Epoch: 5 [53760/60032 (89.55223880597015%)] \t Loss: 0.27247607707977295\n",
      "Train Epoch: 5 [55680/60032 (92.75053304904051%)] \t Loss: 0.1644023358821869\n",
      "Train Epoch: 5 [57600/60032 (95.94882729211088%)] \t Loss: 0.26045018434524536\n",
      "Train Epoch: 5 [59520/60032 (99.14712153518124%)] \t Loss: 0.3923179805278778\n",
      "\n",
      "Test set: Average loss: 0.0944, Accuracy: 9713/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60032 (0.0%)] \t Loss: 0.3096686005592346\n",
      "Train Epoch: 6 [1920/60032 (3.1982942430703623%)] \t Loss: 0.15846383571624756\n",
      "Train Epoch: 6 [3840/60032 (6.3965884861407245%)] \t Loss: 0.3644202649593353\n",
      "Train Epoch: 6 [5760/60032 (9.594882729211088%)] \t Loss: 0.24886362254619598\n",
      "Train Epoch: 6 [7680/60032 (12.793176972281449%)] \t Loss: 0.20639364421367645\n",
      "Train Epoch: 6 [9600/60032 (15.991471215351812%)] \t Loss: 0.5715509057044983\n",
      "Train Epoch: 6 [11520/60032 (19.189765458422176%)] \t Loss: 0.15847939252853394\n",
      "Train Epoch: 6 [13440/60032 (22.388059701492537%)] \t Loss: 0.18392185866832733\n",
      "Train Epoch: 6 [15360/60032 (25.586353944562898%)] \t Loss: 0.19500337541103363\n",
      "Train Epoch: 6 [17280/60032 (28.784648187633262%)] \t Loss: 0.3152282238006592\n",
      "Train Epoch: 6 [19200/60032 (31.982942430703623%)] \t Loss: 0.3065022826194763\n",
      "Train Epoch: 6 [21120/60032 (35.18123667377399%)] \t Loss: 0.30393579602241516\n",
      "Train Epoch: 6 [23040/60032 (38.37953091684435%)] \t Loss: 0.3287326693534851\n",
      "Train Epoch: 6 [24960/60032 (41.57782515991471%)] \t Loss: 0.3784729540348053\n",
      "Train Epoch: 6 [26880/60032 (44.776119402985074%)] \t Loss: 0.334989994764328\n",
      "Train Epoch: 6 [28800/60032 (47.97441364605544%)] \t Loss: 0.14278271794319153\n",
      "Train Epoch: 6 [30720/60032 (51.172707889125796%)] \t Loss: 0.25073087215423584\n",
      "Train Epoch: 6 [32640/60032 (54.37100213219616%)] \t Loss: 0.2639176845550537\n",
      "Train Epoch: 6 [34560/60032 (57.569296375266525%)] \t Loss: 0.23910841345787048\n",
      "Train Epoch: 6 [36480/60032 (60.76759061833689%)] \t Loss: 0.17485281825065613\n",
      "Train Epoch: 6 [38400/60032 (63.96588486140725%)] \t Loss: 0.2323673665523529\n",
      "Train Epoch: 6 [40320/60032 (67.16417910447761%)] \t Loss: 0.3666287064552307\n",
      "Train Epoch: 6 [42240/60032 (70.36247334754798%)] \t Loss: 0.16361859440803528\n",
      "Train Epoch: 6 [44160/60032 (73.56076759061834%)] \t Loss: 0.3150913715362549\n",
      "Train Epoch: 6 [46080/60032 (76.7590618336887%)] \t Loss: 0.18741345405578613\n",
      "Train Epoch: 6 [48000/60032 (79.95735607675905%)] \t Loss: 0.3370194733142853\n",
      "Train Epoch: 6 [49920/60032 (83.15565031982942%)] \t Loss: 0.3086278736591339\n",
      "Train Epoch: 6 [51840/60032 (86.35394456289978%)] \t Loss: 0.19902284443378448\n",
      "Train Epoch: 6 [53760/60032 (89.55223880597015%)] \t Loss: 0.14986556768417358\n",
      "Train Epoch: 6 [55680/60032 (92.75053304904051%)] \t Loss: 0.10293539613485336\n",
      "Train Epoch: 6 [57600/60032 (95.94882729211088%)] \t Loss: 0.22062301635742188\n",
      "Train Epoch: 6 [59520/60032 (99.14712153518124%)] \t Loss: 0.30949118733406067\n",
      "\n",
      "Test set: Average loss: 0.0854, Accuracy: 9733/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60032 (0.0%)] \t Loss: 0.3212735056877136\n",
      "Train Epoch: 7 [1920/60032 (3.1982942430703623%)] \t Loss: 0.16743290424346924\n",
      "Train Epoch: 7 [3840/60032 (6.3965884861407245%)] \t Loss: 0.3077911138534546\n",
      "Train Epoch: 7 [5760/60032 (9.594882729211088%)] \t Loss: 0.2866877317428589\n",
      "Train Epoch: 7 [7680/60032 (12.793176972281449%)] \t Loss: 0.19123327732086182\n",
      "Train Epoch: 7 [9600/60032 (15.991471215351812%)] \t Loss: 0.21441073715686798\n",
      "Train Epoch: 7 [11520/60032 (19.189765458422176%)] \t Loss: 0.24733956158161163\n",
      "Train Epoch: 7 [13440/60032 (22.388059701492537%)] \t Loss: 0.3573141098022461\n",
      "Train Epoch: 7 [15360/60032 (25.586353944562898%)] \t Loss: 0.2349783033132553\n",
      "Train Epoch: 7 [17280/60032 (28.784648187633262%)] \t Loss: 0.11379507184028625\n",
      "Train Epoch: 7 [19200/60032 (31.982942430703623%)] \t Loss: 0.3337045907974243\n",
      "Train Epoch: 7 [21120/60032 (35.18123667377399%)] \t Loss: 0.2373967170715332\n",
      "Train Epoch: 7 [23040/60032 (38.37953091684435%)] \t Loss: 0.22912611067295074\n",
      "Train Epoch: 7 [24960/60032 (41.57782515991471%)] \t Loss: 0.3339919447898865\n",
      "Train Epoch: 7 [26880/60032 (44.776119402985074%)] \t Loss: 0.36442825198173523\n",
      "Train Epoch: 7 [28800/60032 (47.97441364605544%)] \t Loss: 0.26700377464294434\n",
      "Train Epoch: 7 [30720/60032 (51.172707889125796%)] \t Loss: 0.21413902938365936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [32640/60032 (54.37100213219616%)] \t Loss: 0.16506671905517578\n",
      "Train Epoch: 7 [34560/60032 (57.569296375266525%)] \t Loss: 0.20389318466186523\n",
      "Train Epoch: 7 [36480/60032 (60.76759061833689%)] \t Loss: 0.2014172077178955\n",
      "Train Epoch: 7 [38400/60032 (63.96588486140725%)] \t Loss: 0.11400559544563293\n",
      "Train Epoch: 7 [40320/60032 (67.16417910447761%)] \t Loss: 0.07432058453559875\n",
      "Train Epoch: 7 [42240/60032 (70.36247334754798%)] \t Loss: 0.18154758214950562\n",
      "Train Epoch: 7 [44160/60032 (73.56076759061834%)] \t Loss: 0.1419028639793396\n",
      "Train Epoch: 7 [46080/60032 (76.7590618336887%)] \t Loss: 0.23125982284545898\n",
      "Train Epoch: 7 [48000/60032 (79.95735607675905%)] \t Loss: 0.25147390365600586\n",
      "Train Epoch: 7 [49920/60032 (83.15565031982942%)] \t Loss: 0.16979151964187622\n",
      "Train Epoch: 7 [51840/60032 (86.35394456289978%)] \t Loss: 0.2923412621021271\n",
      "Train Epoch: 7 [53760/60032 (89.55223880597015%)] \t Loss: 0.2673073410987854\n",
      "Train Epoch: 7 [55680/60032 (92.75053304904051%)] \t Loss: 0.1763361543416977\n",
      "Train Epoch: 7 [57600/60032 (95.94882729211088%)] \t Loss: 0.15033620595932007\n",
      "Train Epoch: 7 [59520/60032 (99.14712153518124%)] \t Loss: 0.138101726770401\n",
      "\n",
      "Test set: Average loss: 0.0775, Accuracy: 9755/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60032 (0.0%)] \t Loss: 0.1644098460674286\n",
      "Train Epoch: 8 [1920/60032 (3.1982942430703623%)] \t Loss: 0.20801697671413422\n",
      "Train Epoch: 8 [3840/60032 (6.3965884861407245%)] \t Loss: 0.16924026608467102\n",
      "Train Epoch: 8 [5760/60032 (9.594882729211088%)] \t Loss: 0.20693427324295044\n",
      "Train Epoch: 8 [7680/60032 (12.793176972281449%)] \t Loss: 0.13983140885829926\n",
      "Train Epoch: 8 [9600/60032 (15.991471215351812%)] \t Loss: 0.276242196559906\n",
      "Train Epoch: 8 [11520/60032 (19.189765458422176%)] \t Loss: 0.1428164541721344\n",
      "Train Epoch: 8 [13440/60032 (22.388059701492537%)] \t Loss: 0.1949734091758728\n",
      "Train Epoch: 8 [15360/60032 (25.586353944562898%)] \t Loss: 0.11316249519586563\n",
      "Train Epoch: 8 [17280/60032 (28.784648187633262%)] \t Loss: 0.3636668026447296\n",
      "Train Epoch: 8 [19200/60032 (31.982942430703623%)] \t Loss: 0.05708923563361168\n",
      "Train Epoch: 8 [21120/60032 (35.18123667377399%)] \t Loss: 0.24947868287563324\n",
      "Train Epoch: 8 [23040/60032 (38.37953091684435%)] \t Loss: 0.3868447542190552\n",
      "Train Epoch: 8 [24960/60032 (41.57782515991471%)] \t Loss: 0.28389179706573486\n",
      "Train Epoch: 8 [26880/60032 (44.776119402985074%)] \t Loss: 0.23682676255702972\n",
      "Train Epoch: 8 [28800/60032 (47.97441364605544%)] \t Loss: 0.15597748756408691\n",
      "Train Epoch: 8 [30720/60032 (51.172707889125796%)] \t Loss: 0.16414642333984375\n",
      "Train Epoch: 8 [32640/60032 (54.37100213219616%)] \t Loss: 0.17437388002872467\n",
      "Train Epoch: 8 [34560/60032 (57.569296375266525%)] \t Loss: 0.2780548334121704\n",
      "Train Epoch: 8 [36480/60032 (60.76759061833689%)] \t Loss: 0.3234440088272095\n",
      "Train Epoch: 8 [38400/60032 (63.96588486140725%)] \t Loss: 0.23575401306152344\n",
      "Train Epoch: 8 [40320/60032 (67.16417910447761%)] \t Loss: 0.14011141657829285\n",
      "Train Epoch: 8 [42240/60032 (70.36247334754798%)] \t Loss: 0.15856321156024933\n",
      "Train Epoch: 8 [44160/60032 (73.56076759061834%)] \t Loss: 0.14064675569534302\n",
      "Train Epoch: 8 [46080/60032 (76.7590618336887%)] \t Loss: 0.16384193301200867\n",
      "Train Epoch: 8 [48000/60032 (79.95735607675905%)] \t Loss: 0.43595370650291443\n",
      "Train Epoch: 8 [49920/60032 (83.15565031982942%)] \t Loss: 0.21180561184883118\n",
      "Train Epoch: 8 [51840/60032 (86.35394456289978%)] \t Loss: 0.11367782950401306\n",
      "Train Epoch: 8 [53760/60032 (89.55223880597015%)] \t Loss: 0.3474804759025574\n",
      "Train Epoch: 8 [55680/60032 (92.75053304904051%)] \t Loss: 0.13935256004333496\n",
      "Train Epoch: 8 [57600/60032 (95.94882729211088%)] \t Loss: 0.09992174059152603\n",
      "Train Epoch: 8 [59520/60032 (99.14712153518124%)] \t Loss: 0.28897783160209656\n",
      "\n",
      "Test set: Average loss: 0.0723, Accuracy: 9774/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60032 (0.0%)] \t Loss: 0.2694222331047058\n",
      "Train Epoch: 9 [1920/60032 (3.1982942430703623%)] \t Loss: 0.18327400088310242\n",
      "Train Epoch: 9 [3840/60032 (6.3965884861407245%)] \t Loss: 0.1728847622871399\n",
      "Train Epoch: 9 [5760/60032 (9.594882729211088%)] \t Loss: 0.08695491403341293\n",
      "Train Epoch: 9 [7680/60032 (12.793176972281449%)] \t Loss: 0.21718904376029968\n",
      "Train Epoch: 9 [9600/60032 (15.991471215351812%)] \t Loss: 0.3974912464618683\n",
      "Train Epoch: 9 [11520/60032 (19.189765458422176%)] \t Loss: 0.1866673231124878\n",
      "Train Epoch: 9 [13440/60032 (22.388059701492537%)] \t Loss: 0.12646879255771637\n",
      "Train Epoch: 9 [15360/60032 (25.586353944562898%)] \t Loss: 0.26117920875549316\n",
      "Train Epoch: 9 [17280/60032 (28.784648187633262%)] \t Loss: 0.1120598167181015\n",
      "Train Epoch: 9 [19200/60032 (31.982942430703623%)] \t Loss: 0.35205310583114624\n",
      "Train Epoch: 9 [21120/60032 (35.18123667377399%)] \t Loss: 0.23993809521198273\n",
      "Train Epoch: 9 [23040/60032 (38.37953091684435%)] \t Loss: 0.24943630397319794\n",
      "Train Epoch: 9 [24960/60032 (41.57782515991471%)] \t Loss: 0.21597720682621002\n",
      "Train Epoch: 9 [26880/60032 (44.776119402985074%)] \t Loss: 0.1464906930923462\n",
      "Train Epoch: 9 [28800/60032 (47.97441364605544%)] \t Loss: 0.11557826399803162\n",
      "Train Epoch: 9 [30720/60032 (51.172707889125796%)] \t Loss: 0.18341222405433655\n",
      "Train Epoch: 9 [32640/60032 (54.37100213219616%)] \t Loss: 0.2329808622598648\n",
      "Train Epoch: 9 [34560/60032 (57.569296375266525%)] \t Loss: 0.10323269665241241\n",
      "Train Epoch: 9 [36480/60032 (60.76759061833689%)] \t Loss: 0.10487943887710571\n",
      "Train Epoch: 9 [38400/60032 (63.96588486140725%)] \t Loss: 0.23792843520641327\n",
      "Train Epoch: 9 [40320/60032 (67.16417910447761%)] \t Loss: 0.1654537320137024\n",
      "Train Epoch: 9 [42240/60032 (70.36247334754798%)] \t Loss: 0.2876255512237549\n",
      "Train Epoch: 9 [44160/60032 (73.56076759061834%)] \t Loss: 0.1641981452703476\n",
      "Train Epoch: 9 [46080/60032 (76.7590618336887%)] \t Loss: 0.2682405710220337\n",
      "Train Epoch: 9 [48000/60032 (79.95735607675905%)] \t Loss: 0.2735682725906372\n",
      "Train Epoch: 9 [49920/60032 (83.15565031982942%)] \t Loss: 0.13134491443634033\n",
      "Train Epoch: 9 [51840/60032 (86.35394456289978%)] \t Loss: 0.2913643717765808\n",
      "Train Epoch: 9 [53760/60032 (89.55223880597015%)] \t Loss: 0.24852843582630157\n",
      "Train Epoch: 9 [55680/60032 (92.75053304904051%)] \t Loss: 0.2280394434928894\n",
      "Train Epoch: 9 [57600/60032 (95.94882729211088%)] \t Loss: 0.267821729183197\n",
      "Train Epoch: 9 [59520/60032 (99.14712153518124%)] \t Loss: 0.14929184317588806\n",
      "\n",
      "Test set: Average loss: 0.0684, Accuracy: 9790/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60032 (0.0%)] \t Loss: 0.26175007224082947\n",
      "Train Epoch: 10 [1920/60032 (3.1982942430703623%)] \t Loss: 0.2073897421360016\n",
      "Train Epoch: 10 [3840/60032 (6.3965884861407245%)] \t Loss: 0.16913586854934692\n",
      "Train Epoch: 10 [5760/60032 (9.594882729211088%)] \t Loss: 0.21260586380958557\n",
      "Train Epoch: 10 [7680/60032 (12.793176972281449%)] \t Loss: 0.2986742854118347\n",
      "Train Epoch: 10 [9600/60032 (15.991471215351812%)] \t Loss: 0.15383629500865936\n",
      "Train Epoch: 10 [11520/60032 (19.189765458422176%)] \t Loss: 0.2014758586883545\n",
      "Train Epoch: 10 [13440/60032 (22.388059701492537%)] \t Loss: 0.106425940990448\n",
      "Train Epoch: 10 [15360/60032 (25.586353944562898%)] \t Loss: 0.16035684943199158\n",
      "Train Epoch: 10 [17280/60032 (28.784648187633262%)] \t Loss: 0.14094769954681396\n",
      "Train Epoch: 10 [19200/60032 (31.982942430703623%)] \t Loss: 0.24911198019981384\n",
      "Train Epoch: 10 [21120/60032 (35.18123667377399%)] \t Loss: 0.2004336714744568\n",
      "Train Epoch: 10 [23040/60032 (38.37953091684435%)] \t Loss: 0.14710061252117157\n",
      "Train Epoch: 10 [24960/60032 (41.57782515991471%)] \t Loss: 0.1202475056052208\n",
      "Train Epoch: 10 [26880/60032 (44.776119402985074%)] \t Loss: 0.3115328550338745\n",
      "Train Epoch: 10 [28800/60032 (47.97441364605544%)] \t Loss: 0.15839526057243347\n",
      "Train Epoch: 10 [30720/60032 (51.172707889125796%)] \t Loss: 0.12906581163406372\n",
      "Train Epoch: 10 [32640/60032 (54.37100213219616%)] \t Loss: 0.2271949201822281\n",
      "Train Epoch: 10 [34560/60032 (57.569296375266525%)] \t Loss: 0.16948309540748596\n",
      "Train Epoch: 10 [36480/60032 (60.76759061833689%)] \t Loss: 0.27906984090805054\n",
      "Train Epoch: 10 [38400/60032 (63.96588486140725%)] \t Loss: 0.36667919158935547\n",
      "Train Epoch: 10 [40320/60032 (67.16417910447761%)] \t Loss: 0.16330018639564514\n",
      "Train Epoch: 10 [42240/60032 (70.36247334754798%)] \t Loss: 0.07566165179014206\n",
      "Train Epoch: 10 [44160/60032 (73.56076759061834%)] \t Loss: 0.1831781417131424\n",
      "Train Epoch: 10 [46080/60032 (76.7590618336887%)] \t Loss: 0.2698932886123657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [48000/60032 (79.95735607675905%)] \t Loss: 0.12986382842063904\n",
      "Train Epoch: 10 [49920/60032 (83.15565031982942%)] \t Loss: 0.24955178797245026\n",
      "Train Epoch: 10 [51840/60032 (86.35394456289978%)] \t Loss: 0.12508250772953033\n",
      "Train Epoch: 10 [53760/60032 (89.55223880597015%)] \t Loss: 0.18662652373313904\n",
      "Train Epoch: 10 [55680/60032 (92.75053304904051%)] \t Loss: 0.1405729055404663\n",
      "Train Epoch: 10 [57600/60032 (95.94882729211088%)] \t Loss: 0.31665992736816406\n",
      "Train Epoch: 10 [59520/60032 (99.14712153518124%)] \t Loss: 0.05486259609460831\n",
      "\n",
      "Test set: Average loss: 0.0652, Accuracy: 9796/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01) \n",
    "epoch = 10\n",
    "for epoch in range(1, epoch + 1):\n",
    "    train(model, federated_train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)\n",
    "\n",
    "th.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Digit = tensor([[3]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f98a0a1d2e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[1]\n",
    "# img = img.view(1, 784).float()\n",
    "img = img.view(1,1,28,28).to(device)\n",
    "with th.no_grad():\n",
    "    output = model(img)\n",
    "\n",
    "pred = output.argmax(1, keepdim = True)\n",
    "print(\"Predicted Digit =\", pred.data)\n",
    "plt.imshow(img.view(28, 28).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sy.BaseDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
