{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "# mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import syft as sy\n",
    "\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:trusted_agg #objects:0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "trusted_agg = sy.VirtualWorker(hook, id = \"trusted_agg\")\n",
    "\n",
    "bob.clear_objects()\n",
    "alice.clear_objects()\n",
    "trusted_agg.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])).federate((bob, alice)), \n",
    "                                                batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = th.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bob_train_dataset = sy.BaseDataset(train_data[:train_idx], train_labels[:train_idx]).send(bob)\n",
    "# bob_test_dataset = sy.BaseDataset(test_data[:test_idx], test_labels[:test_idx]).send(bob)\n",
    "\n",
    "# alice_train_dataset = sy.BaseDataset(train_data[train_idx:], train_labels[train_idx:]).send(alice)\n",
    "# alice_test_dataset = sy.BaseDataset(test_data[test_idx:], test_labels[test_idx:]).send(alice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_dataset = sy.FederatedDataset([bob_train_dataset, alice_train_dataset])\n",
    "# federated_test_dataset = sy.FederatedDataset([bob_test_dataset, alice_test_dataset])\n",
    "\n",
    "# federated_train_dataloader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size = 64)\n",
    "# federated_test_dataloader = sy.FederatedDataLoader(federated_test_dataset, shuffle=True, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, federate_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(federate_train_loader):\n",
    "        model.send(data.location)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get()\n",
    "        if batch_idx % 10 == 0:\n",
    "            loss = loss.get()\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx*64}/{len(federate_train_loader)*64} ({100. * batch_idx / len(federated_train_loader)}%)] \\t Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with th.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction= 'sum').item() #sum up batch loss\n",
    "            pred = output.argmax(1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60032 (0.0%)] \t Loss: 0.5493183732032776\n",
      "Train Epoch: 1 [640/60032 (1.0660980810234542%)] \t Loss: 0.6795970797538757\n",
      "Train Epoch: 1 [1280/60032 (2.1321961620469083%)] \t Loss: 0.856945276260376\n",
      "Train Epoch: 1 [1920/60032 (3.1982942430703623%)] \t Loss: 0.6018005013465881\n",
      "Train Epoch: 1 [2560/60032 (4.264392324093817%)] \t Loss: 0.5160875916481018\n",
      "Train Epoch: 1 [3200/60032 (5.330490405117271%)] \t Loss: 0.5883960723876953\n",
      "Train Epoch: 1 [3840/60032 (6.3965884861407245%)] \t Loss: 0.9034500122070312\n",
      "Train Epoch: 1 [4480/60032 (7.462686567164179%)] \t Loss: 0.7067348957061768\n",
      "Train Epoch: 1 [5120/60032 (8.528784648187633%)] \t Loss: 0.6554229259490967\n",
      "Train Epoch: 1 [5760/60032 (9.594882729211088%)] \t Loss: 0.4344828128814697\n",
      "Train Epoch: 1 [6400/60032 (10.660980810234541%)] \t Loss: 0.6617513298988342\n",
      "Train Epoch: 1 [7040/60032 (11.727078891257996%)] \t Loss: 0.5518676042556763\n",
      "Train Epoch: 1 [7680/60032 (12.793176972281449%)] \t Loss: 0.7054015398025513\n",
      "Train Epoch: 1 [8320/60032 (13.859275053304904%)] \t Loss: 0.9055043458938599\n",
      "Train Epoch: 1 [8960/60032 (14.925373134328359%)] \t Loss: 0.5672898888587952\n",
      "Train Epoch: 1 [9600/60032 (15.991471215351812%)] \t Loss: 0.5421259999275208\n",
      "Train Epoch: 1 [10240/60032 (17.057569296375267%)] \t Loss: 0.5398743152618408\n",
      "Train Epoch: 1 [10880/60032 (18.12366737739872%)] \t Loss: 0.48938560485839844\n",
      "Train Epoch: 1 [11520/60032 (19.189765458422176%)] \t Loss: 0.3923293352127075\n",
      "Train Epoch: 1 [12160/60032 (20.255863539445627%)] \t Loss: 0.47526684403419495\n",
      "Train Epoch: 1 [12800/60032 (21.321961620469082%)] \t Loss: 0.7050414085388184\n",
      "Train Epoch: 1 [13440/60032 (22.388059701492537%)] \t Loss: 0.37124109268188477\n",
      "Train Epoch: 1 [14080/60032 (23.454157782515992%)] \t Loss: 0.49237579107284546\n",
      "Train Epoch: 1 [14720/60032 (24.520255863539447%)] \t Loss: 0.5665345191955566\n",
      "Train Epoch: 1 [15360/60032 (25.586353944562898%)] \t Loss: 0.7679954171180725\n",
      "Train Epoch: 1 [16000/60032 (26.652452025586353%)] \t Loss: 0.4201383590698242\n",
      "Train Epoch: 1 [16640/60032 (27.718550106609808%)] \t Loss: 0.6412627100944519\n",
      "Train Epoch: 1 [17280/60032 (28.784648187633262%)] \t Loss: 0.536858320236206\n",
      "Train Epoch: 1 [17920/60032 (29.850746268656717%)] \t Loss: 0.7403974533081055\n",
      "Train Epoch: 1 [18560/60032 (30.916844349680172%)] \t Loss: 0.537417471408844\n",
      "Train Epoch: 1 [19200/60032 (31.982942430703623%)] \t Loss: 0.6423410177230835\n",
      "Train Epoch: 1 [19840/60032 (33.04904051172708%)] \t Loss: 0.3345581591129303\n",
      "Train Epoch: 1 [20480/60032 (34.11513859275053%)] \t Loss: 0.45028191804885864\n",
      "Train Epoch: 1 [21120/60032 (35.18123667377399%)] \t Loss: 0.5169636011123657\n",
      "Train Epoch: 1 [21760/60032 (36.24733475479744%)] \t Loss: 0.3689979910850525\n",
      "Train Epoch: 1 [22400/60032 (37.3134328358209%)] \t Loss: 0.3939054012298584\n",
      "Train Epoch: 1 [23040/60032 (38.37953091684435%)] \t Loss: 0.353584885597229\n",
      "Train Epoch: 1 [23680/60032 (39.44562899786781%)] \t Loss: 0.5534343719482422\n",
      "Train Epoch: 1 [24320/60032 (40.511727078891255%)] \t Loss: 0.7324015498161316\n",
      "Train Epoch: 1 [24960/60032 (41.57782515991471%)] \t Loss: 0.3354867398738861\n",
      "Train Epoch: 1 [25600/60032 (42.643923240938165%)] \t Loss: 0.6200931072235107\n",
      "Train Epoch: 1 [26240/60032 (43.71002132196162%)] \t Loss: 0.5119492411613464\n",
      "Train Epoch: 1 [26880/60032 (44.776119402985074%)] \t Loss: 0.5337515473365784\n",
      "Train Epoch: 1 [27520/60032 (45.84221748400853%)] \t Loss: 0.7363575100898743\n",
      "Train Epoch: 1 [28160/60032 (46.908315565031984%)] \t Loss: 0.5392850041389465\n",
      "Train Epoch: 1 [28800/60032 (47.97441364605544%)] \t Loss: 0.5125471949577332\n",
      "Train Epoch: 1 [29440/60032 (49.04051172707889%)] \t Loss: 0.501427948474884\n",
      "Train Epoch: 1 [30080/60032 (50.10660980810235%)] \t Loss: 0.42918145656585693\n",
      "Train Epoch: 1 [30720/60032 (51.172707889125796%)] \t Loss: 0.39114612340927124\n",
      "Train Epoch: 1 [31360/60032 (52.23880597014925%)] \t Loss: 0.44408655166625977\n",
      "Train Epoch: 1 [32000/60032 (53.304904051172706%)] \t Loss: 0.4747871458530426\n",
      "Train Epoch: 1 [32640/60032 (54.37100213219616%)] \t Loss: 0.532482385635376\n",
      "Train Epoch: 1 [33280/60032 (55.437100213219615%)] \t Loss: 0.3464515209197998\n",
      "Train Epoch: 1 [33920/60032 (56.50319829424307%)] \t Loss: 0.5247087478637695\n",
      "Train Epoch: 1 [34560/60032 (57.569296375266525%)] \t Loss: 0.38309726119041443\n",
      "Train Epoch: 1 [35200/60032 (58.63539445628998%)] \t Loss: 0.4582139849662781\n",
      "Train Epoch: 1 [35840/60032 (59.701492537313435%)] \t Loss: 0.4579959511756897\n",
      "Train Epoch: 1 [36480/60032 (60.76759061833689%)] \t Loss: 0.26883360743522644\n",
      "Train Epoch: 1 [37120/60032 (61.833688699360344%)] \t Loss: 0.607864260673523\n",
      "Train Epoch: 1 [37760/60032 (62.89978678038379%)] \t Loss: 0.8323617577552795\n",
      "Train Epoch: 1 [38400/60032 (63.96588486140725%)] \t Loss: 0.5363316535949707\n",
      "Train Epoch: 1 [39040/60032 (65.0319829424307%)] \t Loss: 0.5479407906532288\n",
      "Train Epoch: 1 [39680/60032 (66.09808102345416%)] \t Loss: 0.5564455389976501\n",
      "Train Epoch: 1 [40320/60032 (67.16417910447761%)] \t Loss: 0.5401365756988525\n",
      "Train Epoch: 1 [40960/60032 (68.23027718550107%)] \t Loss: 0.3272678554058075\n",
      "Train Epoch: 1 [41600/60032 (69.29637526652452%)] \t Loss: 0.35048431158065796\n",
      "Train Epoch: 1 [42240/60032 (70.36247334754798%)] \t Loss: 0.4001239538192749\n",
      "Train Epoch: 1 [42880/60032 (71.42857142857143%)] \t Loss: 0.5725909471511841\n",
      "Train Epoch: 1 [43520/60032 (72.49466950959489%)] \t Loss: 0.39346328377723694\n",
      "Train Epoch: 1 [44160/60032 (73.56076759061834%)] \t Loss: 0.5326822996139526\n",
      "Train Epoch: 1 [44800/60032 (74.6268656716418%)] \t Loss: 0.43077391386032104\n",
      "Train Epoch: 1 [45440/60032 (75.69296375266525%)] \t Loss: 0.4537806510925293\n",
      "Train Epoch: 1 [46080/60032 (76.7590618336887%)] \t Loss: 0.5391183495521545\n",
      "Train Epoch: 1 [46720/60032 (77.82515991471216%)] \t Loss: 0.44838979840278625\n",
      "Train Epoch: 1 [47360/60032 (78.89125799573561%)] \t Loss: 0.41713809967041016\n",
      "Train Epoch: 1 [48000/60032 (79.95735607675905%)] \t Loss: 0.45300549268722534\n",
      "Train Epoch: 1 [48640/60032 (81.02345415778251%)] \t Loss: 0.25953125953674316\n",
      "Train Epoch: 1 [49280/60032 (82.08955223880596%)] \t Loss: 0.6217715740203857\n",
      "Train Epoch: 1 [49920/60032 (83.15565031982942%)] \t Loss: 0.32764655351638794\n",
      "Train Epoch: 1 [50560/60032 (84.22174840085287%)] \t Loss: 0.38485187292099\n",
      "Train Epoch: 1 [51200/60032 (85.28784648187633%)] \t Loss: 0.39963603019714355\n",
      "Train Epoch: 1 [51840/60032 (86.35394456289978%)] \t Loss: 0.293306827545166\n",
      "Train Epoch: 1 [52480/60032 (87.42004264392324%)] \t Loss: 0.34766945242881775\n",
      "Train Epoch: 1 [53120/60032 (88.4861407249467%)] \t Loss: 0.3704248070716858\n",
      "Train Epoch: 1 [53760/60032 (89.55223880597015%)] \t Loss: 0.8146166801452637\n",
      "Train Epoch: 1 [54400/60032 (90.6183368869936%)] \t Loss: 0.43849584460258484\n",
      "Train Epoch: 1 [55040/60032 (91.68443496801706%)] \t Loss: 0.25100260972976685\n",
      "Train Epoch: 1 [55680/60032 (92.75053304904051%)] \t Loss: 0.5190194249153137\n",
      "Train Epoch: 1 [56320/60032 (93.81663113006397%)] \t Loss: 0.42795851826667786\n",
      "Train Epoch: 1 [56960/60032 (94.88272921108742%)] \t Loss: 0.4430341422557831\n",
      "Train Epoch: 1 [57600/60032 (95.94882729211088%)] \t Loss: 0.5016705989837646\n",
      "Train Epoch: 1 [58240/60032 (97.01492537313433%)] \t Loss: 0.6302497386932373\n",
      "Train Epoch: 1 [58880/60032 (98.08102345415779%)] \t Loss: 0.5565586686134338\n",
      "Train Epoch: 1 [59520/60032 (99.14712153518124%)] \t Loss: 0.3922487497329712\n",
      "\n",
      "Test set: Average loss: 0.1776, Accuracy: 9488/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60032 (0.0%)] \t Loss: 0.5044503211975098\n",
      "Train Epoch: 2 [640/60032 (1.0660980810234542%)] \t Loss: 0.4754317104816437\n",
      "Train Epoch: 2 [1280/60032 (2.1321961620469083%)] \t Loss: 0.44131022691726685\n",
      "Train Epoch: 2 [1920/60032 (3.1982942430703623%)] \t Loss: 0.25112220644950867\n",
      "Train Epoch: 2 [2560/60032 (4.264392324093817%)] \t Loss: 0.4359533190727234\n",
      "Train Epoch: 2 [3200/60032 (5.330490405117271%)] \t Loss: 0.29395338892936707\n",
      "Train Epoch: 2 [3840/60032 (6.3965884861407245%)] \t Loss: 0.5707532167434692\n",
      "Train Epoch: 2 [4480/60032 (7.462686567164179%)] \t Loss: 0.3887806534767151\n",
      "Train Epoch: 2 [5120/60032 (8.528784648187633%)] \t Loss: 0.45641952753067017\n",
      "Train Epoch: 2 [5760/60032 (9.594882729211088%)] \t Loss: 0.5660545229911804\n",
      "Train Epoch: 2 [6400/60032 (10.660980810234541%)] \t Loss: 0.22436781227588654\n",
      "Train Epoch: 2 [7040/60032 (11.727078891257996%)] \t Loss: 0.4243280291557312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [7680/60032 (12.793176972281449%)] \t Loss: 0.6588570475578308\n",
      "Train Epoch: 2 [8320/60032 (13.859275053304904%)] \t Loss: 0.5268580317497253\n",
      "Train Epoch: 2 [8960/60032 (14.925373134328359%)] \t Loss: 0.24381917715072632\n",
      "Train Epoch: 2 [9600/60032 (15.991471215351812%)] \t Loss: 0.4789677858352661\n",
      "Train Epoch: 2 [10240/60032 (17.057569296375267%)] \t Loss: 0.42705070972442627\n",
      "Train Epoch: 2 [10880/60032 (18.12366737739872%)] \t Loss: 0.4165276288986206\n",
      "Train Epoch: 2 [11520/60032 (19.189765458422176%)] \t Loss: 0.7013831734657288\n",
      "Train Epoch: 2 [12160/60032 (20.255863539445627%)] \t Loss: 0.3256555199623108\n",
      "Train Epoch: 2 [12800/60032 (21.321961620469082%)] \t Loss: 0.29518306255340576\n",
      "Train Epoch: 2 [13440/60032 (22.388059701492537%)] \t Loss: 0.45505428314208984\n",
      "Train Epoch: 2 [14080/60032 (23.454157782515992%)] \t Loss: 0.6590161919593811\n",
      "Train Epoch: 2 [14720/60032 (24.520255863539447%)] \t Loss: 0.5553333163261414\n",
      "Train Epoch: 2 [15360/60032 (25.586353944562898%)] \t Loss: 0.3752779960632324\n",
      "Train Epoch: 2 [16000/60032 (26.652452025586353%)] \t Loss: 0.32631993293762207\n",
      "Train Epoch: 2 [16640/60032 (27.718550106609808%)] \t Loss: 0.3178080916404724\n",
      "Train Epoch: 2 [17280/60032 (28.784648187633262%)] \t Loss: 0.5287200212478638\n",
      "Train Epoch: 2 [17920/60032 (29.850746268656717%)] \t Loss: 0.2549970746040344\n",
      "Train Epoch: 2 [18560/60032 (30.916844349680172%)] \t Loss: 0.37002044916152954\n",
      "Train Epoch: 2 [19200/60032 (31.982942430703623%)] \t Loss: 0.30792832374572754\n",
      "Train Epoch: 2 [19840/60032 (33.04904051172708%)] \t Loss: 0.39944517612457275\n",
      "Train Epoch: 2 [20480/60032 (34.11513859275053%)] \t Loss: 0.43062734603881836\n",
      "Train Epoch: 2 [21120/60032 (35.18123667377399%)] \t Loss: 0.38789546489715576\n",
      "Train Epoch: 2 [21760/60032 (36.24733475479744%)] \t Loss: 0.4372074604034424\n",
      "Train Epoch: 2 [22400/60032 (37.3134328358209%)] \t Loss: 0.2923535108566284\n",
      "Train Epoch: 2 [23040/60032 (38.37953091684435%)] \t Loss: 0.50652015209198\n",
      "Train Epoch: 2 [23680/60032 (39.44562899786781%)] \t Loss: 0.5119748711585999\n",
      "Train Epoch: 2 [24320/60032 (40.511727078891255%)] \t Loss: 0.47506824135780334\n",
      "Train Epoch: 2 [24960/60032 (41.57782515991471%)] \t Loss: 0.4515458345413208\n",
      "Train Epoch: 2 [25600/60032 (42.643923240938165%)] \t Loss: 0.4625917077064514\n",
      "Train Epoch: 2 [26240/60032 (43.71002132196162%)] \t Loss: 0.5728614926338196\n",
      "Train Epoch: 2 [26880/60032 (44.776119402985074%)] \t Loss: 0.5972724556922913\n",
      "Train Epoch: 2 [27520/60032 (45.84221748400853%)] \t Loss: 0.4235181212425232\n",
      "Train Epoch: 2 [28160/60032 (46.908315565031984%)] \t Loss: 0.5333387851715088\n",
      "Train Epoch: 2 [28800/60032 (47.97441364605544%)] \t Loss: 0.3052787184715271\n",
      "Train Epoch: 2 [29440/60032 (49.04051172707889%)] \t Loss: 0.3933354616165161\n",
      "Train Epoch: 2 [30080/60032 (50.10660980810235%)] \t Loss: 0.40029725432395935\n",
      "Train Epoch: 2 [30720/60032 (51.172707889125796%)] \t Loss: 0.4379042983055115\n",
      "Train Epoch: 2 [31360/60032 (52.23880597014925%)] \t Loss: 0.5911504030227661\n",
      "Train Epoch: 2 [32000/60032 (53.304904051172706%)] \t Loss: 0.3275584578514099\n",
      "Train Epoch: 2 [32640/60032 (54.37100213219616%)] \t Loss: 0.36848127841949463\n",
      "Train Epoch: 2 [33280/60032 (55.437100213219615%)] \t Loss: 0.31748348474502563\n",
      "Train Epoch: 2 [33920/60032 (56.50319829424307%)] \t Loss: 0.49793654680252075\n",
      "Train Epoch: 2 [34560/60032 (57.569296375266525%)] \t Loss: 0.7562553882598877\n",
      "Train Epoch: 2 [35200/60032 (58.63539445628998%)] \t Loss: 0.3925352096557617\n",
      "Train Epoch: 2 [35840/60032 (59.701492537313435%)] \t Loss: 0.27013805508613586\n",
      "Train Epoch: 2 [36480/60032 (60.76759061833689%)] \t Loss: 0.3008410334587097\n",
      "Train Epoch: 2 [37120/60032 (61.833688699360344%)] \t Loss: 0.46470168232917786\n",
      "Train Epoch: 2 [37760/60032 (62.89978678038379%)] \t Loss: 0.5385584235191345\n",
      "Train Epoch: 2 [38400/60032 (63.96588486140725%)] \t Loss: 0.43439722061157227\n",
      "Train Epoch: 2 [39040/60032 (65.0319829424307%)] \t Loss: 0.3962877690792084\n",
      "Train Epoch: 2 [39680/60032 (66.09808102345416%)] \t Loss: 0.4076135754585266\n",
      "Train Epoch: 2 [40320/60032 (67.16417910447761%)] \t Loss: 0.44846582412719727\n",
      "Train Epoch: 2 [40960/60032 (68.23027718550107%)] \t Loss: 0.4850551187992096\n",
      "Train Epoch: 2 [41600/60032 (69.29637526652452%)] \t Loss: 0.3935176730155945\n",
      "Train Epoch: 2 [42240/60032 (70.36247334754798%)] \t Loss: 0.3212117552757263\n",
      "Train Epoch: 2 [42880/60032 (71.42857142857143%)] \t Loss: 0.6397048830986023\n",
      "Train Epoch: 2 [43520/60032 (72.49466950959489%)] \t Loss: 0.3982432782649994\n",
      "Train Epoch: 2 [44160/60032 (73.56076759061834%)] \t Loss: 0.24831363558769226\n",
      "Train Epoch: 2 [44800/60032 (74.6268656716418%)] \t Loss: 0.5952684879302979\n",
      "Train Epoch: 2 [45440/60032 (75.69296375266525%)] \t Loss: 0.23128554224967957\n",
      "Train Epoch: 2 [46080/60032 (76.7590618336887%)] \t Loss: 0.4699897766113281\n",
      "Train Epoch: 2 [46720/60032 (77.82515991471216%)] \t Loss: 0.31096476316452026\n",
      "Train Epoch: 2 [47360/60032 (78.89125799573561%)] \t Loss: 0.34628868103027344\n",
      "Train Epoch: 2 [48000/60032 (79.95735607675905%)] \t Loss: 0.19851534068584442\n",
      "Train Epoch: 2 [48640/60032 (81.02345415778251%)] \t Loss: 0.5138986110687256\n",
      "Train Epoch: 2 [49280/60032 (82.08955223880596%)] \t Loss: 0.3554866313934326\n",
      "Train Epoch: 2 [49920/60032 (83.15565031982942%)] \t Loss: 0.3415331542491913\n",
      "Train Epoch: 2 [50560/60032 (84.22174840085287%)] \t Loss: 0.24579662084579468\n",
      "Train Epoch: 2 [51200/60032 (85.28784648187633%)] \t Loss: 0.30082881450653076\n",
      "Train Epoch: 2 [51840/60032 (86.35394456289978%)] \t Loss: 0.45386672019958496\n",
      "Train Epoch: 2 [52480/60032 (87.42004264392324%)] \t Loss: 0.32501092553138733\n",
      "Train Epoch: 2 [53120/60032 (88.4861407249467%)] \t Loss: 0.21096819639205933\n",
      "Train Epoch: 2 [53760/60032 (89.55223880597015%)] \t Loss: 0.35632044076919556\n",
      "Train Epoch: 2 [54400/60032 (90.6183368869936%)] \t Loss: 0.6653648614883423\n",
      "Train Epoch: 2 [55040/60032 (91.68443496801706%)] \t Loss: 0.3111412525177002\n",
      "Train Epoch: 2 [55680/60032 (92.75053304904051%)] \t Loss: 0.3992566466331482\n",
      "Train Epoch: 2 [56320/60032 (93.81663113006397%)] \t Loss: 0.5935582518577576\n",
      "Train Epoch: 2 [56960/60032 (94.88272921108742%)] \t Loss: 0.24745076894760132\n",
      "Train Epoch: 2 [57600/60032 (95.94882729211088%)] \t Loss: 0.16142290830612183\n",
      "Train Epoch: 2 [58240/60032 (97.01492537313433%)] \t Loss: 0.39093154668807983\n",
      "Train Epoch: 2 [58880/60032 (98.08102345415779%)] \t Loss: 0.4308265149593353\n",
      "Train Epoch: 2 [59520/60032 (99.14712153518124%)] \t Loss: 0.4030751585960388\n",
      "\n",
      "Test set: Average loss: 0.1351, Accuracy: 9594/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60032 (0.0%)] \t Loss: 0.40783578157424927\n",
      "Train Epoch: 3 [640/60032 (1.0660980810234542%)] \t Loss: 0.1982726752758026\n",
      "Train Epoch: 3 [1280/60032 (2.1321961620469083%)] \t Loss: 0.1412971168756485\n",
      "Train Epoch: 3 [1920/60032 (3.1982942430703623%)] \t Loss: 0.278203547000885\n",
      "Train Epoch: 3 [2560/60032 (4.264392324093817%)] \t Loss: 0.31728416681289673\n",
      "Train Epoch: 3 [3200/60032 (5.330490405117271%)] \t Loss: 0.38105279207229614\n",
      "Train Epoch: 3 [3840/60032 (6.3965884861407245%)] \t Loss: 0.43189337849617004\n",
      "Train Epoch: 3 [4480/60032 (7.462686567164179%)] \t Loss: 0.35886356234550476\n",
      "Train Epoch: 3 [5120/60032 (8.528784648187633%)] \t Loss: 0.555271565914154\n",
      "Train Epoch: 3 [5760/60032 (9.594882729211088%)] \t Loss: 0.2771022319793701\n",
      "Train Epoch: 3 [6400/60032 (10.660980810234541%)] \t Loss: 0.25720342993736267\n",
      "Train Epoch: 3 [7040/60032 (11.727078891257996%)] \t Loss: 0.390031099319458\n",
      "Train Epoch: 3 [7680/60032 (12.793176972281449%)] \t Loss: 0.4521644711494446\n",
      "Train Epoch: 3 [8320/60032 (13.859275053304904%)] \t Loss: 0.43572941422462463\n",
      "Train Epoch: 3 [8960/60032 (14.925373134328359%)] \t Loss: 0.4096377491950989\n",
      "Train Epoch: 3 [9600/60032 (15.991471215351812%)] \t Loss: 0.3162133991718292\n",
      "Train Epoch: 3 [10240/60032 (17.057569296375267%)] \t Loss: 0.21894125640392303\n",
      "Train Epoch: 3 [10880/60032 (18.12366737739872%)] \t Loss: 0.44208401441574097\n",
      "Train Epoch: 3 [11520/60032 (19.189765458422176%)] \t Loss: 0.2670305669307709\n",
      "Train Epoch: 3 [12160/60032 (20.255863539445627%)] \t Loss: 0.4959266483783722\n",
      "Train Epoch: 3 [12800/60032 (21.321961620469082%)] \t Loss: 0.34814903140068054\n",
      "Train Epoch: 3 [13440/60032 (22.388059701492537%)] \t Loss: 0.5576414465904236\n",
      "Train Epoch: 3 [14080/60032 (23.454157782515992%)] \t Loss: 0.4184032082557678\n",
      "Train Epoch: 3 [14720/60032 (24.520255863539447%)] \t Loss: 0.3008175492286682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [15360/60032 (25.586353944562898%)] \t Loss: 0.404274046421051\n",
      "Train Epoch: 3 [16000/60032 (26.652452025586353%)] \t Loss: 0.4639897048473358\n",
      "Train Epoch: 3 [16640/60032 (27.718550106609808%)] \t Loss: 0.8322294354438782\n",
      "Train Epoch: 3 [17280/60032 (28.784648187633262%)] \t Loss: 0.2509915232658386\n",
      "Train Epoch: 3 [17920/60032 (29.850746268656717%)] \t Loss: 0.2150626927614212\n",
      "Train Epoch: 3 [18560/60032 (30.916844349680172%)] \t Loss: 0.23653534054756165\n",
      "Train Epoch: 3 [19200/60032 (31.982942430703623%)] \t Loss: 0.3675850033760071\n",
      "Train Epoch: 3 [19840/60032 (33.04904051172708%)] \t Loss: 0.31141310930252075\n",
      "Train Epoch: 3 [20480/60032 (34.11513859275053%)] \t Loss: 0.21202297508716583\n",
      "Train Epoch: 3 [21120/60032 (35.18123667377399%)] \t Loss: 0.18090030550956726\n",
      "Train Epoch: 3 [21760/60032 (36.24733475479744%)] \t Loss: 0.3136182129383087\n",
      "Train Epoch: 3 [22400/60032 (37.3134328358209%)] \t Loss: 0.4116103947162628\n",
      "Train Epoch: 3 [23040/60032 (38.37953091684435%)] \t Loss: 0.5011206865310669\n",
      "Train Epoch: 3 [23680/60032 (39.44562899786781%)] \t Loss: 0.39044517278671265\n",
      "Train Epoch: 3 [24320/60032 (40.511727078891255%)] \t Loss: 0.2181880623102188\n",
      "Train Epoch: 3 [24960/60032 (41.57782515991471%)] \t Loss: 0.42847391963005066\n",
      "Train Epoch: 3 [25600/60032 (42.643923240938165%)] \t Loss: 0.46086108684539795\n",
      "Train Epoch: 3 [26240/60032 (43.71002132196162%)] \t Loss: 0.2920132279396057\n",
      "Train Epoch: 3 [26880/60032 (44.776119402985074%)] \t Loss: 0.47223734855651855\n",
      "Train Epoch: 3 [27520/60032 (45.84221748400853%)] \t Loss: 0.2647305130958557\n",
      "Train Epoch: 3 [28160/60032 (46.908315565031984%)] \t Loss: 0.3067423403263092\n",
      "Train Epoch: 3 [28800/60032 (47.97441364605544%)] \t Loss: 0.4120727777481079\n",
      "Train Epoch: 3 [29440/60032 (49.04051172707889%)] \t Loss: 0.40093642473220825\n",
      "Train Epoch: 3 [30080/60032 (50.10660980810235%)] \t Loss: 0.23850320279598236\n",
      "Train Epoch: 3 [30720/60032 (51.172707889125796%)] \t Loss: 0.3752080500125885\n",
      "Train Epoch: 3 [31360/60032 (52.23880597014925%)] \t Loss: 0.4532431662082672\n",
      "Train Epoch: 3 [32000/60032 (53.304904051172706%)] \t Loss: 0.3730489909648895\n",
      "Train Epoch: 3 [32640/60032 (54.37100213219616%)] \t Loss: 0.20138099789619446\n",
      "Train Epoch: 3 [33280/60032 (55.437100213219615%)] \t Loss: 0.4992467761039734\n",
      "Train Epoch: 3 [33920/60032 (56.50319829424307%)] \t Loss: 0.3790838122367859\n",
      "Train Epoch: 3 [34560/60032 (57.569296375266525%)] \t Loss: 0.42971286177635193\n",
      "Train Epoch: 3 [35200/60032 (58.63539445628998%)] \t Loss: 0.3183802366256714\n",
      "Train Epoch: 3 [35840/60032 (59.701492537313435%)] \t Loss: 0.3172069489955902\n",
      "Train Epoch: 3 [36480/60032 (60.76759061833689%)] \t Loss: 0.3026663064956665\n",
      "Train Epoch: 3 [37120/60032 (61.833688699360344%)] \t Loss: 0.3091549873352051\n",
      "Train Epoch: 3 [37760/60032 (62.89978678038379%)] \t Loss: 0.28537100553512573\n",
      "Train Epoch: 3 [38400/60032 (63.96588486140725%)] \t Loss: 0.3039851188659668\n",
      "Train Epoch: 3 [39040/60032 (65.0319829424307%)] \t Loss: 0.1966201364994049\n",
      "Train Epoch: 3 [39680/60032 (66.09808102345416%)] \t Loss: 0.41456153988838196\n",
      "Train Epoch: 3 [40320/60032 (67.16417910447761%)] \t Loss: 0.39709603786468506\n",
      "Train Epoch: 3 [40960/60032 (68.23027718550107%)] \t Loss: 0.18909433484077454\n",
      "Train Epoch: 3 [41600/60032 (69.29637526652452%)] \t Loss: 0.19191065430641174\n",
      "Train Epoch: 3 [42240/60032 (70.36247334754798%)] \t Loss: 0.271558552980423\n",
      "Train Epoch: 3 [42880/60032 (71.42857142857143%)] \t Loss: 0.4050588011741638\n",
      "Train Epoch: 3 [43520/60032 (72.49466950959489%)] \t Loss: 0.34671419858932495\n",
      "Train Epoch: 3 [44160/60032 (73.56076759061834%)] \t Loss: 0.22462162375450134\n",
      "Train Epoch: 3 [44800/60032 (74.6268656716418%)] \t Loss: 0.3260214626789093\n",
      "Train Epoch: 3 [45440/60032 (75.69296375266525%)] \t Loss: 0.41372448205947876\n",
      "Train Epoch: 3 [46080/60032 (76.7590618336887%)] \t Loss: 0.16629856824874878\n",
      "Train Epoch: 3 [46720/60032 (77.82515991471216%)] \t Loss: 0.25982174277305603\n",
      "Train Epoch: 3 [47360/60032 (78.89125799573561%)] \t Loss: 0.4425612986087799\n",
      "Train Epoch: 3 [48000/60032 (79.95735607675905%)] \t Loss: 0.15061287581920624\n",
      "Train Epoch: 3 [48640/60032 (81.02345415778251%)] \t Loss: 0.34511739015579224\n",
      "Train Epoch: 3 [49280/60032 (82.08955223880596%)] \t Loss: 0.22424891591072083\n",
      "Train Epoch: 3 [49920/60032 (83.15565031982942%)] \t Loss: 0.37265294790267944\n",
      "Train Epoch: 3 [50560/60032 (84.22174840085287%)] \t Loss: 0.264579713344574\n",
      "Train Epoch: 3 [51200/60032 (85.28784648187633%)] \t Loss: 0.40216493606567383\n",
      "Train Epoch: 3 [51840/60032 (86.35394456289978%)] \t Loss: 0.38020265102386475\n",
      "Train Epoch: 3 [52480/60032 (87.42004264392324%)] \t Loss: 0.49655601382255554\n",
      "Train Epoch: 3 [53120/60032 (88.4861407249467%)] \t Loss: 0.28060975670814514\n",
      "Train Epoch: 3 [53760/60032 (89.55223880597015%)] \t Loss: 0.39630943536758423\n",
      "Train Epoch: 3 [54400/60032 (90.6183368869936%)] \t Loss: 0.3556920289993286\n",
      "Train Epoch: 3 [55040/60032 (91.68443496801706%)] \t Loss: 0.4705355763435364\n",
      "Train Epoch: 3 [55680/60032 (92.75053304904051%)] \t Loss: 0.15372997522354126\n",
      "Train Epoch: 3 [56320/60032 (93.81663113006397%)] \t Loss: 0.6162993311882019\n",
      "Train Epoch: 3 [56960/60032 (94.88272921108742%)] \t Loss: 0.19405019283294678\n",
      "Train Epoch: 3 [57600/60032 (95.94882729211088%)] \t Loss: 0.33194276690483093\n",
      "Train Epoch: 3 [58240/60032 (97.01492537313433%)] \t Loss: 0.24724605679512024\n",
      "Train Epoch: 3 [58880/60032 (98.08102345415779%)] \t Loss: 0.4651070237159729\n",
      "Train Epoch: 3 [59520/60032 (99.14712153518124%)] \t Loss: 0.18503212928771973\n",
      "\n",
      "Test set: Average loss: 0.1143, Accuracy: 9637/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60032 (0.0%)] \t Loss: 0.1860489845275879\n",
      "Train Epoch: 4 [640/60032 (1.0660980810234542%)] \t Loss: 0.5345048904418945\n",
      "Train Epoch: 4 [1280/60032 (2.1321961620469083%)] \t Loss: 0.14423015713691711\n",
      "Train Epoch: 4 [1920/60032 (3.1982942430703623%)] \t Loss: 0.28091907501220703\n",
      "Train Epoch: 4 [2560/60032 (4.264392324093817%)] \t Loss: 0.4348328113555908\n",
      "Train Epoch: 4 [3200/60032 (5.330490405117271%)] \t Loss: 0.48466378450393677\n",
      "Train Epoch: 4 [3840/60032 (6.3965884861407245%)] \t Loss: 0.23086130619049072\n",
      "Train Epoch: 4 [4480/60032 (7.462686567164179%)] \t Loss: 0.3845159113407135\n",
      "Train Epoch: 4 [5120/60032 (8.528784648187633%)] \t Loss: 0.35809993743896484\n",
      "Train Epoch: 4 [5760/60032 (9.594882729211088%)] \t Loss: 0.2501178979873657\n",
      "Train Epoch: 4 [6400/60032 (10.660980810234541%)] \t Loss: 0.3270370364189148\n",
      "Train Epoch: 4 [7040/60032 (11.727078891257996%)] \t Loss: 0.4638898968696594\n",
      "Train Epoch: 4 [7680/60032 (12.793176972281449%)] \t Loss: 0.29934900999069214\n",
      "Train Epoch: 4 [8320/60032 (13.859275053304904%)] \t Loss: 0.2703810930252075\n",
      "Train Epoch: 4 [8960/60032 (14.925373134328359%)] \t Loss: 0.20251986384391785\n",
      "Train Epoch: 4 [9600/60032 (15.991471215351812%)] \t Loss: 0.3242380619049072\n",
      "Train Epoch: 4 [10240/60032 (17.057569296375267%)] \t Loss: 0.26104527711868286\n",
      "Train Epoch: 4 [10880/60032 (18.12366737739872%)] \t Loss: 0.2900942862033844\n",
      "Train Epoch: 4 [11520/60032 (19.189765458422176%)] \t Loss: 0.17723791301250458\n",
      "Train Epoch: 4 [12160/60032 (20.255863539445627%)] \t Loss: 0.42038220167160034\n",
      "Train Epoch: 4 [12800/60032 (21.321961620469082%)] \t Loss: 0.33290135860443115\n",
      "Train Epoch: 4 [13440/60032 (22.388059701492537%)] \t Loss: 0.2980996370315552\n",
      "Train Epoch: 4 [14080/60032 (23.454157782515992%)] \t Loss: 0.1954573541879654\n",
      "Train Epoch: 4 [14720/60032 (24.520255863539447%)] \t Loss: 0.2368481308221817\n",
      "Train Epoch: 4 [15360/60032 (25.586353944562898%)] \t Loss: 0.6109564304351807\n",
      "Train Epoch: 4 [16000/60032 (26.652452025586353%)] \t Loss: 0.292841374874115\n",
      "Train Epoch: 4 [16640/60032 (27.718550106609808%)] \t Loss: 0.25912246108055115\n",
      "Train Epoch: 4 [17280/60032 (28.784648187633262%)] \t Loss: 0.1596158891916275\n",
      "Train Epoch: 4 [17920/60032 (29.850746268656717%)] \t Loss: 0.1926158368587494\n",
      "Train Epoch: 4 [18560/60032 (30.916844349680172%)] \t Loss: 0.1845378279685974\n",
      "Train Epoch: 4 [19200/60032 (31.982942430703623%)] \t Loss: 0.4581151008605957\n",
      "Train Epoch: 4 [19840/60032 (33.04904051172708%)] \t Loss: 0.18496641516685486\n",
      "Train Epoch: 4 [20480/60032 (34.11513859275053%)] \t Loss: 0.2031061053276062\n",
      "Train Epoch: 4 [21120/60032 (35.18123667377399%)] \t Loss: 0.33153533935546875\n",
      "Train Epoch: 4 [21760/60032 (36.24733475479744%)] \t Loss: 0.7839417457580566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [22400/60032 (37.3134328358209%)] \t Loss: 0.3494512140750885\n",
      "Train Epoch: 4 [23040/60032 (38.37953091684435%)] \t Loss: 0.3136310577392578\n",
      "Train Epoch: 4 [23680/60032 (39.44562899786781%)] \t Loss: 0.5544831156730652\n",
      "Train Epoch: 4 [24320/60032 (40.511727078891255%)] \t Loss: 0.35231155157089233\n",
      "Train Epoch: 4 [24960/60032 (41.57782515991471%)] \t Loss: 0.28206682205200195\n",
      "Train Epoch: 4 [25600/60032 (42.643923240938165%)] \t Loss: 0.20724211633205414\n",
      "Train Epoch: 4 [26240/60032 (43.71002132196162%)] \t Loss: 0.2710801362991333\n",
      "Train Epoch: 4 [26880/60032 (44.776119402985074%)] \t Loss: 0.42047184705734253\n",
      "Train Epoch: 4 [27520/60032 (45.84221748400853%)] \t Loss: 0.2985580563545227\n",
      "Train Epoch: 4 [28160/60032 (46.908315565031984%)] \t Loss: 0.18855027854442596\n",
      "Train Epoch: 4 [28800/60032 (47.97441364605544%)] \t Loss: 0.23264040052890778\n",
      "Train Epoch: 4 [29440/60032 (49.04051172707889%)] \t Loss: 0.2870449125766754\n",
      "Train Epoch: 4 [30080/60032 (50.10660980810235%)] \t Loss: 0.3445824086666107\n",
      "Train Epoch: 4 [30720/60032 (51.172707889125796%)] \t Loss: 0.3456879258155823\n",
      "Train Epoch: 4 [31360/60032 (52.23880597014925%)] \t Loss: 0.1946827918291092\n",
      "Train Epoch: 4 [32000/60032 (53.304904051172706%)] \t Loss: 0.20549412071704865\n",
      "Train Epoch: 4 [32640/60032 (54.37100213219616%)] \t Loss: 0.3101431131362915\n",
      "Train Epoch: 4 [33280/60032 (55.437100213219615%)] \t Loss: 0.2054542750120163\n",
      "Train Epoch: 4 [33920/60032 (56.50319829424307%)] \t Loss: 0.24909095466136932\n",
      "Train Epoch: 4 [34560/60032 (57.569296375266525%)] \t Loss: 0.35343074798583984\n",
      "Train Epoch: 4 [35200/60032 (58.63539445628998%)] \t Loss: 0.221986323595047\n",
      "Train Epoch: 4 [35840/60032 (59.701492537313435%)] \t Loss: 0.21964912116527557\n",
      "Train Epoch: 4 [36480/60032 (60.76759061833689%)] \t Loss: 0.40470126271247864\n",
      "Train Epoch: 4 [37120/60032 (61.833688699360344%)] \t Loss: 0.3160795569419861\n",
      "Train Epoch: 4 [37760/60032 (62.89978678038379%)] \t Loss: 0.4458844065666199\n",
      "Train Epoch: 4 [38400/60032 (63.96588486140725%)] \t Loss: 0.3488088548183441\n",
      "Train Epoch: 4 [39040/60032 (65.0319829424307%)] \t Loss: 0.43392109870910645\n",
      "Train Epoch: 4 [39680/60032 (66.09808102345416%)] \t Loss: 0.21157138049602509\n",
      "Train Epoch: 4 [40320/60032 (67.16417910447761%)] \t Loss: 0.24414899945259094\n",
      "Train Epoch: 4 [40960/60032 (68.23027718550107%)] \t Loss: 0.3401162624359131\n",
      "Train Epoch: 4 [41600/60032 (69.29637526652452%)] \t Loss: 0.2039027214050293\n",
      "Train Epoch: 4 [42240/60032 (70.36247334754798%)] \t Loss: 0.22041243314743042\n",
      "Train Epoch: 4 [42880/60032 (71.42857142857143%)] \t Loss: 0.27160248160362244\n",
      "Train Epoch: 4 [43520/60032 (72.49466950959489%)] \t Loss: 0.41138043999671936\n",
      "Train Epoch: 4 [44160/60032 (73.56076759061834%)] \t Loss: 0.24694238603115082\n",
      "Train Epoch: 4 [44800/60032 (74.6268656716418%)] \t Loss: 0.2065492421388626\n",
      "Train Epoch: 4 [45440/60032 (75.69296375266525%)] \t Loss: 0.15310855209827423\n",
      "Train Epoch: 4 [46080/60032 (76.7590618336887%)] \t Loss: 0.37836867570877075\n",
      "Train Epoch: 4 [46720/60032 (77.82515991471216%)] \t Loss: 0.3278579115867615\n",
      "Train Epoch: 4 [47360/60032 (78.89125799573561%)] \t Loss: 0.5114355683326721\n",
      "Train Epoch: 4 [48000/60032 (79.95735607675905%)] \t Loss: 0.33105453848838806\n",
      "Train Epoch: 4 [48640/60032 (81.02345415778251%)] \t Loss: 0.33471816778182983\n",
      "Train Epoch: 4 [49280/60032 (82.08955223880596%)] \t Loss: 0.43758079409599304\n",
      "Train Epoch: 4 [49920/60032 (83.15565031982942%)] \t Loss: 0.11669940501451492\n",
      "Train Epoch: 4 [50560/60032 (84.22174840085287%)] \t Loss: 0.17825213074684143\n",
      "Train Epoch: 4 [51200/60032 (85.28784648187633%)] \t Loss: 0.4364858865737915\n",
      "Train Epoch: 4 [51840/60032 (86.35394456289978%)] \t Loss: 0.378101110458374\n",
      "Train Epoch: 4 [52480/60032 (87.42004264392324%)] \t Loss: 0.19240981340408325\n",
      "Train Epoch: 4 [53120/60032 (88.4861407249467%)] \t Loss: 0.383884459733963\n",
      "Train Epoch: 4 [53760/60032 (89.55223880597015%)] \t Loss: 0.2715374529361725\n",
      "Train Epoch: 4 [54400/60032 (90.6183368869936%)] \t Loss: 0.2586899697780609\n",
      "Train Epoch: 4 [55040/60032 (91.68443496801706%)] \t Loss: 0.24235527217388153\n",
      "Train Epoch: 4 [55680/60032 (92.75053304904051%)] \t Loss: 0.2651711106300354\n",
      "Train Epoch: 4 [56320/60032 (93.81663113006397%)] \t Loss: 0.18577152490615845\n",
      "Train Epoch: 4 [56960/60032 (94.88272921108742%)] \t Loss: 0.3164781332015991\n",
      "Train Epoch: 4 [57600/60032 (95.94882729211088%)] \t Loss: 0.2477930337190628\n",
      "Train Epoch: 4 [58240/60032 (97.01492537313433%)] \t Loss: 0.21368956565856934\n",
      "Train Epoch: 4 [58880/60032 (98.08102345415779%)] \t Loss: 0.2705453336238861\n",
      "Train Epoch: 4 [59520/60032 (99.14712153518124%)] \t Loss: 0.30243179202079773\n",
      "\n",
      "Test set: Average loss: 0.0985, Accuracy: 9695/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60032 (0.0%)] \t Loss: 0.40136826038360596\n",
      "Train Epoch: 5 [640/60032 (1.0660980810234542%)] \t Loss: 0.21649006009101868\n",
      "Train Epoch: 5 [1280/60032 (2.1321961620469083%)] \t Loss: 0.40833085775375366\n",
      "Train Epoch: 5 [1920/60032 (3.1982942430703623%)] \t Loss: 0.5409132838249207\n",
      "Train Epoch: 5 [2560/60032 (4.264392324093817%)] \t Loss: 0.20307686924934387\n",
      "Train Epoch: 5 [3200/60032 (5.330490405117271%)] \t Loss: 0.4230048954486847\n",
      "Train Epoch: 5 [3840/60032 (6.3965884861407245%)] \t Loss: 0.5777186155319214\n",
      "Train Epoch: 5 [4480/60032 (7.462686567164179%)] \t Loss: 0.44011998176574707\n",
      "Train Epoch: 5 [5120/60032 (8.528784648187633%)] \t Loss: 0.27641531825065613\n",
      "Train Epoch: 5 [5760/60032 (9.594882729211088%)] \t Loss: 0.20047950744628906\n",
      "Train Epoch: 5 [6400/60032 (10.660980810234541%)] \t Loss: 0.2202540934085846\n",
      "Train Epoch: 5 [7040/60032 (11.727078891257996%)] \t Loss: 0.17724862694740295\n",
      "Train Epoch: 5 [7680/60032 (12.793176972281449%)] \t Loss: 0.3864322900772095\n",
      "Train Epoch: 5 [8320/60032 (13.859275053304904%)] \t Loss: 0.13597409427165985\n",
      "Train Epoch: 5 [8960/60032 (14.925373134328359%)] \t Loss: 0.26952505111694336\n",
      "Train Epoch: 5 [9600/60032 (15.991471215351812%)] \t Loss: 0.40387624502182007\n",
      "Train Epoch: 5 [10240/60032 (17.057569296375267%)] \t Loss: 0.46641984581947327\n",
      "Train Epoch: 5 [10880/60032 (18.12366737739872%)] \t Loss: 0.25242748856544495\n",
      "Train Epoch: 5 [11520/60032 (19.189765458422176%)] \t Loss: 0.2443407028913498\n",
      "Train Epoch: 5 [12160/60032 (20.255863539445627%)] \t Loss: 0.30304110050201416\n",
      "Train Epoch: 5 [12800/60032 (21.321961620469082%)] \t Loss: 0.1493435502052307\n",
      "Train Epoch: 5 [13440/60032 (22.388059701492537%)] \t Loss: 0.391737163066864\n",
      "Train Epoch: 5 [14080/60032 (23.454157782515992%)] \t Loss: 0.40721437335014343\n",
      "Train Epoch: 5 [14720/60032 (24.520255863539447%)] \t Loss: 0.37506961822509766\n",
      "Train Epoch: 5 [15360/60032 (25.586353944562898%)] \t Loss: 0.20898720622062683\n",
      "Train Epoch: 5 [16000/60032 (26.652452025586353%)] \t Loss: 0.22534848749637604\n",
      "Train Epoch: 5 [16640/60032 (27.718550106609808%)] \t Loss: 0.16427621245384216\n",
      "Train Epoch: 5 [17280/60032 (28.784648187633262%)] \t Loss: 0.2546624541282654\n",
      "Train Epoch: 5 [17920/60032 (29.850746268656717%)] \t Loss: 0.3408418297767639\n",
      "Train Epoch: 5 [18560/60032 (30.916844349680172%)] \t Loss: 0.2375466674566269\n",
      "Train Epoch: 5 [19200/60032 (31.982942430703623%)] \t Loss: 0.3013530373573303\n",
      "Train Epoch: 5 [19840/60032 (33.04904051172708%)] \t Loss: 0.35627835988998413\n",
      "Train Epoch: 5 [20480/60032 (34.11513859275053%)] \t Loss: 0.2842814326286316\n",
      "Train Epoch: 5 [21120/60032 (35.18123667377399%)] \t Loss: 0.22764770686626434\n",
      "Train Epoch: 5 [21760/60032 (36.24733475479744%)] \t Loss: 0.25640377402305603\n",
      "Train Epoch: 5 [22400/60032 (37.3134328358209%)] \t Loss: 0.43398889899253845\n",
      "Train Epoch: 5 [23040/60032 (38.37953091684435%)] \t Loss: 0.2735288143157959\n",
      "Train Epoch: 5 [23680/60032 (39.44562899786781%)] \t Loss: 0.1883257031440735\n",
      "Train Epoch: 5 [24320/60032 (40.511727078891255%)] \t Loss: 0.18483152985572815\n",
      "Train Epoch: 5 [24960/60032 (41.57782515991471%)] \t Loss: 0.30477049946784973\n",
      "Train Epoch: 5 [25600/60032 (42.643923240938165%)] \t Loss: 0.18589702248573303\n",
      "Train Epoch: 5 [26240/60032 (43.71002132196162%)] \t Loss: 0.18434245884418488\n",
      "Train Epoch: 5 [26880/60032 (44.776119402985074%)] \t Loss: 0.28136640787124634\n",
      "Train Epoch: 5 [27520/60032 (45.84221748400853%)] \t Loss: 0.30830806493759155\n",
      "Train Epoch: 5 [28160/60032 (46.908315565031984%)] \t Loss: 0.23692157864570618\n",
      "Train Epoch: 5 [28800/60032 (47.97441364605544%)] \t Loss: 0.289301335811615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [29440/60032 (49.04051172707889%)] \t Loss: 0.2874738276004791\n",
      "Train Epoch: 5 [30080/60032 (50.10660980810235%)] \t Loss: 0.15101918578147888\n",
      "Train Epoch: 5 [30720/60032 (51.172707889125796%)] \t Loss: 0.33131757378578186\n",
      "Train Epoch: 5 [31360/60032 (52.23880597014925%)] \t Loss: 0.17101800441741943\n",
      "Train Epoch: 5 [32000/60032 (53.304904051172706%)] \t Loss: 0.4122413694858551\n",
      "Train Epoch: 5 [32640/60032 (54.37100213219616%)] \t Loss: 0.18504329025745392\n",
      "Train Epoch: 5 [33280/60032 (55.437100213219615%)] \t Loss: 0.2821393609046936\n",
      "Train Epoch: 5 [33920/60032 (56.50319829424307%)] \t Loss: 0.35722115635871887\n",
      "Train Epoch: 5 [34560/60032 (57.569296375266525%)] \t Loss: 0.14648589491844177\n",
      "Train Epoch: 5 [35200/60032 (58.63539445628998%)] \t Loss: 0.13702884316444397\n",
      "Train Epoch: 5 [35840/60032 (59.701492537313435%)] \t Loss: 0.2217128574848175\n",
      "Train Epoch: 5 [36480/60032 (60.76759061833689%)] \t Loss: 0.20891991257667542\n",
      "Train Epoch: 5 [37120/60032 (61.833688699360344%)] \t Loss: 0.3227938711643219\n",
      "Train Epoch: 5 [37760/60032 (62.89978678038379%)] \t Loss: 0.12220382690429688\n",
      "Train Epoch: 5 [38400/60032 (63.96588486140725%)] \t Loss: 0.22810930013656616\n",
      "Train Epoch: 5 [39040/60032 (65.0319829424307%)] \t Loss: 0.501431941986084\n",
      "Train Epoch: 5 [39680/60032 (66.09808102345416%)] \t Loss: 0.33271801471710205\n",
      "Train Epoch: 5 [40320/60032 (67.16417910447761%)] \t Loss: 0.09824297577142715\n",
      "Train Epoch: 5 [40960/60032 (68.23027718550107%)] \t Loss: 0.1865987777709961\n",
      "Train Epoch: 5 [41600/60032 (69.29637526652452%)] \t Loss: 0.3636990785598755\n",
      "Train Epoch: 5 [42240/60032 (70.36247334754798%)] \t Loss: 0.3991956114768982\n",
      "Train Epoch: 5 [42880/60032 (71.42857142857143%)] \t Loss: 0.15011517703533173\n",
      "Train Epoch: 5 [43520/60032 (72.49466950959489%)] \t Loss: 0.2156439572572708\n",
      "Train Epoch: 5 [44160/60032 (73.56076759061834%)] \t Loss: 0.23315712809562683\n",
      "Train Epoch: 5 [44800/60032 (74.6268656716418%)] \t Loss: 0.1030094251036644\n",
      "Train Epoch: 5 [45440/60032 (75.69296375266525%)] \t Loss: 0.43110358715057373\n",
      "Train Epoch: 5 [46080/60032 (76.7590618336887%)] \t Loss: 0.10917451977729797\n",
      "Train Epoch: 5 [46720/60032 (77.82515991471216%)] \t Loss: 0.2119830697774887\n",
      "Train Epoch: 5 [47360/60032 (78.89125799573561%)] \t Loss: 0.2510795295238495\n",
      "Train Epoch: 5 [48000/60032 (79.95735607675905%)] \t Loss: 0.21632413566112518\n",
      "Train Epoch: 5 [48640/60032 (81.02345415778251%)] \t Loss: 0.20111311972141266\n",
      "Train Epoch: 5 [49280/60032 (82.08955223880596%)] \t Loss: 0.2595209777355194\n",
      "Train Epoch: 5 [49920/60032 (83.15565031982942%)] \t Loss: 0.45489081740379333\n",
      "Train Epoch: 5 [50560/60032 (84.22174840085287%)] \t Loss: 0.3612358570098877\n",
      "Train Epoch: 5 [51200/60032 (85.28784648187633%)] \t Loss: 0.26987093687057495\n",
      "Train Epoch: 5 [51840/60032 (86.35394456289978%)] \t Loss: 0.20188644528388977\n",
      "Train Epoch: 5 [52480/60032 (87.42004264392324%)] \t Loss: 0.18900121748447418\n",
      "Train Epoch: 5 [53120/60032 (88.4861407249467%)] \t Loss: 0.22503525018692017\n",
      "Train Epoch: 5 [53760/60032 (89.55223880597015%)] \t Loss: 0.26284295320510864\n",
      "Train Epoch: 5 [54400/60032 (90.6183368869936%)] \t Loss: 0.3503491282463074\n",
      "Train Epoch: 5 [55040/60032 (91.68443496801706%)] \t Loss: 0.1747230887413025\n",
      "Train Epoch: 5 [55680/60032 (92.75053304904051%)] \t Loss: 0.21603119373321533\n",
      "Train Epoch: 5 [56320/60032 (93.81663113006397%)] \t Loss: 0.3254803419113159\n",
      "Train Epoch: 5 [56960/60032 (94.88272921108742%)] \t Loss: 0.19401581585407257\n",
      "Train Epoch: 5 [57600/60032 (95.94882729211088%)] \t Loss: 0.2561311721801758\n",
      "Train Epoch: 5 [58240/60032 (97.01492537313433%)] \t Loss: 0.37730053067207336\n",
      "Train Epoch: 5 [58880/60032 (98.08102345415779%)] \t Loss: 0.29709601402282715\n",
      "Train Epoch: 5 [59520/60032 (99.14712153518124%)] \t Loss: 0.20824387669563293\n",
      "\n",
      "Test set: Average loss: 0.0906, Accuracy: 9700/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60032 (0.0%)] \t Loss: 0.20496182143688202\n",
      "Train Epoch: 6 [640/60032 (1.0660980810234542%)] \t Loss: 0.31168410181999207\n",
      "Train Epoch: 6 [1280/60032 (2.1321961620469083%)] \t Loss: 0.24813532829284668\n",
      "Train Epoch: 6 [1920/60032 (3.1982942430703623%)] \t Loss: 0.23265480995178223\n",
      "Train Epoch: 6 [2560/60032 (4.264392324093817%)] \t Loss: 0.35664817690849304\n",
      "Train Epoch: 6 [3200/60032 (5.330490405117271%)] \t Loss: 0.28086113929748535\n",
      "Train Epoch: 6 [3840/60032 (6.3965884861407245%)] \t Loss: 0.28381142020225525\n",
      "Train Epoch: 6 [4480/60032 (7.462686567164179%)] \t Loss: 0.16339263319969177\n",
      "Train Epoch: 6 [5120/60032 (8.528784648187633%)] \t Loss: 0.1575421541929245\n",
      "Train Epoch: 6 [5760/60032 (9.594882729211088%)] \t Loss: 0.159653902053833\n",
      "Train Epoch: 6 [6400/60032 (10.660980810234541%)] \t Loss: 0.3563794195652008\n",
      "Train Epoch: 6 [7040/60032 (11.727078891257996%)] \t Loss: 0.2912179231643677\n",
      "Train Epoch: 6 [7680/60032 (12.793176972281449%)] \t Loss: 0.61918044090271\n",
      "Train Epoch: 6 [8320/60032 (13.859275053304904%)] \t Loss: 0.28794917464256287\n",
      "Train Epoch: 6 [8960/60032 (14.925373134328359%)] \t Loss: 0.3098165988922119\n",
      "Train Epoch: 6 [9600/60032 (15.991471215351812%)] \t Loss: 0.18917664885520935\n",
      "Train Epoch: 6 [10240/60032 (17.057569296375267%)] \t Loss: 0.2946755886077881\n",
      "Train Epoch: 6 [10880/60032 (18.12366737739872%)] \t Loss: 0.23425835371017456\n",
      "Train Epoch: 6 [11520/60032 (19.189765458422176%)] \t Loss: 0.13021451234817505\n",
      "Train Epoch: 6 [12160/60032 (20.255863539445627%)] \t Loss: 0.3167484402656555\n",
      "Train Epoch: 6 [12800/60032 (21.321961620469082%)] \t Loss: 0.27299147844314575\n",
      "Train Epoch: 6 [13440/60032 (22.388059701492537%)] \t Loss: 0.14180782437324524\n",
      "Train Epoch: 6 [14080/60032 (23.454157782515992%)] \t Loss: 0.4023052453994751\n",
      "Train Epoch: 6 [14720/60032 (24.520255863539447%)] \t Loss: 0.26599550247192383\n",
      "Train Epoch: 6 [15360/60032 (25.586353944562898%)] \t Loss: 0.19687651097774506\n",
      "Train Epoch: 6 [16000/60032 (26.652452025586353%)] \t Loss: 0.2688024044036865\n",
      "Train Epoch: 6 [16640/60032 (27.718550106609808%)] \t Loss: 0.2679629325866699\n",
      "Train Epoch: 6 [17280/60032 (28.784648187633262%)] \t Loss: 0.25925374031066895\n",
      "Train Epoch: 6 [17920/60032 (29.850746268656717%)] \t Loss: 0.1920129656791687\n",
      "Train Epoch: 6 [18560/60032 (30.916844349680172%)] \t Loss: 0.13529038429260254\n",
      "Train Epoch: 6 [19200/60032 (31.982942430703623%)] \t Loss: 0.23716820776462555\n",
      "Train Epoch: 6 [19840/60032 (33.04904051172708%)] \t Loss: 0.2879140377044678\n",
      "Train Epoch: 6 [20480/60032 (34.11513859275053%)] \t Loss: 0.5159870982170105\n",
      "Train Epoch: 6 [21120/60032 (35.18123667377399%)] \t Loss: 0.23118892312049866\n",
      "Train Epoch: 6 [21760/60032 (36.24733475479744%)] \t Loss: 0.24143606424331665\n",
      "Train Epoch: 6 [22400/60032 (37.3134328358209%)] \t Loss: 0.30358603596687317\n",
      "Train Epoch: 6 [23040/60032 (38.37953091684435%)] \t Loss: 0.2639009952545166\n",
      "Train Epoch: 6 [23680/60032 (39.44562899786781%)] \t Loss: 0.25938358902931213\n",
      "Train Epoch: 6 [24320/60032 (40.511727078891255%)] \t Loss: 0.17782412469387054\n",
      "Train Epoch: 6 [24960/60032 (41.57782515991471%)] \t Loss: 0.16511601209640503\n",
      "Train Epoch: 6 [25600/60032 (42.643923240938165%)] \t Loss: 0.2109878659248352\n",
      "Train Epoch: 6 [26240/60032 (43.71002132196162%)] \t Loss: 0.17676889896392822\n",
      "Train Epoch: 6 [26880/60032 (44.776119402985074%)] \t Loss: 0.1717054396867752\n",
      "Train Epoch: 6 [27520/60032 (45.84221748400853%)] \t Loss: 0.1712622046470642\n",
      "Train Epoch: 6 [28160/60032 (46.908315565031984%)] \t Loss: 0.3631325960159302\n",
      "Train Epoch: 6 [28800/60032 (47.97441364605544%)] \t Loss: 0.26653963327407837\n",
      "Train Epoch: 6 [29440/60032 (49.04051172707889%)] \t Loss: 0.17650578916072845\n",
      "Train Epoch: 6 [30080/60032 (50.10660980810235%)] \t Loss: 0.33310019969940186\n",
      "Train Epoch: 6 [30720/60032 (51.172707889125796%)] \t Loss: 0.07912877202033997\n",
      "Train Epoch: 6 [31360/60032 (52.23880597014925%)] \t Loss: 0.2796831429004669\n",
      "Train Epoch: 6 [32000/60032 (53.304904051172706%)] \t Loss: 0.20219172537326813\n",
      "Train Epoch: 6 [32640/60032 (54.37100213219616%)] \t Loss: 0.19140903651714325\n",
      "Train Epoch: 6 [33280/60032 (55.437100213219615%)] \t Loss: 0.2976374626159668\n",
      "Train Epoch: 6 [33920/60032 (56.50319829424307%)] \t Loss: 0.13424982130527496\n",
      "Train Epoch: 6 [34560/60032 (57.569296375266525%)] \t Loss: 0.26592153310775757\n",
      "Train Epoch: 6 [35200/60032 (58.63539445628998%)] \t Loss: 0.2113204300403595\n",
      "Train Epoch: 6 [35840/60032 (59.701492537313435%)] \t Loss: 0.3486993908882141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [36480/60032 (60.76759061833689%)] \t Loss: 0.28039008378982544\n",
      "Train Epoch: 6 [37120/60032 (61.833688699360344%)] \t Loss: 0.18488557636737823\n",
      "Train Epoch: 6 [37760/60032 (62.89978678038379%)] \t Loss: 0.18679946660995483\n",
      "Train Epoch: 6 [38400/60032 (63.96588486140725%)] \t Loss: 0.38707607984542847\n",
      "Train Epoch: 6 [39040/60032 (65.0319829424307%)] \t Loss: 0.5092176198959351\n",
      "Train Epoch: 6 [39680/60032 (66.09808102345416%)] \t Loss: 0.2559972405433655\n",
      "Train Epoch: 6 [40320/60032 (67.16417910447761%)] \t Loss: 0.21783562004566193\n",
      "Train Epoch: 6 [40960/60032 (68.23027718550107%)] \t Loss: 0.39312034845352173\n",
      "Train Epoch: 6 [41600/60032 (69.29637526652452%)] \t Loss: 0.24792659282684326\n",
      "Train Epoch: 6 [42240/60032 (70.36247334754798%)] \t Loss: 0.3456321954727173\n",
      "Train Epoch: 6 [42880/60032 (71.42857142857143%)] \t Loss: 0.2258315086364746\n",
      "Train Epoch: 6 [43520/60032 (72.49466950959489%)] \t Loss: 0.22998057305812836\n",
      "Train Epoch: 6 [44160/60032 (73.56076759061834%)] \t Loss: 0.27502238750457764\n",
      "Train Epoch: 6 [44800/60032 (74.6268656716418%)] \t Loss: 0.16575759649276733\n",
      "Train Epoch: 6 [45440/60032 (75.69296375266525%)] \t Loss: 0.13626547157764435\n",
      "Train Epoch: 6 [46080/60032 (76.7590618336887%)] \t Loss: 0.3366076350212097\n",
      "Train Epoch: 6 [46720/60032 (77.82515991471216%)] \t Loss: 0.26476627588272095\n",
      "Train Epoch: 6 [47360/60032 (78.89125799573561%)] \t Loss: 0.4467654824256897\n",
      "Train Epoch: 6 [48000/60032 (79.95735607675905%)] \t Loss: 0.4144671857357025\n",
      "Train Epoch: 6 [48640/60032 (81.02345415778251%)] \t Loss: 0.5926467776298523\n",
      "Train Epoch: 6 [49280/60032 (82.08955223880596%)] \t Loss: 0.18228153884410858\n",
      "Train Epoch: 6 [49920/60032 (83.15565031982942%)] \t Loss: 0.41054630279541016\n",
      "Train Epoch: 6 [50560/60032 (84.22174840085287%)] \t Loss: 0.3857918083667755\n",
      "Train Epoch: 6 [51200/60032 (85.28784648187633%)] \t Loss: 0.37058526277542114\n",
      "Train Epoch: 6 [51840/60032 (86.35394456289978%)] \t Loss: 0.1776127815246582\n",
      "Train Epoch: 6 [52480/60032 (87.42004264392324%)] \t Loss: 0.13431406021118164\n",
      "Train Epoch: 6 [53120/60032 (88.4861407249467%)] \t Loss: 0.0741490051150322\n",
      "Train Epoch: 6 [53760/60032 (89.55223880597015%)] \t Loss: 0.27093613147735596\n",
      "Train Epoch: 6 [54400/60032 (90.6183368869936%)] \t Loss: 0.2778853178024292\n",
      "Train Epoch: 6 [55040/60032 (91.68443496801706%)] \t Loss: 0.13833943009376526\n",
      "Train Epoch: 6 [55680/60032 (92.75053304904051%)] \t Loss: 0.2593618333339691\n",
      "Train Epoch: 6 [56320/60032 (93.81663113006397%)] \t Loss: 0.08010932803153992\n",
      "Train Epoch: 6 [56960/60032 (94.88272921108742%)] \t Loss: 0.38781094551086426\n",
      "Train Epoch: 6 [57600/60032 (95.94882729211088%)] \t Loss: 0.24557071924209595\n",
      "Train Epoch: 6 [58240/60032 (97.01492537313433%)] \t Loss: 0.3372669816017151\n",
      "Train Epoch: 6 [58880/60032 (98.08102345415779%)] \t Loss: 0.29872018098831177\n",
      "Train Epoch: 6 [59520/60032 (99.14712153518124%)] \t Loss: 0.45701801776885986\n",
      "\n",
      "Test set: Average loss: 0.0841, Accuracy: 9728/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60032 (0.0%)] \t Loss: 0.1675032675266266\n",
      "Train Epoch: 7 [640/60032 (1.0660980810234542%)] \t Loss: 0.2722378373146057\n",
      "Train Epoch: 7 [1280/60032 (2.1321961620469083%)] \t Loss: 0.2551257610321045\n",
      "Train Epoch: 7 [1920/60032 (3.1982942430703623%)] \t Loss: 0.22812223434448242\n",
      "Train Epoch: 7 [2560/60032 (4.264392324093817%)] \t Loss: 0.3968106508255005\n",
      "Train Epoch: 7 [3200/60032 (5.330490405117271%)] \t Loss: 0.18689881265163422\n",
      "Train Epoch: 7 [3840/60032 (6.3965884861407245%)] \t Loss: 0.2798881232738495\n",
      "Train Epoch: 7 [4480/60032 (7.462686567164179%)] \t Loss: 0.2638980448246002\n",
      "Train Epoch: 7 [5120/60032 (8.528784648187633%)] \t Loss: 0.18436861038208008\n",
      "Train Epoch: 7 [5760/60032 (9.594882729211088%)] \t Loss: 0.12085942924022675\n",
      "Train Epoch: 7 [6400/60032 (10.660980810234541%)] \t Loss: 0.15727701783180237\n",
      "Train Epoch: 7 [7040/60032 (11.727078891257996%)] \t Loss: 0.3054537773132324\n",
      "Train Epoch: 7 [7680/60032 (12.793176972281449%)] \t Loss: 0.2825550138950348\n",
      "Train Epoch: 7 [8320/60032 (13.859275053304904%)] \t Loss: 0.21044103801250458\n",
      "Train Epoch: 7 [8960/60032 (14.925373134328359%)] \t Loss: 0.3866703510284424\n",
      "Train Epoch: 7 [9600/60032 (15.991471215351812%)] \t Loss: 0.24797797203063965\n",
      "Train Epoch: 7 [10240/60032 (17.057569296375267%)] \t Loss: 0.19538426399230957\n",
      "Train Epoch: 7 [10880/60032 (18.12366737739872%)] \t Loss: 0.18228167295455933\n",
      "Train Epoch: 7 [11520/60032 (19.189765458422176%)] \t Loss: 0.27788227796554565\n",
      "Train Epoch: 7 [12160/60032 (20.255863539445627%)] \t Loss: 0.15785333514213562\n",
      "Train Epoch: 7 [12800/60032 (21.321961620469082%)] \t Loss: 0.20412135124206543\n",
      "Train Epoch: 7 [13440/60032 (22.388059701492537%)] \t Loss: 0.1736050546169281\n",
      "Train Epoch: 7 [14080/60032 (23.454157782515992%)] \t Loss: 0.25827956199645996\n",
      "Train Epoch: 7 [14720/60032 (24.520255863539447%)] \t Loss: 0.2986500859260559\n",
      "Train Epoch: 7 [15360/60032 (25.586353944562898%)] \t Loss: 0.375504732131958\n",
      "Train Epoch: 7 [16000/60032 (26.652452025586353%)] \t Loss: 0.3603988289833069\n",
      "Train Epoch: 7 [16640/60032 (27.718550106609808%)] \t Loss: 0.3427106738090515\n",
      "Train Epoch: 7 [17280/60032 (28.784648187633262%)] \t Loss: 0.18745718896389008\n",
      "Train Epoch: 7 [17920/60032 (29.850746268656717%)] \t Loss: 0.08773624151945114\n",
      "Train Epoch: 7 [18560/60032 (30.916844349680172%)] \t Loss: 0.35254964232444763\n",
      "Train Epoch: 7 [19200/60032 (31.982942430703623%)] \t Loss: 0.11887890845537186\n",
      "Train Epoch: 7 [19840/60032 (33.04904051172708%)] \t Loss: 0.12884902954101562\n",
      "Train Epoch: 7 [20480/60032 (34.11513859275053%)] \t Loss: 0.19926881790161133\n",
      "Train Epoch: 7 [21120/60032 (35.18123667377399%)] \t Loss: 0.11357369273900986\n",
      "Train Epoch: 7 [21760/60032 (36.24733475479744%)] \t Loss: 0.16794976592063904\n",
      "Train Epoch: 7 [22400/60032 (37.3134328358209%)] \t Loss: 0.3414349853992462\n",
      "Train Epoch: 7 [23040/60032 (38.37953091684435%)] \t Loss: 0.3577727973461151\n",
      "Train Epoch: 7 [23680/60032 (39.44562899786781%)] \t Loss: 0.2847548723220825\n",
      "Train Epoch: 7 [24320/60032 (40.511727078891255%)] \t Loss: 0.3512820601463318\n",
      "Train Epoch: 7 [24960/60032 (41.57782515991471%)] \t Loss: 0.23884516954421997\n",
      "Train Epoch: 7 [25600/60032 (42.643923240938165%)] \t Loss: 0.279513955116272\n",
      "Train Epoch: 7 [26240/60032 (43.71002132196162%)] \t Loss: 0.15273718535900116\n",
      "Train Epoch: 7 [26880/60032 (44.776119402985074%)] \t Loss: 0.21857492625713348\n",
      "Train Epoch: 7 [27520/60032 (45.84221748400853%)] \t Loss: 0.18419627845287323\n",
      "Train Epoch: 7 [28160/60032 (46.908315565031984%)] \t Loss: 0.4500746726989746\n",
      "Train Epoch: 7 [28800/60032 (47.97441364605544%)] \t Loss: 0.1342831701040268\n",
      "Train Epoch: 7 [29440/60032 (49.04051172707889%)] \t Loss: 0.270846426486969\n",
      "Train Epoch: 7 [30080/60032 (50.10660980810235%)] \t Loss: 0.30256450176239014\n",
      "Train Epoch: 7 [30720/60032 (51.172707889125796%)] \t Loss: 0.2276638001203537\n",
      "Train Epoch: 7 [31360/60032 (52.23880597014925%)] \t Loss: 0.32180336117744446\n",
      "Train Epoch: 7 [32000/60032 (53.304904051172706%)] \t Loss: 0.28024038672447205\n",
      "Train Epoch: 7 [32640/60032 (54.37100213219616%)] \t Loss: 0.5058203935623169\n",
      "Train Epoch: 7 [33280/60032 (55.437100213219615%)] \t Loss: 0.38136595487594604\n",
      "Train Epoch: 7 [33920/60032 (56.50319829424307%)] \t Loss: 0.18735693395137787\n",
      "Train Epoch: 7 [34560/60032 (57.569296375266525%)] \t Loss: 0.25600001215934753\n",
      "Train Epoch: 7 [35200/60032 (58.63539445628998%)] \t Loss: 0.22695530951023102\n",
      "Train Epoch: 7 [35840/60032 (59.701492537313435%)] \t Loss: 0.09233040362596512\n",
      "Train Epoch: 7 [36480/60032 (60.76759061833689%)] \t Loss: 0.14802972972393036\n",
      "Train Epoch: 7 [37120/60032 (61.833688699360344%)] \t Loss: 0.2789260745048523\n",
      "Train Epoch: 7 [37760/60032 (62.89978678038379%)] \t Loss: 0.2192874401807785\n",
      "Train Epoch: 7 [38400/60032 (63.96588486140725%)] \t Loss: 0.23112396895885468\n",
      "Train Epoch: 7 [39040/60032 (65.0319829424307%)] \t Loss: 0.3011489510536194\n",
      "Train Epoch: 7 [39680/60032 (66.09808102345416%)] \t Loss: 0.5736777782440186\n",
      "Train Epoch: 7 [40320/60032 (67.16417910447761%)] \t Loss: 0.4568490982055664\n",
      "Train Epoch: 7 [40960/60032 (68.23027718550107%)] \t Loss: 0.1042838767170906\n",
      "Train Epoch: 7 [41600/60032 (69.29637526652452%)] \t Loss: 0.227005273103714\n",
      "Train Epoch: 7 [42240/60032 (70.36247334754798%)] \t Loss: 0.23006948828697205\n",
      "Train Epoch: 7 [42880/60032 (71.42857142857143%)] \t Loss: 0.2670214772224426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [43520/60032 (72.49466950959489%)] \t Loss: 0.2038646787405014\n",
      "Train Epoch: 7 [44160/60032 (73.56076759061834%)] \t Loss: 0.292995810508728\n",
      "Train Epoch: 7 [44800/60032 (74.6268656716418%)] \t Loss: 0.20483462512493134\n",
      "Train Epoch: 7 [45440/60032 (75.69296375266525%)] \t Loss: 0.4118446409702301\n",
      "Train Epoch: 7 [46080/60032 (76.7590618336887%)] \t Loss: 0.35773277282714844\n",
      "Train Epoch: 7 [46720/60032 (77.82515991471216%)] \t Loss: 0.38740816712379456\n",
      "Train Epoch: 7 [47360/60032 (78.89125799573561%)] \t Loss: 0.1682249903678894\n",
      "Train Epoch: 7 [48000/60032 (79.95735607675905%)] \t Loss: 0.36414676904678345\n",
      "Train Epoch: 7 [48640/60032 (81.02345415778251%)] \t Loss: 0.18575787544250488\n",
      "Train Epoch: 7 [49280/60032 (82.08955223880596%)] \t Loss: 0.2184619903564453\n",
      "Train Epoch: 7 [49920/60032 (83.15565031982942%)] \t Loss: 0.4923863410949707\n",
      "Train Epoch: 7 [50560/60032 (84.22174840085287%)] \t Loss: 0.21559080481529236\n",
      "Train Epoch: 7 [51200/60032 (85.28784648187633%)] \t Loss: 0.1445978581905365\n",
      "Train Epoch: 7 [51840/60032 (86.35394456289978%)] \t Loss: 0.11018539220094681\n",
      "Train Epoch: 7 [52480/60032 (87.42004264392324%)] \t Loss: 0.22778844833374023\n",
      "Train Epoch: 7 [53120/60032 (88.4861407249467%)] \t Loss: 0.5779286026954651\n",
      "Train Epoch: 7 [53760/60032 (89.55223880597015%)] \t Loss: 0.13065096735954285\n",
      "Train Epoch: 7 [54400/60032 (90.6183368869936%)] \t Loss: 0.2090766429901123\n",
      "Train Epoch: 7 [55040/60032 (91.68443496801706%)] \t Loss: 0.32429105043411255\n",
      "Train Epoch: 7 [55680/60032 (92.75053304904051%)] \t Loss: 0.1424499899148941\n",
      "Train Epoch: 7 [56320/60032 (93.81663113006397%)] \t Loss: 0.2987775206565857\n",
      "Train Epoch: 7 [56960/60032 (94.88272921108742%)] \t Loss: 0.17967499792575836\n",
      "Train Epoch: 7 [57600/60032 (95.94882729211088%)] \t Loss: 0.15808910131454468\n",
      "Train Epoch: 7 [58240/60032 (97.01492537313433%)] \t Loss: 0.13720190525054932\n",
      "Train Epoch: 7 [58880/60032 (98.08102345415779%)] \t Loss: 0.3397752642631531\n",
      "Train Epoch: 7 [59520/60032 (99.14712153518124%)] \t Loss: 0.10803202539682388\n",
      "\n",
      "Test set: Average loss: 0.0786, Accuracy: 9741/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60032 (0.0%)] \t Loss: 0.159600630402565\n",
      "Train Epoch: 8 [640/60032 (1.0660980810234542%)] \t Loss: 0.21674862504005432\n",
      "Train Epoch: 8 [1280/60032 (2.1321961620469083%)] \t Loss: 0.35759398341178894\n",
      "Train Epoch: 8 [1920/60032 (3.1982942430703623%)] \t Loss: 0.07510627806186676\n",
      "Train Epoch: 8 [2560/60032 (4.264392324093817%)] \t Loss: 0.3692239820957184\n",
      "Train Epoch: 8 [3200/60032 (5.330490405117271%)] \t Loss: 0.3120304048061371\n",
      "Train Epoch: 8 [3840/60032 (6.3965884861407245%)] \t Loss: 0.3524131178855896\n",
      "Train Epoch: 8 [4480/60032 (7.462686567164179%)] \t Loss: 0.3867039084434509\n",
      "Train Epoch: 8 [5120/60032 (8.528784648187633%)] \t Loss: 0.25113630294799805\n",
      "Train Epoch: 8 [5760/60032 (9.594882729211088%)] \t Loss: 0.14785340428352356\n",
      "Train Epoch: 8 [6400/60032 (10.660980810234541%)] \t Loss: 0.24997219443321228\n",
      "Train Epoch: 8 [7040/60032 (11.727078891257996%)] \t Loss: 0.16008850932121277\n",
      "Train Epoch: 8 [7680/60032 (12.793176972281449%)] \t Loss: 0.2060200423002243\n",
      "Train Epoch: 8 [8320/60032 (13.859275053304904%)] \t Loss: 0.2061825692653656\n",
      "Train Epoch: 8 [8960/60032 (14.925373134328359%)] \t Loss: 0.26561686396598816\n",
      "Train Epoch: 8 [9600/60032 (15.991471215351812%)] \t Loss: 0.19499769806861877\n",
      "Train Epoch: 8 [10240/60032 (17.057569296375267%)] \t Loss: 0.18158283829689026\n",
      "Train Epoch: 8 [10880/60032 (18.12366737739872%)] \t Loss: 0.16151590645313263\n",
      "Train Epoch: 8 [11520/60032 (19.189765458422176%)] \t Loss: 0.6296294331550598\n",
      "Train Epoch: 8 [12160/60032 (20.255863539445627%)] \t Loss: 0.20004212856292725\n",
      "Train Epoch: 8 [12800/60032 (21.321961620469082%)] \t Loss: 0.26798978447914124\n",
      "Train Epoch: 8 [13440/60032 (22.388059701492537%)] \t Loss: 0.18408338725566864\n",
      "Train Epoch: 8 [14080/60032 (23.454157782515992%)] \t Loss: 0.20783942937850952\n",
      "Train Epoch: 8 [14720/60032 (24.520255863539447%)] \t Loss: 0.18152108788490295\n",
      "Train Epoch: 8 [15360/60032 (25.586353944562898%)] \t Loss: 0.16091467440128326\n",
      "Train Epoch: 8 [16000/60032 (26.652452025586353%)] \t Loss: 0.25938454270362854\n",
      "Train Epoch: 8 [16640/60032 (27.718550106609808%)] \t Loss: 0.26075050234794617\n",
      "Train Epoch: 8 [17280/60032 (28.784648187633262%)] \t Loss: 0.0962226465344429\n",
      "Train Epoch: 8 [17920/60032 (29.850746268656717%)] \t Loss: 0.13748717308044434\n",
      "Train Epoch: 8 [18560/60032 (30.916844349680172%)] \t Loss: 0.22837570309638977\n",
      "Train Epoch: 8 [19200/60032 (31.982942430703623%)] \t Loss: 0.34360575675964355\n",
      "Train Epoch: 8 [19840/60032 (33.04904051172708%)] \t Loss: 0.2406637966632843\n",
      "Train Epoch: 8 [20480/60032 (34.11513859275053%)] \t Loss: 0.3056197166442871\n",
      "Train Epoch: 8 [21120/60032 (35.18123667377399%)] \t Loss: 0.23378968238830566\n",
      "Train Epoch: 8 [21760/60032 (36.24733475479744%)] \t Loss: 0.4504360556602478\n",
      "Train Epoch: 8 [22400/60032 (37.3134328358209%)] \t Loss: 0.2988307476043701\n",
      "Train Epoch: 8 [23040/60032 (38.37953091684435%)] \t Loss: 0.3312416672706604\n",
      "Train Epoch: 8 [23680/60032 (39.44562899786781%)] \t Loss: 0.4817829430103302\n",
      "Train Epoch: 8 [24320/60032 (40.511727078891255%)] \t Loss: 0.23872140049934387\n",
      "Train Epoch: 8 [24960/60032 (41.57782515991471%)] \t Loss: 0.28801608085632324\n",
      "Train Epoch: 8 [25600/60032 (42.643923240938165%)] \t Loss: 0.16097888350486755\n",
      "Train Epoch: 8 [26240/60032 (43.71002132196162%)] \t Loss: 0.2725066542625427\n",
      "Train Epoch: 8 [26880/60032 (44.776119402985074%)] \t Loss: 0.21476790308952332\n",
      "Train Epoch: 8 [27520/60032 (45.84221748400853%)] \t Loss: 0.4102180004119873\n",
      "Train Epoch: 8 [28160/60032 (46.908315565031984%)] \t Loss: 0.18352574110031128\n",
      "Train Epoch: 8 [28800/60032 (47.97441364605544%)] \t Loss: 0.21751409769058228\n",
      "Train Epoch: 8 [29440/60032 (49.04051172707889%)] \t Loss: 0.26986443996429443\n",
      "Train Epoch: 8 [30080/60032 (50.10660980810235%)] \t Loss: 0.20085829496383667\n",
      "Train Epoch: 8 [30720/60032 (51.172707889125796%)] \t Loss: 0.3125041127204895\n",
      "Train Epoch: 8 [31360/60032 (52.23880597014925%)] \t Loss: 0.26796039938926697\n",
      "Train Epoch: 8 [32000/60032 (53.304904051172706%)] \t Loss: 0.42987510561943054\n",
      "Train Epoch: 8 [32640/60032 (54.37100213219616%)] \t Loss: 0.332301527261734\n",
      "Train Epoch: 8 [33280/60032 (55.437100213219615%)] \t Loss: 0.10868972539901733\n",
      "Train Epoch: 8 [33920/60032 (56.50319829424307%)] \t Loss: 0.21838024258613586\n",
      "Train Epoch: 8 [34560/60032 (57.569296375266525%)] \t Loss: 0.23267334699630737\n",
      "Train Epoch: 8 [35200/60032 (58.63539445628998%)] \t Loss: 0.19291695952415466\n",
      "Train Epoch: 8 [35840/60032 (59.701492537313435%)] \t Loss: 0.23887240886688232\n",
      "Train Epoch: 8 [36480/60032 (60.76759061833689%)] \t Loss: 0.3394894003868103\n",
      "Train Epoch: 8 [37120/60032 (61.833688699360344%)] \t Loss: 0.14423343539237976\n",
      "Train Epoch: 8 [37760/60032 (62.89978678038379%)] \t Loss: 0.15866713225841522\n",
      "Train Epoch: 8 [38400/60032 (63.96588486140725%)] \t Loss: 0.34186962246894836\n",
      "Train Epoch: 8 [39040/60032 (65.0319829424307%)] \t Loss: 0.26708176732063293\n",
      "Train Epoch: 8 [39680/60032 (66.09808102345416%)] \t Loss: 0.34530341625213623\n",
      "Train Epoch: 8 [40320/60032 (67.16417910447761%)] \t Loss: 0.11989431828260422\n",
      "Train Epoch: 8 [40960/60032 (68.23027718550107%)] \t Loss: 0.19666898250579834\n",
      "Train Epoch: 8 [41600/60032 (69.29637526652452%)] \t Loss: 0.2282094657421112\n",
      "Train Epoch: 8 [42240/60032 (70.36247334754798%)] \t Loss: 0.13186471164226532\n",
      "Train Epoch: 8 [42880/60032 (71.42857142857143%)] \t Loss: 0.20182912051677704\n",
      "Train Epoch: 8 [43520/60032 (72.49466950959489%)] \t Loss: 0.400703489780426\n",
      "Train Epoch: 8 [44160/60032 (73.56076759061834%)] \t Loss: 0.16394202411174774\n",
      "Train Epoch: 8 [44800/60032 (74.6268656716418%)] \t Loss: 0.1604255884885788\n",
      "Train Epoch: 8 [45440/60032 (75.69296375266525%)] \t Loss: 0.4275169372558594\n",
      "Train Epoch: 8 [46080/60032 (76.7590618336887%)] \t Loss: 0.3575601279735565\n",
      "Train Epoch: 8 [46720/60032 (77.82515991471216%)] \t Loss: 0.10866376757621765\n",
      "Train Epoch: 8 [47360/60032 (78.89125799573561%)] \t Loss: 0.27199530601501465\n",
      "Train Epoch: 8 [48000/60032 (79.95735607675905%)] \t Loss: 0.248183935880661\n",
      "Train Epoch: 8 [48640/60032 (81.02345415778251%)] \t Loss: 0.21820828318595886\n",
      "Train Epoch: 8 [49280/60032 (82.08955223880596%)] \t Loss: 0.1612277776002884\n",
      "Train Epoch: 8 [49920/60032 (83.15565031982942%)] \t Loss: 0.1377791315317154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [50560/60032 (84.22174840085287%)] \t Loss: 0.11703162640333176\n",
      "Train Epoch: 8 [51200/60032 (85.28784648187633%)] \t Loss: 0.2640764117240906\n",
      "Train Epoch: 8 [51840/60032 (86.35394456289978%)] \t Loss: 0.12892021238803864\n",
      "Train Epoch: 8 [52480/60032 (87.42004264392324%)] \t Loss: 0.23920002579689026\n",
      "Train Epoch: 8 [53120/60032 (88.4861407249467%)] \t Loss: 0.3748863935470581\n",
      "Train Epoch: 8 [53760/60032 (89.55223880597015%)] \t Loss: 0.3148857057094574\n",
      "Train Epoch: 8 [54400/60032 (90.6183368869936%)] \t Loss: 0.453130304813385\n",
      "Train Epoch: 8 [55040/60032 (91.68443496801706%)] \t Loss: 0.2691745162010193\n",
      "Train Epoch: 8 [55680/60032 (92.75053304904051%)] \t Loss: 0.36815202236175537\n",
      "Train Epoch: 8 [56320/60032 (93.81663113006397%)] \t Loss: 0.24517735838890076\n",
      "Train Epoch: 8 [56960/60032 (94.88272921108742%)] \t Loss: 0.2863905727863312\n",
      "Train Epoch: 8 [57600/60032 (95.94882729211088%)] \t Loss: 0.2378346174955368\n",
      "Train Epoch: 8 [58240/60032 (97.01492537313433%)] \t Loss: 0.2388359010219574\n",
      "Train Epoch: 8 [58880/60032 (98.08102345415779%)] \t Loss: 0.1943414956331253\n",
      "Train Epoch: 8 [59520/60032 (99.14712153518124%)] \t Loss: 0.24267832934856415\n",
      "\n",
      "Test set: Average loss: 0.0726, Accuracy: 9759/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60032 (0.0%)] \t Loss: 0.1556043028831482\n",
      "Train Epoch: 9 [640/60032 (1.0660980810234542%)] \t Loss: 0.15886437892913818\n",
      "Train Epoch: 9 [1280/60032 (2.1321961620469083%)] \t Loss: 0.13890063762664795\n",
      "Train Epoch: 9 [1920/60032 (3.1982942430703623%)] \t Loss: 0.32637208700180054\n",
      "Train Epoch: 9 [2560/60032 (4.264392324093817%)] \t Loss: 0.4111166298389435\n",
      "Train Epoch: 9 [3200/60032 (5.330490405117271%)] \t Loss: 0.21928508579730988\n",
      "Train Epoch: 9 [3840/60032 (6.3965884861407245%)] \t Loss: 0.33587414026260376\n",
      "Train Epoch: 9 [4480/60032 (7.462686567164179%)] \t Loss: 0.24392443895339966\n",
      "Train Epoch: 9 [5120/60032 (8.528784648187633%)] \t Loss: 0.12924711406230927\n",
      "Train Epoch: 9 [5760/60032 (9.594882729211088%)] \t Loss: 0.21552686393260956\n",
      "Train Epoch: 9 [6400/60032 (10.660980810234541%)] \t Loss: 0.13112856447696686\n",
      "Train Epoch: 9 [7040/60032 (11.727078891257996%)] \t Loss: 0.3490625023841858\n",
      "Train Epoch: 9 [7680/60032 (12.793176972281449%)] \t Loss: 0.16231226921081543\n",
      "Train Epoch: 9 [8320/60032 (13.859275053304904%)] \t Loss: 0.09706073999404907\n",
      "Train Epoch: 9 [8960/60032 (14.925373134328359%)] \t Loss: 0.15584230422973633\n",
      "Train Epoch: 9 [9600/60032 (15.991471215351812%)] \t Loss: 0.38928666710853577\n",
      "Train Epoch: 9 [10240/60032 (17.057569296375267%)] \t Loss: 0.26067259907722473\n",
      "Train Epoch: 9 [10880/60032 (18.12366737739872%)] \t Loss: 0.26753494143486023\n",
      "Train Epoch: 9 [11520/60032 (19.189765458422176%)] \t Loss: 0.27855294942855835\n",
      "Train Epoch: 9 [12160/60032 (20.255863539445627%)] \t Loss: 0.21569779515266418\n",
      "Train Epoch: 9 [12800/60032 (21.321961620469082%)] \t Loss: 0.295287162065506\n",
      "Train Epoch: 9 [13440/60032 (22.388059701492537%)] \t Loss: 0.1451166719198227\n",
      "Train Epoch: 9 [14080/60032 (23.454157782515992%)] \t Loss: 0.19135460257530212\n",
      "Train Epoch: 9 [14720/60032 (24.520255863539447%)] \t Loss: 0.16554611921310425\n",
      "Train Epoch: 9 [15360/60032 (25.586353944562898%)] \t Loss: 0.12499044835567474\n",
      "Train Epoch: 9 [16000/60032 (26.652452025586353%)] \t Loss: 0.26771464943885803\n",
      "Train Epoch: 9 [16640/60032 (27.718550106609808%)] \t Loss: 0.1871938407421112\n",
      "Train Epoch: 9 [17280/60032 (28.784648187633262%)] \t Loss: 0.20548558235168457\n",
      "Train Epoch: 9 [17920/60032 (29.850746268656717%)] \t Loss: 0.14992406964302063\n",
      "Train Epoch: 9 [18560/60032 (30.916844349680172%)] \t Loss: 0.26064544916152954\n",
      "Train Epoch: 9 [19200/60032 (31.982942430703623%)] \t Loss: 0.07477184385061264\n",
      "Train Epoch: 9 [19840/60032 (33.04904051172708%)] \t Loss: 0.21980300545692444\n",
      "Train Epoch: 9 [20480/60032 (34.11513859275053%)] \t Loss: 0.1432422399520874\n",
      "Train Epoch: 9 [21120/60032 (35.18123667377399%)] \t Loss: 0.22162915766239166\n",
      "Train Epoch: 9 [21760/60032 (36.24733475479744%)] \t Loss: 0.1720859855413437\n",
      "Train Epoch: 9 [22400/60032 (37.3134328358209%)] \t Loss: 0.4435674548149109\n",
      "Train Epoch: 9 [23040/60032 (38.37953091684435%)] \t Loss: 0.2696094810962677\n",
      "Train Epoch: 9 [23680/60032 (39.44562899786781%)] \t Loss: 0.2293928861618042\n",
      "Train Epoch: 9 [24320/60032 (40.511727078891255%)] \t Loss: 0.1812727153301239\n",
      "Train Epoch: 9 [24960/60032 (41.57782515991471%)] \t Loss: 0.1798022836446762\n",
      "Train Epoch: 9 [25600/60032 (42.643923240938165%)] \t Loss: 0.1846916377544403\n",
      "Train Epoch: 9 [26240/60032 (43.71002132196162%)] \t Loss: 0.13194143772125244\n",
      "Train Epoch: 9 [26880/60032 (44.776119402985074%)] \t Loss: 0.1774091124534607\n",
      "Train Epoch: 9 [27520/60032 (45.84221748400853%)] \t Loss: 0.1723443567752838\n",
      "Train Epoch: 9 [28160/60032 (46.908315565031984%)] \t Loss: 0.09760331362485886\n",
      "Train Epoch: 9 [28800/60032 (47.97441364605544%)] \t Loss: 0.2117556780576706\n",
      "Train Epoch: 9 [29440/60032 (49.04051172707889%)] \t Loss: 0.28674712777137756\n",
      "Train Epoch: 9 [30080/60032 (50.10660980810235%)] \t Loss: 0.06222326681017876\n",
      "Train Epoch: 9 [30720/60032 (51.172707889125796%)] \t Loss: 0.17985756695270538\n",
      "Train Epoch: 9 [31360/60032 (52.23880597014925%)] \t Loss: 0.2879890203475952\n",
      "Train Epoch: 9 [32000/60032 (53.304904051172706%)] \t Loss: 0.14282356202602386\n",
      "Train Epoch: 9 [32640/60032 (54.37100213219616%)] \t Loss: 0.16237276792526245\n",
      "Train Epoch: 9 [33280/60032 (55.437100213219615%)] \t Loss: 0.14001189172267914\n",
      "Train Epoch: 9 [33920/60032 (56.50319829424307%)] \t Loss: 0.18943683803081512\n",
      "Train Epoch: 9 [34560/60032 (57.569296375266525%)] \t Loss: 0.15038487315177917\n",
      "Train Epoch: 9 [35200/60032 (58.63539445628998%)] \t Loss: 0.13765735924243927\n",
      "Train Epoch: 9 [35840/60032 (59.701492537313435%)] \t Loss: 0.3056665062904358\n",
      "Train Epoch: 9 [36480/60032 (60.76759061833689%)] \t Loss: 0.19505974650382996\n",
      "Train Epoch: 9 [37120/60032 (61.833688699360344%)] \t Loss: 0.23043563961982727\n",
      "Train Epoch: 9 [37760/60032 (62.89978678038379%)] \t Loss: 0.21680176258087158\n",
      "Train Epoch: 9 [38400/60032 (63.96588486140725%)] \t Loss: 0.317623496055603\n",
      "Train Epoch: 9 [39040/60032 (65.0319829424307%)] \t Loss: 0.3422773778438568\n",
      "Train Epoch: 9 [39680/60032 (66.09808102345416%)] \t Loss: 0.2846071720123291\n",
      "Train Epoch: 9 [40320/60032 (67.16417910447761%)] \t Loss: 0.07369914650917053\n",
      "Train Epoch: 9 [40960/60032 (68.23027718550107%)] \t Loss: 0.16993644833564758\n",
      "Train Epoch: 9 [41600/60032 (69.29637526652452%)] \t Loss: 0.16665232181549072\n",
      "Train Epoch: 9 [42240/60032 (70.36247334754798%)] \t Loss: 0.13720901310443878\n",
      "Train Epoch: 9 [42880/60032 (71.42857142857143%)] \t Loss: 0.12407707422971725\n",
      "Train Epoch: 9 [43520/60032 (72.49466950959489%)] \t Loss: 0.14502370357513428\n",
      "Train Epoch: 9 [44160/60032 (73.56076759061834%)] \t Loss: 0.07748731970787048\n",
      "Train Epoch: 9 [44800/60032 (74.6268656716418%)] \t Loss: 0.2560938596725464\n",
      "Train Epoch: 9 [45440/60032 (75.69296375266525%)] \t Loss: 0.1569177359342575\n",
      "Train Epoch: 9 [46080/60032 (76.7590618336887%)] \t Loss: 0.19108186662197113\n",
      "Train Epoch: 9 [46720/60032 (77.82515991471216%)] \t Loss: 0.327229768037796\n",
      "Train Epoch: 9 [47360/60032 (78.89125799573561%)] \t Loss: 0.1212710365653038\n",
      "Train Epoch: 9 [48000/60032 (79.95735607675905%)] \t Loss: 0.09932439029216766\n",
      "Train Epoch: 9 [48640/60032 (81.02345415778251%)] \t Loss: 0.23545727133750916\n",
      "Train Epoch: 9 [49280/60032 (82.08955223880596%)] \t Loss: 0.1284487098455429\n",
      "Train Epoch: 9 [49920/60032 (83.15565031982942%)] \t Loss: 0.08922510594129562\n",
      "Train Epoch: 9 [50560/60032 (84.22174840085287%)] \t Loss: 0.20695479214191437\n",
      "Train Epoch: 9 [51200/60032 (85.28784648187633%)] \t Loss: 0.33146530389785767\n",
      "Train Epoch: 9 [51840/60032 (86.35394456289978%)] \t Loss: 0.3402605652809143\n",
      "Train Epoch: 9 [52480/60032 (87.42004264392324%)] \t Loss: 0.16885502636432648\n",
      "Train Epoch: 9 [53120/60032 (88.4861407249467%)] \t Loss: 0.118063785135746\n",
      "Train Epoch: 9 [53760/60032 (89.55223880597015%)] \t Loss: 0.2728208005428314\n",
      "Train Epoch: 9 [54400/60032 (90.6183368869936%)] \t Loss: 0.15945664048194885\n",
      "Train Epoch: 9 [55040/60032 (91.68443496801706%)] \t Loss: 0.2550676763057709\n",
      "Train Epoch: 9 [55680/60032 (92.75053304904051%)] \t Loss: 0.4441554546356201\n",
      "Train Epoch: 9 [56320/60032 (93.81663113006397%)] \t Loss: 0.10748136788606644\n",
      "Train Epoch: 9 [56960/60032 (94.88272921108742%)] \t Loss: 0.29315313696861267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [57600/60032 (95.94882729211088%)] \t Loss: 0.2026934176683426\n",
      "Train Epoch: 9 [58240/60032 (97.01492537313433%)] \t Loss: 0.4527500569820404\n",
      "Train Epoch: 9 [58880/60032 (98.08102345415779%)] \t Loss: 0.09611155092716217\n",
      "Train Epoch: 9 [59520/60032 (99.14712153518124%)] \t Loss: 0.30617427825927734\n",
      "\n",
      "Test set: Average loss: 0.0681, Accuracy: 9774/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60032 (0.0%)] \t Loss: 0.15500053763389587\n",
      "Train Epoch: 10 [640/60032 (1.0660980810234542%)] \t Loss: 0.22111675143241882\n",
      "Train Epoch: 10 [1280/60032 (2.1321961620469083%)] \t Loss: 0.2916680872440338\n",
      "Train Epoch: 10 [1920/60032 (3.1982942430703623%)] \t Loss: 0.3425648808479309\n",
      "Train Epoch: 10 [2560/60032 (4.264392324093817%)] \t Loss: 0.20463156700134277\n",
      "Train Epoch: 10 [3200/60032 (5.330490405117271%)] \t Loss: 0.29713472723960876\n",
      "Train Epoch: 10 [3840/60032 (6.3965884861407245%)] \t Loss: 0.46400532126426697\n",
      "Train Epoch: 10 [4480/60032 (7.462686567164179%)] \t Loss: 0.15480147302150726\n",
      "Train Epoch: 10 [5120/60032 (8.528784648187633%)] \t Loss: 0.07812914252281189\n",
      "Train Epoch: 10 [5760/60032 (9.594882729211088%)] \t Loss: 0.20243346691131592\n",
      "Train Epoch: 10 [6400/60032 (10.660980810234541%)] \t Loss: 0.18536700308322906\n",
      "Train Epoch: 10 [7040/60032 (11.727078891257996%)] \t Loss: 0.25420647859573364\n",
      "Train Epoch: 10 [7680/60032 (12.793176972281449%)] \t Loss: 0.2401176542043686\n",
      "Train Epoch: 10 [8320/60032 (13.859275053304904%)] \t Loss: 0.052648890763521194\n",
      "Train Epoch: 10 [8960/60032 (14.925373134328359%)] \t Loss: 0.2921828627586365\n",
      "Train Epoch: 10 [9600/60032 (15.991471215351812%)] \t Loss: 0.22858098149299622\n",
      "Train Epoch: 10 [10240/60032 (17.057569296375267%)] \t Loss: 0.22891300916671753\n",
      "Train Epoch: 10 [10880/60032 (18.12366737739872%)] \t Loss: 0.15280838310718536\n",
      "Train Epoch: 10 [11520/60032 (19.189765458422176%)] \t Loss: 0.33695298433303833\n",
      "Train Epoch: 10 [12160/60032 (20.255863539445627%)] \t Loss: 0.11972925812005997\n",
      "Train Epoch: 10 [12800/60032 (21.321961620469082%)] \t Loss: 0.14479714632034302\n",
      "Train Epoch: 10 [13440/60032 (22.388059701492537%)] \t Loss: 0.33432525396347046\n",
      "Train Epoch: 10 [14080/60032 (23.454157782515992%)] \t Loss: 0.20885705947875977\n",
      "Train Epoch: 10 [14720/60032 (24.520255863539447%)] \t Loss: 0.20305295288562775\n",
      "Train Epoch: 10 [15360/60032 (25.586353944562898%)] \t Loss: 0.1880733072757721\n",
      "Train Epoch: 10 [16000/60032 (26.652452025586353%)] \t Loss: 0.14342112839221954\n",
      "Train Epoch: 10 [16640/60032 (27.718550106609808%)] \t Loss: 0.11235101521015167\n",
      "Train Epoch: 10 [17280/60032 (28.784648187633262%)] \t Loss: 0.23021623492240906\n",
      "Train Epoch: 10 [17920/60032 (29.850746268656717%)] \t Loss: 0.17628887295722961\n",
      "Train Epoch: 10 [18560/60032 (30.916844349680172%)] \t Loss: 0.13620401918888092\n",
      "Train Epoch: 10 [19200/60032 (31.982942430703623%)] \t Loss: 0.2842831611633301\n",
      "Train Epoch: 10 [19840/60032 (33.04904051172708%)] \t Loss: 0.06664557754993439\n",
      "Train Epoch: 10 [20480/60032 (34.11513859275053%)] \t Loss: 0.2547714114189148\n",
      "Train Epoch: 10 [21120/60032 (35.18123667377399%)] \t Loss: 0.29065990447998047\n",
      "Train Epoch: 10 [21760/60032 (36.24733475479744%)] \t Loss: 0.09852755814790726\n",
      "Train Epoch: 10 [22400/60032 (37.3134328358209%)] \t Loss: 0.3655916750431061\n",
      "Train Epoch: 10 [23040/60032 (38.37953091684435%)] \t Loss: 0.11504492908716202\n",
      "Train Epoch: 10 [23680/60032 (39.44562899786781%)] \t Loss: 0.13176748156547546\n",
      "Train Epoch: 10 [24320/60032 (40.511727078891255%)] \t Loss: 0.27265095710754395\n",
      "Train Epoch: 10 [24960/60032 (41.57782515991471%)] \t Loss: 0.196698859333992\n",
      "Train Epoch: 10 [25600/60032 (42.643923240938165%)] \t Loss: 0.11629316210746765\n",
      "Train Epoch: 10 [26240/60032 (43.71002132196162%)] \t Loss: 0.1568835973739624\n",
      "Train Epoch: 10 [26880/60032 (44.776119402985074%)] \t Loss: 0.23403681814670563\n",
      "Train Epoch: 10 [27520/60032 (45.84221748400853%)] \t Loss: 0.19741883873939514\n",
      "Train Epoch: 10 [28160/60032 (46.908315565031984%)] \t Loss: 0.263588547706604\n",
      "Train Epoch: 10 [28800/60032 (47.97441364605544%)] \t Loss: 0.22038845717906952\n",
      "Train Epoch: 10 [29440/60032 (49.04051172707889%)] \t Loss: 0.17794889211654663\n",
      "Train Epoch: 10 [30080/60032 (50.10660980810235%)] \t Loss: 0.1314413696527481\n",
      "Train Epoch: 10 [30720/60032 (51.172707889125796%)] \t Loss: 0.20128928124904633\n",
      "Train Epoch: 10 [31360/60032 (52.23880597014925%)] \t Loss: 0.2478996217250824\n",
      "Train Epoch: 10 [32000/60032 (53.304904051172706%)] \t Loss: 0.18435116112232208\n",
      "Train Epoch: 10 [32640/60032 (54.37100213219616%)] \t Loss: 0.3759007155895233\n",
      "Train Epoch: 10 [33280/60032 (55.437100213219615%)] \t Loss: 0.2125045359134674\n",
      "Train Epoch: 10 [33920/60032 (56.50319829424307%)] \t Loss: 0.1497766077518463\n",
      "Train Epoch: 10 [34560/60032 (57.569296375266525%)] \t Loss: 0.32626157999038696\n",
      "Train Epoch: 10 [35200/60032 (58.63539445628998%)] \t Loss: 0.08605025708675385\n",
      "Train Epoch: 10 [35840/60032 (59.701492537313435%)] \t Loss: 0.20519918203353882\n",
      "Train Epoch: 10 [36480/60032 (60.76759061833689%)] \t Loss: 0.2527585029602051\n",
      "Train Epoch: 10 [37120/60032 (61.833688699360344%)] \t Loss: 0.16001039743423462\n",
      "Train Epoch: 10 [37760/60032 (62.89978678038379%)] \t Loss: 0.41267362236976624\n",
      "Train Epoch: 10 [38400/60032 (63.96588486140725%)] \t Loss: 0.08360029757022858\n",
      "Train Epoch: 10 [39040/60032 (65.0319829424307%)] \t Loss: 0.1961902230978012\n",
      "Train Epoch: 10 [39680/60032 (66.09808102345416%)] \t Loss: 0.3217378854751587\n",
      "Train Epoch: 10 [40320/60032 (67.16417910447761%)] \t Loss: 0.26544201374053955\n",
      "Train Epoch: 10 [40960/60032 (68.23027718550107%)] \t Loss: 0.2039521336555481\n",
      "Train Epoch: 10 [41600/60032 (69.29637526652452%)] \t Loss: 0.7032591104507446\n",
      "Train Epoch: 10 [42240/60032 (70.36247334754798%)] \t Loss: 0.18315105140209198\n",
      "Train Epoch: 10 [42880/60032 (71.42857142857143%)] \t Loss: 0.38063180446624756\n",
      "Train Epoch: 10 [43520/60032 (72.49466950959489%)] \t Loss: 0.120038703083992\n",
      "Train Epoch: 10 [44160/60032 (73.56076759061834%)] \t Loss: 0.14240197837352753\n",
      "Train Epoch: 10 [44800/60032 (74.6268656716418%)] \t Loss: 0.17727336287498474\n",
      "Train Epoch: 10 [45440/60032 (75.69296375266525%)] \t Loss: 0.32223543524742126\n",
      "Train Epoch: 10 [46080/60032 (76.7590618336887%)] \t Loss: 0.2934427559375763\n",
      "Train Epoch: 10 [46720/60032 (77.82515991471216%)] \t Loss: 0.15142764151096344\n",
      "Train Epoch: 10 [47360/60032 (78.89125799573561%)] \t Loss: 0.20557205379009247\n",
      "Train Epoch: 10 [48000/60032 (79.95735607675905%)] \t Loss: 0.08012860268354416\n",
      "Train Epoch: 10 [48640/60032 (81.02345415778251%)] \t Loss: 0.2082805037498474\n",
      "Train Epoch: 10 [49280/60032 (82.08955223880596%)] \t Loss: 0.19524934887886047\n",
      "Train Epoch: 10 [49920/60032 (83.15565031982942%)] \t Loss: 0.24576671421527863\n",
      "Train Epoch: 10 [50560/60032 (84.22174840085287%)] \t Loss: 0.3019450902938843\n",
      "Train Epoch: 10 [51200/60032 (85.28784648187633%)] \t Loss: 0.08694735169410706\n",
      "Train Epoch: 10 [51840/60032 (86.35394456289978%)] \t Loss: 0.21598562598228455\n",
      "Train Epoch: 10 [52480/60032 (87.42004264392324%)] \t Loss: 0.13060186803340912\n",
      "Train Epoch: 10 [53120/60032 (88.4861407249467%)] \t Loss: 0.22168435156345367\n",
      "Train Epoch: 10 [53760/60032 (89.55223880597015%)] \t Loss: 0.5049557089805603\n",
      "Train Epoch: 10 [54400/60032 (90.6183368869936%)] \t Loss: 0.31897470355033875\n",
      "Train Epoch: 10 [55040/60032 (91.68443496801706%)] \t Loss: 0.16888464987277985\n",
      "Train Epoch: 10 [55680/60032 (92.75053304904051%)] \t Loss: 0.3275566101074219\n",
      "Train Epoch: 10 [56320/60032 (93.81663113006397%)] \t Loss: 0.2500816583633423\n",
      "Train Epoch: 10 [56960/60032 (94.88272921108742%)] \t Loss: 0.10201089829206467\n",
      "Train Epoch: 10 [57600/60032 (95.94882729211088%)] \t Loss: 0.1861354410648346\n",
      "Train Epoch: 10 [58240/60032 (97.01492537313433%)] \t Loss: 0.09679817408323288\n",
      "Train Epoch: 10 [58880/60032 (98.08102345415779%)] \t Loss: 0.21390607953071594\n",
      "Train Epoch: 10 [59520/60032 (99.14712153518124%)] \t Loss: 0.059307925403118134\n",
      "\n",
      "Test set: Average loss: 0.0650, Accuracy: 9789/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/60032 (0.0%)] \t Loss: 0.14111018180847168\n",
      "Train Epoch: 11 [640/60032 (1.0660980810234542%)] \t Loss: 0.4275985658168793\n",
      "Train Epoch: 11 [1280/60032 (2.1321961620469083%)] \t Loss: 0.20483359694480896\n",
      "Train Epoch: 11 [1920/60032 (3.1982942430703623%)] \t Loss: 0.10892713069915771\n",
      "Train Epoch: 11 [2560/60032 (4.264392324093817%)] \t Loss: 0.2929782271385193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [3200/60032 (5.330490405117271%)] \t Loss: 0.26779139041900635\n",
      "Train Epoch: 11 [3840/60032 (6.3965884861407245%)] \t Loss: 0.20952171087265015\n",
      "Train Epoch: 11 [4480/60032 (7.462686567164179%)] \t Loss: 0.1294107884168625\n",
      "Train Epoch: 11 [5120/60032 (8.528784648187633%)] \t Loss: 0.3069232404232025\n",
      "Train Epoch: 11 [5760/60032 (9.594882729211088%)] \t Loss: 0.22056622803211212\n",
      "Train Epoch: 11 [6400/60032 (10.660980810234541%)] \t Loss: 0.23525911569595337\n",
      "Train Epoch: 11 [7040/60032 (11.727078891257996%)] \t Loss: 0.09868206083774567\n",
      "Train Epoch: 11 [7680/60032 (12.793176972281449%)] \t Loss: 0.12767678499221802\n",
      "Train Epoch: 11 [8320/60032 (13.859275053304904%)] \t Loss: 0.18867692351341248\n",
      "Train Epoch: 11 [8960/60032 (14.925373134328359%)] \t Loss: 0.2724462151527405\n",
      "Train Epoch: 11 [9600/60032 (15.991471215351812%)] \t Loss: 0.1808701604604721\n",
      "Train Epoch: 11 [10240/60032 (17.057569296375267%)] \t Loss: 0.25736477971076965\n",
      "Train Epoch: 11 [10880/60032 (18.12366737739872%)] \t Loss: 0.20985044538974762\n",
      "Train Epoch: 11 [11520/60032 (19.189765458422176%)] \t Loss: 0.25697970390319824\n",
      "Train Epoch: 11 [12160/60032 (20.255863539445627%)] \t Loss: 0.08507422357797623\n",
      "Train Epoch: 11 [12800/60032 (21.321961620469082%)] \t Loss: 0.08792491257190704\n",
      "Train Epoch: 11 [13440/60032 (22.388059701492537%)] \t Loss: 0.15110790729522705\n",
      "Train Epoch: 11 [14080/60032 (23.454157782515992%)] \t Loss: 0.17595122754573822\n",
      "Train Epoch: 11 [14720/60032 (24.520255863539447%)] \t Loss: 0.11419044435024261\n",
      "Train Epoch: 11 [15360/60032 (25.586353944562898%)] \t Loss: 0.12813924252986908\n",
      "Train Epoch: 11 [16000/60032 (26.652452025586353%)] \t Loss: 0.12450302392244339\n",
      "Train Epoch: 11 [16640/60032 (27.718550106609808%)] \t Loss: 0.15118534862995148\n",
      "Train Epoch: 11 [17280/60032 (28.784648187633262%)] \t Loss: 0.3132357597351074\n",
      "Train Epoch: 11 [17920/60032 (29.850746268656717%)] \t Loss: 0.31274378299713135\n",
      "Train Epoch: 11 [18560/60032 (30.916844349680172%)] \t Loss: 0.29285210371017456\n",
      "Train Epoch: 11 [19200/60032 (31.982942430703623%)] \t Loss: 0.15754824876785278\n",
      "Train Epoch: 11 [19840/60032 (33.04904051172708%)] \t Loss: 0.11941120028495789\n",
      "Train Epoch: 11 [20480/60032 (34.11513859275053%)] \t Loss: 0.129487082362175\n",
      "Train Epoch: 11 [21120/60032 (35.18123667377399%)] \t Loss: 0.4103916883468628\n",
      "Train Epoch: 11 [21760/60032 (36.24733475479744%)] \t Loss: 0.12037335336208344\n",
      "Train Epoch: 11 [22400/60032 (37.3134328358209%)] \t Loss: 0.10856428742408752\n",
      "Train Epoch: 11 [23040/60032 (38.37953091684435%)] \t Loss: 0.14507347345352173\n",
      "Train Epoch: 11 [23680/60032 (39.44562899786781%)] \t Loss: 0.24048399925231934\n",
      "Train Epoch: 11 [24320/60032 (40.511727078891255%)] \t Loss: 0.12257475405931473\n",
      "Train Epoch: 11 [24960/60032 (41.57782515991471%)] \t Loss: 0.19251036643981934\n",
      "Train Epoch: 11 [25600/60032 (42.643923240938165%)] \t Loss: 0.197390615940094\n",
      "Train Epoch: 11 [26240/60032 (43.71002132196162%)] \t Loss: 0.21538151800632477\n",
      "Train Epoch: 11 [26880/60032 (44.776119402985074%)] \t Loss: 0.14137965440750122\n",
      "Train Epoch: 11 [27520/60032 (45.84221748400853%)] \t Loss: 0.16131262481212616\n",
      "Train Epoch: 11 [28160/60032 (46.908315565031984%)] \t Loss: 0.2664862275123596\n",
      "Train Epoch: 11 [28800/60032 (47.97441364605544%)] \t Loss: 0.14357686042785645\n",
      "Train Epoch: 11 [29440/60032 (49.04051172707889%)] \t Loss: 0.12942247092723846\n",
      "Train Epoch: 11 [30080/60032 (50.10660980810235%)] \t Loss: 0.21132540702819824\n",
      "Train Epoch: 11 [30720/60032 (51.172707889125796%)] \t Loss: 0.20708855986595154\n",
      "Train Epoch: 11 [31360/60032 (52.23880597014925%)] \t Loss: 0.36415570974349976\n",
      "Train Epoch: 11 [32000/60032 (53.304904051172706%)] \t Loss: 0.15800553560256958\n",
      "Train Epoch: 11 [32640/60032 (54.37100213219616%)] \t Loss: 0.15261909365653992\n",
      "Train Epoch: 11 [33280/60032 (55.437100213219615%)] \t Loss: 0.13078898191452026\n",
      "Train Epoch: 11 [33920/60032 (56.50319829424307%)] \t Loss: 0.1765555739402771\n",
      "Train Epoch: 11 [34560/60032 (57.569296375266525%)] \t Loss: 0.11471415311098099\n",
      "Train Epoch: 11 [35200/60032 (58.63539445628998%)] \t Loss: 0.09582584351301193\n",
      "Train Epoch: 11 [35840/60032 (59.701492537313435%)] \t Loss: 0.304705947637558\n",
      "Train Epoch: 11 [36480/60032 (60.76759061833689%)] \t Loss: 0.25193729996681213\n",
      "Train Epoch: 11 [37120/60032 (61.833688699360344%)] \t Loss: 0.26428869366645813\n",
      "Train Epoch: 11 [37760/60032 (62.89978678038379%)] \t Loss: 0.18748615682125092\n",
      "Train Epoch: 11 [38400/60032 (63.96588486140725%)] \t Loss: 0.13882194459438324\n",
      "Train Epoch: 11 [39040/60032 (65.0319829424307%)] \t Loss: 0.3319932222366333\n",
      "Train Epoch: 11 [39680/60032 (66.09808102345416%)] \t Loss: 0.1547134667634964\n",
      "Train Epoch: 11 [40320/60032 (67.16417910447761%)] \t Loss: 0.1114710122346878\n",
      "Train Epoch: 11 [40960/60032 (68.23027718550107%)] \t Loss: 0.2925266921520233\n",
      "Train Epoch: 11 [41600/60032 (69.29637526652452%)] \t Loss: 0.13911113142967224\n",
      "Train Epoch: 11 [42240/60032 (70.36247334754798%)] \t Loss: 0.23967519402503967\n",
      "Train Epoch: 11 [42880/60032 (71.42857142857143%)] \t Loss: 0.2413235604763031\n",
      "Train Epoch: 11 [43520/60032 (72.49466950959489%)] \t Loss: 0.28785476088523865\n",
      "Train Epoch: 11 [44160/60032 (73.56076759061834%)] \t Loss: 0.26491838693618774\n",
      "Train Epoch: 11 [44800/60032 (74.6268656716418%)] \t Loss: 0.26811233162879944\n",
      "Train Epoch: 11 [45440/60032 (75.69296375266525%)] \t Loss: 0.09978032112121582\n",
      "Train Epoch: 11 [46080/60032 (76.7590618336887%)] \t Loss: 0.16933897137641907\n",
      "Train Epoch: 11 [46720/60032 (77.82515991471216%)] \t Loss: 0.13770724833011627\n",
      "Train Epoch: 11 [47360/60032 (78.89125799573561%)] \t Loss: 0.189270481467247\n",
      "Train Epoch: 11 [48000/60032 (79.95735607675905%)] \t Loss: 0.09281167387962341\n",
      "Train Epoch: 11 [48640/60032 (81.02345415778251%)] \t Loss: 0.2697770297527313\n",
      "Train Epoch: 11 [49280/60032 (82.08955223880596%)] \t Loss: 0.19795161485671997\n",
      "Train Epoch: 11 [49920/60032 (83.15565031982942%)] \t Loss: 0.21994712948799133\n",
      "Train Epoch: 11 [50560/60032 (84.22174840085287%)] \t Loss: 0.3666146397590637\n",
      "Train Epoch: 11 [51200/60032 (85.28784648187633%)] \t Loss: 0.15869756042957306\n",
      "Train Epoch: 11 [51840/60032 (86.35394456289978%)] \t Loss: 0.08780927211046219\n",
      "Train Epoch: 11 [52480/60032 (87.42004264392324%)] \t Loss: 0.27834469079971313\n",
      "Train Epoch: 11 [53120/60032 (88.4861407249467%)] \t Loss: 0.1714765429496765\n",
      "Train Epoch: 11 [53760/60032 (89.55223880597015%)] \t Loss: 0.09797725826501846\n",
      "Train Epoch: 11 [54400/60032 (90.6183368869936%)] \t Loss: 0.15976999700069427\n",
      "Train Epoch: 11 [55040/60032 (91.68443496801706%)] \t Loss: 0.14234741032123566\n",
      "Train Epoch: 11 [55680/60032 (92.75053304904051%)] \t Loss: 0.15011434257030487\n",
      "Train Epoch: 11 [56320/60032 (93.81663113006397%)] \t Loss: 0.1719837188720703\n",
      "Train Epoch: 11 [56960/60032 (94.88272921108742%)] \t Loss: 0.182350754737854\n",
      "Train Epoch: 11 [57600/60032 (95.94882729211088%)] \t Loss: 0.17408573627471924\n",
      "Train Epoch: 11 [58240/60032 (97.01492537313433%)] \t Loss: 0.20142659544944763\n",
      "Train Epoch: 11 [58880/60032 (98.08102345415779%)] \t Loss: 0.08466649800539017\n",
      "Train Epoch: 11 [59520/60032 (99.14712153518124%)] \t Loss: 0.1483668088912964\n",
      "\n",
      "Test set: Average loss: 0.0650, Accuracy: 9800/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/60032 (0.0%)] \t Loss: 0.15769177675247192\n",
      "Train Epoch: 12 [640/60032 (1.0660980810234542%)] \t Loss: 0.1292223334312439\n",
      "Train Epoch: 12 [1280/60032 (2.1321961620469083%)] \t Loss: 0.14800645411014557\n",
      "Train Epoch: 12 [1920/60032 (3.1982942430703623%)] \t Loss: 0.07202628254890442\n",
      "Train Epoch: 12 [2560/60032 (4.264392324093817%)] \t Loss: 0.3670884370803833\n",
      "Train Epoch: 12 [3200/60032 (5.330490405117271%)] \t Loss: 0.173476904630661\n",
      "Train Epoch: 12 [3840/60032 (6.3965884861407245%)] \t Loss: 0.28810256719589233\n",
      "Train Epoch: 12 [4480/60032 (7.462686567164179%)] \t Loss: 0.06585917621850967\n",
      "Train Epoch: 12 [5120/60032 (8.528784648187633%)] \t Loss: 0.3014969825744629\n",
      "Train Epoch: 12 [5760/60032 (9.594882729211088%)] \t Loss: 0.1410844326019287\n",
      "Train Epoch: 12 [6400/60032 (10.660980810234541%)] \t Loss: 0.26191237568855286\n",
      "Train Epoch: 12 [7040/60032 (11.727078891257996%)] \t Loss: 0.12265300750732422\n",
      "Train Epoch: 12 [7680/60032 (12.793176972281449%)] \t Loss: 0.20596793293952942\n",
      "Train Epoch: 12 [8320/60032 (13.859275053304904%)] \t Loss: 0.22407624125480652\n",
      "Train Epoch: 12 [8960/60032 (14.925373134328359%)] \t Loss: 0.20858746767044067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [9600/60032 (15.991471215351812%)] \t Loss: 0.1424078345298767\n",
      "Train Epoch: 12 [10240/60032 (17.057569296375267%)] \t Loss: 0.23251232504844666\n",
      "Train Epoch: 12 [10880/60032 (18.12366737739872%)] \t Loss: 0.2702755928039551\n",
      "Train Epoch: 12 [11520/60032 (19.189765458422176%)] \t Loss: 0.16873987019062042\n",
      "Train Epoch: 12 [12160/60032 (20.255863539445627%)] \t Loss: 0.30403560400009155\n",
      "Train Epoch: 12 [12800/60032 (21.321961620469082%)] \t Loss: 0.12238368391990662\n",
      "Train Epoch: 12 [13440/60032 (22.388059701492537%)] \t Loss: 0.14385825395584106\n",
      "Train Epoch: 12 [14080/60032 (23.454157782515992%)] \t Loss: 0.1591998040676117\n",
      "Train Epoch: 12 [14720/60032 (24.520255863539447%)] \t Loss: 0.15363356471061707\n",
      "Train Epoch: 12 [15360/60032 (25.586353944562898%)] \t Loss: 0.12513145804405212\n",
      "Train Epoch: 12 [16000/60032 (26.652452025586353%)] \t Loss: 0.1519988477230072\n",
      "Train Epoch: 12 [16640/60032 (27.718550106609808%)] \t Loss: 0.1963045746088028\n",
      "Train Epoch: 12 [17280/60032 (28.784648187633262%)] \t Loss: 0.13772661983966827\n",
      "Train Epoch: 12 [17920/60032 (29.850746268656717%)] \t Loss: 0.26484787464141846\n",
      "Train Epoch: 12 [18560/60032 (30.916844349680172%)] \t Loss: 0.11808425933122635\n",
      "Train Epoch: 12 [19200/60032 (31.982942430703623%)] \t Loss: 0.4388120174407959\n",
      "Train Epoch: 12 [19840/60032 (33.04904051172708%)] \t Loss: 0.06676677614450455\n",
      "Train Epoch: 12 [20480/60032 (34.11513859275053%)] \t Loss: 0.14671117067337036\n",
      "Train Epoch: 12 [21120/60032 (35.18123667377399%)] \t Loss: 0.16465939581394196\n",
      "Train Epoch: 12 [21760/60032 (36.24733475479744%)] \t Loss: 0.28598862886428833\n",
      "Train Epoch: 12 [22400/60032 (37.3134328358209%)] \t Loss: 0.12018094956874847\n",
      "Train Epoch: 12 [23040/60032 (38.37953091684435%)] \t Loss: 0.3575645387172699\n",
      "Train Epoch: 12 [23680/60032 (39.44562899786781%)] \t Loss: 0.2380477786064148\n",
      "Train Epoch: 12 [24320/60032 (40.511727078891255%)] \t Loss: 0.23828019201755524\n",
      "Train Epoch: 12 [24960/60032 (41.57782515991471%)] \t Loss: 0.1820790320634842\n",
      "Train Epoch: 12 [25600/60032 (42.643923240938165%)] \t Loss: 0.2557362914085388\n",
      "Train Epoch: 12 [26240/60032 (43.71002132196162%)] \t Loss: 0.24077948927879333\n",
      "Train Epoch: 12 [26880/60032 (44.776119402985074%)] \t Loss: 0.19969062507152557\n",
      "Train Epoch: 12 [27520/60032 (45.84221748400853%)] \t Loss: 0.18612681329250336\n",
      "Train Epoch: 12 [28160/60032 (46.908315565031984%)] \t Loss: 0.22541366517543793\n",
      "Train Epoch: 12 [28800/60032 (47.97441364605544%)] \t Loss: 0.14927265048027039\n",
      "Train Epoch: 12 [29440/60032 (49.04051172707889%)] \t Loss: 0.24171921610832214\n",
      "Train Epoch: 12 [30080/60032 (50.10660980810235%)] \t Loss: 0.181452676653862\n",
      "Train Epoch: 12 [30720/60032 (51.172707889125796%)] \t Loss: 0.11615787446498871\n",
      "Train Epoch: 12 [31360/60032 (52.23880597014925%)] \t Loss: 0.1808789074420929\n",
      "Train Epoch: 12 [32000/60032 (53.304904051172706%)] \t Loss: 0.15908652544021606\n",
      "Train Epoch: 12 [32640/60032 (54.37100213219616%)] \t Loss: 0.25786668062210083\n",
      "Train Epoch: 12 [33280/60032 (55.437100213219615%)] \t Loss: 0.112384133040905\n",
      "Train Epoch: 12 [33920/60032 (56.50319829424307%)] \t Loss: 0.2828872501850128\n",
      "Train Epoch: 12 [34560/60032 (57.569296375266525%)] \t Loss: 0.49925175309181213\n",
      "Train Epoch: 12 [35200/60032 (58.63539445628998%)] \t Loss: 0.366970419883728\n",
      "Train Epoch: 12 [35840/60032 (59.701492537313435%)] \t Loss: 0.14753736555576324\n",
      "Train Epoch: 12 [36480/60032 (60.76759061833689%)] \t Loss: 0.08397647738456726\n",
      "Train Epoch: 12 [37120/60032 (61.833688699360344%)] \t Loss: 0.23862755298614502\n",
      "Train Epoch: 12 [37760/60032 (62.89978678038379%)] \t Loss: 0.10096858441829681\n",
      "Train Epoch: 12 [38400/60032 (63.96588486140725%)] \t Loss: 0.15873420238494873\n",
      "Train Epoch: 12 [39040/60032 (65.0319829424307%)] \t Loss: 0.5760383009910583\n",
      "Train Epoch: 12 [39680/60032 (66.09808102345416%)] \t Loss: 0.3261459469795227\n",
      "Train Epoch: 12 [40320/60032 (67.16417910447761%)] \t Loss: 0.18448886275291443\n",
      "Train Epoch: 12 [40960/60032 (68.23027718550107%)] \t Loss: 0.21957147121429443\n",
      "Train Epoch: 12 [41600/60032 (69.29637526652452%)] \t Loss: 0.12085265666246414\n",
      "Train Epoch: 12 [42240/60032 (70.36247334754798%)] \t Loss: 0.1679648458957672\n",
      "Train Epoch: 12 [42880/60032 (71.42857142857143%)] \t Loss: 0.14199261367321014\n",
      "Train Epoch: 12 [43520/60032 (72.49466950959489%)] \t Loss: 0.5537185668945312\n",
      "Train Epoch: 12 [44160/60032 (73.56076759061834%)] \t Loss: 0.07773572206497192\n",
      "Train Epoch: 12 [44800/60032 (74.6268656716418%)] \t Loss: 0.10494107007980347\n",
      "Train Epoch: 12 [45440/60032 (75.69296375266525%)] \t Loss: 0.1313270777463913\n",
      "Train Epoch: 12 [46080/60032 (76.7590618336887%)] \t Loss: 0.15350082516670227\n",
      "Train Epoch: 12 [46720/60032 (77.82515991471216%)] \t Loss: 0.21528367698192596\n",
      "Train Epoch: 12 [47360/60032 (78.89125799573561%)] \t Loss: 0.32085445523262024\n",
      "Train Epoch: 12 [48000/60032 (79.95735607675905%)] \t Loss: 0.24482569098472595\n",
      "Train Epoch: 12 [48640/60032 (81.02345415778251%)] \t Loss: 0.27088499069213867\n",
      "Train Epoch: 12 [49280/60032 (82.08955223880596%)] \t Loss: 0.21935611963272095\n",
      "Train Epoch: 12 [49920/60032 (83.15565031982942%)] \t Loss: 0.04687308520078659\n",
      "Train Epoch: 12 [50560/60032 (84.22174840085287%)] \t Loss: 0.20758908987045288\n",
      "Train Epoch: 12 [51200/60032 (85.28784648187633%)] \t Loss: 0.2618345022201538\n",
      "Train Epoch: 12 [51840/60032 (86.35394456289978%)] \t Loss: 0.09450569748878479\n",
      "Train Epoch: 12 [52480/60032 (87.42004264392324%)] \t Loss: 0.0865204706788063\n",
      "Train Epoch: 12 [53120/60032 (88.4861407249467%)] \t Loss: 0.26043662428855896\n",
      "Train Epoch: 12 [53760/60032 (89.55223880597015%)] \t Loss: 0.128167062997818\n",
      "Train Epoch: 12 [54400/60032 (90.6183368869936%)] \t Loss: 0.36783474683761597\n",
      "Train Epoch: 12 [55040/60032 (91.68443496801706%)] \t Loss: 0.20041300356388092\n",
      "Train Epoch: 12 [55680/60032 (92.75053304904051%)] \t Loss: 0.32626497745513916\n",
      "Train Epoch: 12 [56320/60032 (93.81663113006397%)] \t Loss: 0.35716232657432556\n",
      "Train Epoch: 12 [56960/60032 (94.88272921108742%)] \t Loss: 0.09773899614810944\n",
      "Train Epoch: 12 [57600/60032 (95.94882729211088%)] \t Loss: 0.07695293426513672\n",
      "Train Epoch: 12 [58240/60032 (97.01492537313433%)] \t Loss: 0.1618354320526123\n",
      "Train Epoch: 12 [58880/60032 (98.08102345415779%)] \t Loss: 0.12898848950862885\n",
      "Train Epoch: 12 [59520/60032 (99.14712153518124%)] \t Loss: 0.21902915835380554\n",
      "\n",
      "Test set: Average loss: 0.0591, Accuracy: 9812/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60032 (0.0%)] \t Loss: 0.358880877494812\n",
      "Train Epoch: 13 [640/60032 (1.0660980810234542%)] \t Loss: 0.13801947236061096\n",
      "Train Epoch: 13 [1280/60032 (2.1321961620469083%)] \t Loss: 0.07760800421237946\n",
      "Train Epoch: 13 [1920/60032 (3.1982942430703623%)] \t Loss: 0.1712176650762558\n",
      "Train Epoch: 13 [2560/60032 (4.264392324093817%)] \t Loss: 0.1399046778678894\n",
      "Train Epoch: 13 [3200/60032 (5.330490405117271%)] \t Loss: 0.12326596677303314\n",
      "Train Epoch: 13 [3840/60032 (6.3965884861407245%)] \t Loss: 0.12034780532121658\n",
      "Train Epoch: 13 [4480/60032 (7.462686567164179%)] \t Loss: 0.09589293599128723\n",
      "Train Epoch: 13 [5120/60032 (8.528784648187633%)] \t Loss: 0.34535443782806396\n",
      "Train Epoch: 13 [5760/60032 (9.594882729211088%)] \t Loss: 0.2303231656551361\n",
      "Train Epoch: 13 [6400/60032 (10.660980810234541%)] \t Loss: 0.10051006823778152\n",
      "Train Epoch: 13 [7040/60032 (11.727078891257996%)] \t Loss: 0.13024967908859253\n",
      "Train Epoch: 13 [7680/60032 (12.793176972281449%)] \t Loss: 0.2468865066766739\n",
      "Train Epoch: 13 [8320/60032 (13.859275053304904%)] \t Loss: 0.0790967121720314\n",
      "Train Epoch: 13 [8960/60032 (14.925373134328359%)] \t Loss: 0.19840537011623383\n",
      "Train Epoch: 13 [9600/60032 (15.991471215351812%)] \t Loss: 0.24410241842269897\n",
      "Train Epoch: 13 [10240/60032 (17.057569296375267%)] \t Loss: 0.12225493788719177\n",
      "Train Epoch: 13 [10880/60032 (18.12366737739872%)] \t Loss: 0.22511042654514313\n",
      "Train Epoch: 13 [11520/60032 (19.189765458422176%)] \t Loss: 0.1460091769695282\n",
      "Train Epoch: 13 [12160/60032 (20.255863539445627%)] \t Loss: 0.2087041139602661\n",
      "Train Epoch: 13 [12800/60032 (21.321961620469082%)] \t Loss: 0.14879389107227325\n",
      "Train Epoch: 13 [13440/60032 (22.388059701492537%)] \t Loss: 0.10187464207410812\n",
      "Train Epoch: 13 [14080/60032 (23.454157782515992%)] \t Loss: 0.35241198539733887\n",
      "Train Epoch: 13 [14720/60032 (24.520255863539447%)] \t Loss: 0.14239878952503204\n",
      "Train Epoch: 13 [15360/60032 (25.586353944562898%)] \t Loss: 0.14272800087928772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [16000/60032 (26.652452025586353%)] \t Loss: 0.044055238366127014\n",
      "Train Epoch: 13 [16640/60032 (27.718550106609808%)] \t Loss: 0.17087450623512268\n",
      "Train Epoch: 13 [17280/60032 (28.784648187633262%)] \t Loss: 0.059706442058086395\n",
      "Train Epoch: 13 [17920/60032 (29.850746268656717%)] \t Loss: 0.2748503088951111\n",
      "Train Epoch: 13 [18560/60032 (30.916844349680172%)] \t Loss: 0.25084438920021057\n",
      "Train Epoch: 13 [19200/60032 (31.982942430703623%)] \t Loss: 0.14452679455280304\n",
      "Train Epoch: 13 [19840/60032 (33.04904051172708%)] \t Loss: 0.2365816831588745\n",
      "Train Epoch: 13 [20480/60032 (34.11513859275053%)] \t Loss: 0.14566156268119812\n",
      "Train Epoch: 13 [21120/60032 (35.18123667377399%)] \t Loss: 0.3126400113105774\n",
      "Train Epoch: 13 [21760/60032 (36.24733475479744%)] \t Loss: 0.24386601150035858\n",
      "Train Epoch: 13 [22400/60032 (37.3134328358209%)] \t Loss: 0.12942826747894287\n",
      "Train Epoch: 13 [23040/60032 (38.37953091684435%)] \t Loss: 0.13132713735103607\n",
      "Train Epoch: 13 [23680/60032 (39.44562899786781%)] \t Loss: 0.12219719588756561\n",
      "Train Epoch: 13 [24320/60032 (40.511727078891255%)] \t Loss: 0.09287910908460617\n",
      "Train Epoch: 13 [24960/60032 (41.57782515991471%)] \t Loss: 0.18187366425991058\n",
      "Train Epoch: 13 [25600/60032 (42.643923240938165%)] \t Loss: 0.08865849673748016\n",
      "Train Epoch: 13 [26240/60032 (43.71002132196162%)] \t Loss: 0.18505623936653137\n",
      "Train Epoch: 13 [26880/60032 (44.776119402985074%)] \t Loss: 0.09502774477005005\n",
      "Train Epoch: 13 [27520/60032 (45.84221748400853%)] \t Loss: 0.09599995613098145\n",
      "Train Epoch: 13 [28160/60032 (46.908315565031984%)] \t Loss: 0.1356322169303894\n",
      "Train Epoch: 13 [28800/60032 (47.97441364605544%)] \t Loss: 0.1027970090508461\n",
      "Train Epoch: 13 [29440/60032 (49.04051172707889%)] \t Loss: 0.14289258420467377\n",
      "Train Epoch: 13 [30080/60032 (50.10660980810235%)] \t Loss: 0.28420335054397583\n",
      "Train Epoch: 13 [30720/60032 (51.172707889125796%)] \t Loss: 0.18858003616333008\n",
      "Train Epoch: 13 [31360/60032 (52.23880597014925%)] \t Loss: 0.09794565290212631\n",
      "Train Epoch: 13 [32000/60032 (53.304904051172706%)] \t Loss: 0.12255104631185532\n",
      "Train Epoch: 13 [32640/60032 (54.37100213219616%)] \t Loss: 0.27157366275787354\n",
      "Train Epoch: 13 [33280/60032 (55.437100213219615%)] \t Loss: 0.1414671242237091\n",
      "Train Epoch: 13 [33920/60032 (56.50319829424307%)] \t Loss: 0.3497532606124878\n",
      "Train Epoch: 13 [34560/60032 (57.569296375266525%)] \t Loss: 0.1680152714252472\n",
      "Train Epoch: 13 [35200/60032 (58.63539445628998%)] \t Loss: 0.25096336007118225\n",
      "Train Epoch: 13 [35840/60032 (59.701492537313435%)] \t Loss: 0.4310595989227295\n",
      "Train Epoch: 13 [36480/60032 (60.76759061833689%)] \t Loss: 0.10172133147716522\n",
      "Train Epoch: 13 [37120/60032 (61.833688699360344%)] \t Loss: 0.14036038517951965\n",
      "Train Epoch: 13 [37760/60032 (62.89978678038379%)] \t Loss: 0.17803451418876648\n",
      "Train Epoch: 13 [38400/60032 (63.96588486140725%)] \t Loss: 0.05941902846097946\n",
      "Train Epoch: 13 [39040/60032 (65.0319829424307%)] \t Loss: 0.1641591191291809\n",
      "Train Epoch: 13 [39680/60032 (66.09808102345416%)] \t Loss: 0.10081303119659424\n",
      "Train Epoch: 13 [40320/60032 (67.16417910447761%)] \t Loss: 0.19343841075897217\n",
      "Train Epoch: 13 [40960/60032 (68.23027718550107%)] \t Loss: 0.19006846845149994\n",
      "Train Epoch: 13 [41600/60032 (69.29637526652452%)] \t Loss: 0.3459061086177826\n",
      "Train Epoch: 13 [42240/60032 (70.36247334754798%)] \t Loss: 0.10643067210912704\n",
      "Train Epoch: 13 [42880/60032 (71.42857142857143%)] \t Loss: 0.3059525191783905\n",
      "Train Epoch: 13 [43520/60032 (72.49466950959489%)] \t Loss: 0.17983520030975342\n",
      "Train Epoch: 13 [44160/60032 (73.56076759061834%)] \t Loss: 0.3456920385360718\n",
      "Train Epoch: 13 [44800/60032 (74.6268656716418%)] \t Loss: 0.28534433245658875\n",
      "Train Epoch: 13 [45440/60032 (75.69296375266525%)] \t Loss: 0.16786636412143707\n",
      "Train Epoch: 13 [46080/60032 (76.7590618336887%)] \t Loss: 0.2904454469680786\n",
      "Train Epoch: 13 [46720/60032 (77.82515991471216%)] \t Loss: 0.146662175655365\n",
      "Train Epoch: 13 [47360/60032 (78.89125799573561%)] \t Loss: 0.18243376910686493\n",
      "Train Epoch: 13 [48000/60032 (79.95735607675905%)] \t Loss: 0.3440207540988922\n",
      "Train Epoch: 13 [48640/60032 (81.02345415778251%)] \t Loss: 0.20644204318523407\n",
      "Train Epoch: 13 [49280/60032 (82.08955223880596%)] \t Loss: 0.3604011535644531\n",
      "Train Epoch: 13 [49920/60032 (83.15565031982942%)] \t Loss: 0.1928074210882187\n",
      "Train Epoch: 13 [50560/60032 (84.22174840085287%)] \t Loss: 0.20693182945251465\n",
      "Train Epoch: 13 [51200/60032 (85.28784648187633%)] \t Loss: 0.38573336601257324\n",
      "Train Epoch: 13 [51840/60032 (86.35394456289978%)] \t Loss: 0.24132037162780762\n",
      "Train Epoch: 13 [52480/60032 (87.42004264392324%)] \t Loss: 0.17869538068771362\n",
      "Train Epoch: 13 [53120/60032 (88.4861407249467%)] \t Loss: 0.04435877501964569\n",
      "Train Epoch: 13 [53760/60032 (89.55223880597015%)] \t Loss: 0.1607726514339447\n",
      "Train Epoch: 13 [54400/60032 (90.6183368869936%)] \t Loss: 0.15879899263381958\n",
      "Train Epoch: 13 [55040/60032 (91.68443496801706%)] \t Loss: 0.25135737657546997\n",
      "Train Epoch: 13 [55680/60032 (92.75053304904051%)] \t Loss: 0.46862027049064636\n",
      "Train Epoch: 13 [56320/60032 (93.81663113006397%)] \t Loss: 0.2631133794784546\n",
      "Train Epoch: 13 [56960/60032 (94.88272921108742%)] \t Loss: 0.19582030177116394\n",
      "Train Epoch: 13 [57600/60032 (95.94882729211088%)] \t Loss: 0.24442370235919952\n",
      "Train Epoch: 13 [58240/60032 (97.01492537313433%)] \t Loss: 0.16687504947185516\n",
      "Train Epoch: 13 [58880/60032 (98.08102345415779%)] \t Loss: 0.1993361860513687\n",
      "Train Epoch: 13 [59520/60032 (99.14712153518124%)] \t Loss: 0.04202660173177719\n",
      "\n",
      "Test set: Average loss: 0.0574, Accuracy: 9827/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60032 (0.0%)] \t Loss: 0.352071613073349\n",
      "Train Epoch: 14 [640/60032 (1.0660980810234542%)] \t Loss: 0.20509707927703857\n",
      "Train Epoch: 14 [1280/60032 (2.1321961620469083%)] \t Loss: 0.2525615990161896\n",
      "Train Epoch: 14 [1920/60032 (3.1982942430703623%)] \t Loss: 0.09454561769962311\n",
      "Train Epoch: 14 [2560/60032 (4.264392324093817%)] \t Loss: 0.10973486304283142\n",
      "Train Epoch: 14 [3200/60032 (5.330490405117271%)] \t Loss: 0.1383749544620514\n",
      "Train Epoch: 14 [3840/60032 (6.3965884861407245%)] \t Loss: 0.4866061508655548\n",
      "Train Epoch: 14 [4480/60032 (7.462686567164179%)] \t Loss: 0.2483065277338028\n",
      "Train Epoch: 14 [5120/60032 (8.528784648187633%)] \t Loss: 0.21742507815361023\n",
      "Train Epoch: 14 [5760/60032 (9.594882729211088%)] \t Loss: 0.23095513880252838\n",
      "Train Epoch: 14 [6400/60032 (10.660980810234541%)] \t Loss: 0.07184820622205734\n",
      "Train Epoch: 14 [7040/60032 (11.727078891257996%)] \t Loss: 0.11069303750991821\n",
      "Train Epoch: 14 [7680/60032 (12.793176972281449%)] \t Loss: 0.1268191784620285\n",
      "Train Epoch: 14 [8320/60032 (13.859275053304904%)] \t Loss: 0.19598868489265442\n",
      "Train Epoch: 14 [8960/60032 (14.925373134328359%)] \t Loss: 0.13603641092777252\n",
      "Train Epoch: 14 [9600/60032 (15.991471215351812%)] \t Loss: 0.15058505535125732\n",
      "Train Epoch: 14 [10240/60032 (17.057569296375267%)] \t Loss: 0.14190809428691864\n",
      "Train Epoch: 14 [10880/60032 (18.12366737739872%)] \t Loss: 0.2910362780094147\n",
      "Train Epoch: 14 [11520/60032 (19.189765458422176%)] \t Loss: 0.2577238082885742\n",
      "Train Epoch: 14 [12160/60032 (20.255863539445627%)] \t Loss: 0.2074054479598999\n",
      "Train Epoch: 14 [12800/60032 (21.321961620469082%)] \t Loss: 0.19732427597045898\n",
      "Train Epoch: 14 [13440/60032 (22.388059701492537%)] \t Loss: 0.30284029245376587\n",
      "Train Epoch: 14 [14080/60032 (23.454157782515992%)] \t Loss: 0.29149365425109863\n",
      "Train Epoch: 14 [14720/60032 (24.520255863539447%)] \t Loss: 0.09519520401954651\n",
      "Train Epoch: 14 [15360/60032 (25.586353944562898%)] \t Loss: 0.31220537424087524\n",
      "Train Epoch: 14 [16000/60032 (26.652452025586353%)] \t Loss: 0.148317351937294\n",
      "Train Epoch: 14 [16640/60032 (27.718550106609808%)] \t Loss: 0.39348822832107544\n",
      "Train Epoch: 14 [17280/60032 (28.784648187633262%)] \t Loss: 0.3218482732772827\n",
      "Train Epoch: 14 [17920/60032 (29.850746268656717%)] \t Loss: 0.2089318335056305\n",
      "Train Epoch: 14 [18560/60032 (30.916844349680172%)] \t Loss: 0.06292617321014404\n",
      "Train Epoch: 14 [19200/60032 (31.982942430703623%)] \t Loss: 0.17365653812885284\n",
      "Train Epoch: 14 [19840/60032 (33.04904051172708%)] \t Loss: 0.1476295441389084\n",
      "Train Epoch: 14 [20480/60032 (34.11513859275053%)] \t Loss: 0.22928786277770996\n",
      "Train Epoch: 14 [21120/60032 (35.18123667377399%)] \t Loss: 0.15658636391162872\n",
      "Train Epoch: 14 [21760/60032 (36.24733475479744%)] \t Loss: 0.37798529863357544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [22400/60032 (37.3134328358209%)] \t Loss: 0.26366478204727173\n",
      "Train Epoch: 14 [23040/60032 (38.37953091684435%)] \t Loss: 0.1678014099597931\n",
      "Train Epoch: 14 [23680/60032 (39.44562899786781%)] \t Loss: 0.10457220673561096\n",
      "Train Epoch: 14 [24320/60032 (40.511727078891255%)] \t Loss: 0.05282852053642273\n",
      "Train Epoch: 14 [24960/60032 (41.57782515991471%)] \t Loss: 0.37414979934692383\n",
      "Train Epoch: 14 [25600/60032 (42.643923240938165%)] \t Loss: 0.12071076780557632\n",
      "Train Epoch: 14 [26240/60032 (43.71002132196162%)] \t Loss: 0.06461441516876221\n",
      "Train Epoch: 14 [26880/60032 (44.776119402985074%)] \t Loss: 0.17860327661037445\n",
      "Train Epoch: 14 [27520/60032 (45.84221748400853%)] \t Loss: 0.33421462774276733\n",
      "Train Epoch: 14 [28160/60032 (46.908315565031984%)] \t Loss: 0.16937585175037384\n",
      "Train Epoch: 14 [28800/60032 (47.97441364605544%)] \t Loss: 0.1719464808702469\n",
      "Train Epoch: 14 [29440/60032 (49.04051172707889%)] \t Loss: 0.09912234544754028\n",
      "Train Epoch: 14 [30080/60032 (50.10660980810235%)] \t Loss: 0.11617058515548706\n",
      "Train Epoch: 14 [30720/60032 (51.172707889125796%)] \t Loss: 0.23229554295539856\n",
      "Train Epoch: 14 [31360/60032 (52.23880597014925%)] \t Loss: 0.17650523781776428\n",
      "Train Epoch: 14 [32000/60032 (53.304904051172706%)] \t Loss: 0.14961130917072296\n",
      "Train Epoch: 14 [32640/60032 (54.37100213219616%)] \t Loss: 0.0756792426109314\n",
      "Train Epoch: 14 [33280/60032 (55.437100213219615%)] \t Loss: 0.06662631779909134\n",
      "Train Epoch: 14 [33920/60032 (56.50319829424307%)] \t Loss: 0.09692300856113434\n",
      "Train Epoch: 14 [34560/60032 (57.569296375266525%)] \t Loss: 0.3296073079109192\n",
      "Train Epoch: 14 [35200/60032 (58.63539445628998%)] \t Loss: 0.1764509081840515\n",
      "Train Epoch: 14 [35840/60032 (59.701492537313435%)] \t Loss: 0.24282580614089966\n",
      "Train Epoch: 14 [36480/60032 (60.76759061833689%)] \t Loss: 0.11789438873529434\n",
      "Train Epoch: 14 [37120/60032 (61.833688699360344%)] \t Loss: 0.1876528561115265\n",
      "Train Epoch: 14 [37760/60032 (62.89978678038379%)] \t Loss: 0.18216152489185333\n",
      "Train Epoch: 14 [38400/60032 (63.96588486140725%)] \t Loss: 0.05608629435300827\n",
      "Train Epoch: 14 [39040/60032 (65.0319829424307%)] \t Loss: 0.11390971392393112\n",
      "Train Epoch: 14 [39680/60032 (66.09808102345416%)] \t Loss: 0.12916821241378784\n",
      "Train Epoch: 14 [40320/60032 (67.16417910447761%)] \t Loss: 0.3689848780632019\n",
      "Train Epoch: 14 [40960/60032 (68.23027718550107%)] \t Loss: 0.3064129948616028\n",
      "Train Epoch: 14 [41600/60032 (69.29637526652452%)] \t Loss: 0.20676815509796143\n",
      "Train Epoch: 14 [42240/60032 (70.36247334754798%)] \t Loss: 0.23029252886772156\n",
      "Train Epoch: 14 [42880/60032 (71.42857142857143%)] \t Loss: 0.07260771095752716\n",
      "Train Epoch: 14 [43520/60032 (72.49466950959489%)] \t Loss: 0.2563766837120056\n",
      "Train Epoch: 14 [44160/60032 (73.56076759061834%)] \t Loss: 0.14539720118045807\n",
      "Train Epoch: 14 [44800/60032 (74.6268656716418%)] \t Loss: 0.21468983590602875\n",
      "Train Epoch: 14 [45440/60032 (75.69296375266525%)] \t Loss: 0.1624448448419571\n",
      "Train Epoch: 14 [46080/60032 (76.7590618336887%)] \t Loss: 0.207327201962471\n",
      "Train Epoch: 14 [46720/60032 (77.82515991471216%)] \t Loss: 0.14220595359802246\n",
      "Train Epoch: 14 [47360/60032 (78.89125799573561%)] \t Loss: 0.0831395834684372\n",
      "Train Epoch: 14 [48000/60032 (79.95735607675905%)] \t Loss: 0.35198837518692017\n",
      "Train Epoch: 14 [48640/60032 (81.02345415778251%)] \t Loss: 0.1630377471446991\n",
      "Train Epoch: 14 [49280/60032 (82.08955223880596%)] \t Loss: 0.2535775303840637\n",
      "Train Epoch: 14 [49920/60032 (83.15565031982942%)] \t Loss: 0.09585171192884445\n",
      "Train Epoch: 14 [50560/60032 (84.22174840085287%)] \t Loss: 0.1406976729631424\n",
      "Train Epoch: 14 [51200/60032 (85.28784648187633%)] \t Loss: 0.046185143291950226\n",
      "Train Epoch: 14 [51840/60032 (86.35394456289978%)] \t Loss: 0.19792762398719788\n",
      "Train Epoch: 14 [52480/60032 (87.42004264392324%)] \t Loss: 0.2127155065536499\n",
      "Train Epoch: 14 [53120/60032 (88.4861407249467%)] \t Loss: 0.12835878133773804\n",
      "Train Epoch: 14 [53760/60032 (89.55223880597015%)] \t Loss: 0.16062970459461212\n",
      "Train Epoch: 14 [54400/60032 (90.6183368869936%)] \t Loss: 0.07875563204288483\n",
      "Train Epoch: 14 [55040/60032 (91.68443496801706%)] \t Loss: 0.13825081288814545\n",
      "Train Epoch: 14 [55680/60032 (92.75053304904051%)] \t Loss: 0.15054473280906677\n",
      "Train Epoch: 14 [56320/60032 (93.81663113006397%)] \t Loss: 0.09110160171985626\n",
      "Train Epoch: 14 [56960/60032 (94.88272921108742%)] \t Loss: 0.22878797352313995\n",
      "Train Epoch: 14 [57600/60032 (95.94882729211088%)] \t Loss: 0.16242049634456635\n",
      "Train Epoch: 14 [58240/60032 (97.01492537313433%)] \t Loss: 0.1943955272436142\n",
      "Train Epoch: 14 [58880/60032 (98.08102345415779%)] \t Loss: 0.2675396203994751\n",
      "Train Epoch: 14 [59520/60032 (99.14712153518124%)] \t Loss: 0.12712180614471436\n",
      "\n",
      "Test set: Average loss: 0.0562, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/60032 (0.0%)] \t Loss: 0.15170077979564667\n",
      "Train Epoch: 15 [640/60032 (1.0660980810234542%)] \t Loss: 0.25201451778411865\n",
      "Train Epoch: 15 [1280/60032 (2.1321961620469083%)] \t Loss: 0.3105727732181549\n",
      "Train Epoch: 15 [1920/60032 (3.1982942430703623%)] \t Loss: 0.08593732863664627\n",
      "Train Epoch: 15 [2560/60032 (4.264392324093817%)] \t Loss: 0.2215871661901474\n",
      "Train Epoch: 15 [3200/60032 (5.330490405117271%)] \t Loss: 0.17101286351680756\n",
      "Train Epoch: 15 [3840/60032 (6.3965884861407245%)] \t Loss: 0.15237295627593994\n",
      "Train Epoch: 15 [4480/60032 (7.462686567164179%)] \t Loss: 0.12326116859912872\n",
      "Train Epoch: 15 [5120/60032 (8.528784648187633%)] \t Loss: 0.1572781801223755\n",
      "Train Epoch: 15 [5760/60032 (9.594882729211088%)] \t Loss: 0.1372511088848114\n",
      "Train Epoch: 15 [6400/60032 (10.660980810234541%)] \t Loss: 0.20997992157936096\n",
      "Train Epoch: 15 [7040/60032 (11.727078891257996%)] \t Loss: 0.18794173002243042\n",
      "Train Epoch: 15 [7680/60032 (12.793176972281449%)] \t Loss: 0.14057192206382751\n",
      "Train Epoch: 15 [8320/60032 (13.859275053304904%)] \t Loss: 0.15436780452728271\n",
      "Train Epoch: 15 [8960/60032 (14.925373134328359%)] \t Loss: 0.1461433321237564\n",
      "Train Epoch: 15 [9600/60032 (15.991471215351812%)] \t Loss: 0.2632785439491272\n",
      "Train Epoch: 15 [10240/60032 (17.057569296375267%)] \t Loss: 0.15938815474510193\n",
      "Train Epoch: 15 [10880/60032 (18.12366737739872%)] \t Loss: 0.1584424376487732\n",
      "Train Epoch: 15 [11520/60032 (19.189765458422176%)] \t Loss: 0.1578821837902069\n",
      "Train Epoch: 15 [12160/60032 (20.255863539445627%)] \t Loss: 0.09660042822360992\n",
      "Train Epoch: 15 [12800/60032 (21.321961620469082%)] \t Loss: 0.1300887167453766\n",
      "Train Epoch: 15 [13440/60032 (22.388059701492537%)] \t Loss: 0.149841770529747\n",
      "Train Epoch: 15 [14080/60032 (23.454157782515992%)] \t Loss: 0.158696249127388\n",
      "Train Epoch: 15 [14720/60032 (24.520255863539447%)] \t Loss: 0.054000116884708405\n",
      "Train Epoch: 15 [15360/60032 (25.586353944562898%)] \t Loss: 0.17575421929359436\n",
      "Train Epoch: 15 [16000/60032 (26.652452025586353%)] \t Loss: 0.29353922605514526\n",
      "Train Epoch: 15 [16640/60032 (27.718550106609808%)] \t Loss: 0.16986168920993805\n",
      "Train Epoch: 15 [17280/60032 (28.784648187633262%)] \t Loss: 0.16014039516448975\n",
      "Train Epoch: 15 [17920/60032 (29.850746268656717%)] \t Loss: 0.07768432050943375\n",
      "Train Epoch: 15 [18560/60032 (30.916844349680172%)] \t Loss: 0.08743871748447418\n",
      "Train Epoch: 15 [19200/60032 (31.982942430703623%)] \t Loss: 0.28086620569229126\n",
      "Train Epoch: 15 [19840/60032 (33.04904051172708%)] \t Loss: 0.10983885824680328\n",
      "Train Epoch: 15 [20480/60032 (34.11513859275053%)] \t Loss: 0.2759546935558319\n",
      "Train Epoch: 15 [21120/60032 (35.18123667377399%)] \t Loss: 0.2798730134963989\n",
      "Train Epoch: 15 [21760/60032 (36.24733475479744%)] \t Loss: 0.30907681584358215\n",
      "Train Epoch: 15 [22400/60032 (37.3134328358209%)] \t Loss: 0.32159531116485596\n",
      "Train Epoch: 15 [23040/60032 (38.37953091684435%)] \t Loss: 0.1044665202498436\n",
      "Train Epoch: 15 [23680/60032 (39.44562899786781%)] \t Loss: 0.17295192182064056\n",
      "Train Epoch: 15 [24320/60032 (40.511727078891255%)] \t Loss: 0.0659443587064743\n",
      "Train Epoch: 15 [24960/60032 (41.57782515991471%)] \t Loss: 0.05319519340991974\n",
      "Train Epoch: 15 [25600/60032 (42.643923240938165%)] \t Loss: 0.2583426535129547\n",
      "Train Epoch: 15 [26240/60032 (43.71002132196162%)] \t Loss: 0.12138747423887253\n",
      "Train Epoch: 15 [26880/60032 (44.776119402985074%)] \t Loss: 0.09086534380912781\n",
      "Train Epoch: 15 [27520/60032 (45.84221748400853%)] \t Loss: 0.2920413017272949\n",
      "Train Epoch: 15 [28160/60032 (46.908315565031984%)] \t Loss: 0.28051137924194336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [28800/60032 (47.97441364605544%)] \t Loss: 0.2080739587545395\n",
      "Train Epoch: 15 [29440/60032 (49.04051172707889%)] \t Loss: 0.16449688374996185\n",
      "Train Epoch: 15 [30080/60032 (50.10660980810235%)] \t Loss: 0.06201435998082161\n",
      "Train Epoch: 15 [30720/60032 (51.172707889125796%)] \t Loss: 0.11111438274383545\n",
      "Train Epoch: 15 [31360/60032 (52.23880597014925%)] \t Loss: 0.21094626188278198\n",
      "Train Epoch: 15 [32000/60032 (53.304904051172706%)] \t Loss: 0.20333929359912872\n",
      "Train Epoch: 15 [32640/60032 (54.37100213219616%)] \t Loss: 0.0810951292514801\n",
      "Train Epoch: 15 [33280/60032 (55.437100213219615%)] \t Loss: 0.289828896522522\n",
      "Train Epoch: 15 [33920/60032 (56.50319829424307%)] \t Loss: 0.11391934752464294\n",
      "Train Epoch: 15 [34560/60032 (57.569296375266525%)] \t Loss: 0.2071499526500702\n",
      "Train Epoch: 15 [35200/60032 (58.63539445628998%)] \t Loss: 0.07873706519603729\n",
      "Train Epoch: 15 [35840/60032 (59.701492537313435%)] \t Loss: 0.13353823125362396\n",
      "Train Epoch: 15 [36480/60032 (60.76759061833689%)] \t Loss: 0.13346651196479797\n",
      "Train Epoch: 15 [37120/60032 (61.833688699360344%)] \t Loss: 0.18687190115451813\n",
      "Train Epoch: 15 [37760/60032 (62.89978678038379%)] \t Loss: 0.1767520308494568\n",
      "Train Epoch: 15 [38400/60032 (63.96588486140725%)] \t Loss: 0.10206156969070435\n",
      "Train Epoch: 15 [39040/60032 (65.0319829424307%)] \t Loss: 0.18882670998573303\n",
      "Train Epoch: 15 [39680/60032 (66.09808102345416%)] \t Loss: 0.19384418427944183\n",
      "Train Epoch: 15 [40320/60032 (67.16417910447761%)] \t Loss: 0.24061039090156555\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01) \n",
    "epoch = 20\n",
    "for epoch in range(1, epoch + 1):\n",
    "    train(model, federated_train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)\n",
    "\n",
    "th.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = mnist_trainset.data[52009]\n",
    "img = image.view(1, 784).float()\n",
    "with th.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "ps = th.exp(logps)\n",
    "probab = list(ps.numpy())\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
    "plt.imshow(img.view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy.BaseDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
